BdactyloidesthruGSEA081615.txt

08/16/15:
# switching from 
/Users/bterry/macbookpro2015/keenanres15/Sitalica26/Sitalica_041515.txt

# To do: working from nprot.2013.084.pdf, apply Trinity to RNAseq single end 95C1-3, T1-3.

# p-1503 of nprot.2013.084.pdf, do run on ***example data set provided***.
# s/w setup (p-1503), path to s/w setup on Crane ???????

# SEE 1st current notes (p-1503)
# Q: will my **single end** RNAseq samples be a problem ????????????




# setting up R & packages ???????

# PROCEDURE:

# 

Trinity version trinityrnaseq_r2013-02-25: http://trinityrnaseq.sourceforge.net
# looks like newer versions available ????????????????????
# v2.0.6 at
https://github.com/trinityrnaseq/trinityrnaseq/releases
# looks like only source code available (tar.gz)
# looks like I could use .gz or .zip ?????????
# why not .tgz rather than .gz ???????????????????????????
# so dnload trinityrnaseq-2.0.6.tar.gz (151 MB)
cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing
tar –xzvf trinityrnaseq-2.0.6.tar.gz
# Same message as below, and won't work.
# tried wi Mac uncompress utility, appears to work, so why not 'tar' ?????????????
# Q: directions to install Trinity, etc. ????????????????


# Dnloading TrinityNatureProtocolTutorial.tgz
# p-1504
# mine only 474 Mb ??????????????????

# Name ‘TrinityNatureProtocolTutorial.tgz’
# Why this, already this name ??????????
tar –xvf TrinityNatureProtocolTutorial.tgz
# nothing happened, so must not be correct, so try as per p-131, B. McCarty book ??????????????
tar –xzvf TrinityNatureProtocolTutorial.tgz
# nothing happened here either, perhaps the 474 Mb file is corrupt ???????
# try rednload, try 
wget http://sourceforge.net/projects/trinityrnaseq/files/misc/TrinityNatureProtocolTutorial.tgz/download
# Started 9:45pm => 10:54pm end.
# -rw-r--r--   1 bterry  staff  474015394 Feb  9  2013 download
# still **not** 540 Mb ???????????????????????
# title is 'download', so perhaps why need for name change.
mv download TrinityNatureProtocolTutorial.tgz
tar –xvf TrinityNatureProtocolTutorial.tgz
philip-terry:trintoGSEA bterry$ tar –xvf TrinityNatureProtocolTutorial.tgz
Usage:
  List:    tar -tf <archive-filename>
  Extract: tar -xf <archive-filename>
  Create:  tar -cf <archive-filename> [filenames...]
  Help:    tar --help
philip-terry:trintoGSEA bterry$ 
# why failed ???????????????????????????
# try:
tar –xzvf TrinityNatureProtocolTutorial.tgz
# Q: same output, WHAT WRONG ????????????????????????????
# tried Mac uncompress facility, appears to have worked. I note: looks like different files than shows, p-1504, perhaps just a different data set ??????



08/18/15:
# Issue: need claim whatever files on tusker want (certainly trimmed 95C1-3,T1-3)
(1)
# created globus acct:
# uname: pterry
# email: pterry@...
# pword: glo15-Tran
(2)
# activate HCC endpoints
# figured out way for hcc#tusker, but ***not*** like directions off one of the links from hcc-docs, 'handling data, 'globus connect' link, ...

08/19/15:
# Q: what to do with files in 
/home/amundsen/pterry
# Q: says not mounted, but can cd to 'scripts dir', perhaps can get files ??????

# For $WORK dir,
Disk usage for user pterry:
  Home [0.7% (0/10GB)               ]  Work [0.5% (280/51200GB)          ]
Disk usage for primary group amundsen:
  Home [0.3% (2/500GB)              ]  Work [18.7% (9587/51200GB)        ]
Disk usage for entire system:
  Home [5.8% (590/10240GB)          ]  Work [83.2% (445355/535321GB)     ]
above output generated by 'hcc-du' command, type 'hcc-du -h' for more options
[pterry@login.tusker ~]$ $WORK
-bash: /work/amundsen/pterry: is a directory
[pterry@login.tusker ~]$ cd $WORK
[pterry@login.tusker pterry]$ pwd
/work/amundsen/pterry
[pterry@login.tusker pterry]$ ls -al
total 550852
drwx--x--- 13 pterry amundsen      4096 Jun 11 22:39 .
drwxr-x--x 10 root   amundsen      4096 Mar 16 13:53 ..
drwxr-xr-x  4 pterry amundsen      4096 Jun 11 23:06 198168_txtome
drwxr-xr-x  2 pterry amundsen      4096 Aug  8  2014 blastngen
drwxr-xr-x 12 pterry amundsen      4096 Jun 17  2014 brachy_dis
drwxr-xr-x  4 pterry amundsen      4096 Dec 10  2013 nprot
drwxr-xr-x  2 pterry amundsen      4096 Dec 11  2012 parallel
-rwxr-xr-x  1 pterry amundsen      2839 Jun 19  2014 ParseFastQ.py
-rw-r--r--  1 pterry amundsen      2746 Jun 19  2014 ParseFastQ.pyc
-rwxr-xr-x  1 pterry amundsen       275 Jun 19  2014 parse.py
drwxr-xr-x  7 pterry amundsen      4096 Aug 16  2014 Sitalica
drwxr-xr-x  5 pterry amundsen      4096 May 19 21:23 Sitalica26
-rw-r--r--  1 pterry amundsen 564002816 Dec  6  2013 SRR031712.fastq
drwxr-xr-x  6 pterry amundsen      4096 Mar 15 10:44 stat932
drwxr-xr-x  3 pterry amundsen      4096 Jan 17  2014 tgirke
drwxr-xr-x  2 pterry amundsen      4096 May 27  2013 velvet
drwxr-xr-x 10 pterry amundsen      4096 Sep 18  2013 velvet5
[pterry@login.tusker pterry]$ logout
Connection to tusker.unl.edu closed.
philip-terry:planets bterry$ ssh -Y pterry@tusker.unl.edu

***THE /WORK FILESYSTEM IS MOUNTED READ-ONLY, AND WILL ONLY BE MOUNTED***
***READ-ONLY BEFORE WE WIPE IT CLEAN. PLEASE SAVE IMPORTANT DATA TO***
***ANOTHER LOCATION ASAP!!!***

# so dirs to try to get with globus:
# Having enough trouble 'activating' endpoints, but finally have.
# So transfer 11 dirs, start ~ 10:30am
# appears to be going so rapidly, perhaps setup 'File transfers to/from **personal wrkstations**. (perhaps for scripts dir on tusker to my macbookpro laptop.
# TO DO: check what have on crane after transfer ?????????
ssh -Y pterry@crane.unl.edu
# Rrq096mN
# checked 
[pterry@login.crane Sitalica26]$ pwd
/work/amundsen/pterry/Sitalica26
[pterry@login.crane Sitalica26]$ ls -al
total 20
drwxr-xr-x  5 pterry amundsen 4096 Aug 19 10:33 .
drwx--x--- 13 pterry amundsen 4096 Aug 19 10:50 ..
drwxr-xr-x  3 pterry amundsen 4096 Aug 19 10:39 bowtie22IND
drwxr-xr-x  6 pterry amundsen 4096 Aug 19 10:42 bufgrass
drwxr-xr-x  2 pterry amundsen 4096 Aug 19 10:43 genome
[pterry@login.crane Sitalica26]$ 
# looked inside bufgrass, looks ok.

# TO DO: perhaps setup 'File transfers to/from **personal wrkstations**. (perhaps for scripts dir on tusker to my macbookpro laptop.


# resume try run example data thru trinity, from github tutorial site, 
http://trinityrnaseq.github.io/trinity_rnaseq_tutorial.html

# To start, assume Trinity v2.0.? installed on hcc#crane appropriately (???), just try start using there.
p-1
Procedure
Collection of RNA-Seq data Timing: ~10 minutes===

ssh -Y pterry@crane.unl.edu
# Rrq096mN
# srun --pty --ntasks-per-node=8 --mem 10gb $SHELL    # 1:23pm => I cancelled, 1:48pm, no resource allocation.
# so just try 'my prev. $SHELL command'
srun --pty $SHELL   # prompt back almost instantly, 10:23pm
# perhaps exit, try prev failed 'srun', see if quicker at night?
exit
srun --pty --ntasks-per-node=8 --mem 10gb $SHELL  # prompt back immedly
cd /work/amundsen/pterry
1.
wget http://sourceforge.net/projects/trinityrnaseq/files/misc/TrinityNatureProtocolTutorial.tgz/download
# started 10:27pm => 11:00pm
# I note dnload speed in K/s, 160-450 range
exit
2.
cd /work/amundsen/pterry
mv download TrinityNatureProtocolTutorial.tgz
3.
srun --pty --ntasks-per-node=8 --mem 10gb $SHELL
tar –xzvf TrinityNatureProtocolTutorial.tgz
# note: could append dir to uncompress to (-C dir. path)
[pterry@c1422.crane pterry]$ tar –xzvf TrinityNatureProtocolTutorial.tgz
tar: invalid option -- '?'
Try `tar --help' or `tar --usage' for more information.
[pterry@c1422.crane pterry]$ 
# what to think ???????????????????????????
# try (perhaps file not compressed ????????????????????)
tar –xvf TrinityNatureProtocolTutorial.tgz
[pterry@c1422.crane pterry]$ tar –xvf TrinityNatureProtocolTutorial.tgz
tar: invalid option -- '?'
Try `tar --help' or `tar --usage' for more information.
[pterry@c1422.crane pterry]$ 
# also failed ????????????????????????????????????????????
# hand typed in command, worked.

08/21/15:
4.
mv TrinityNatureProtocolTutorial Trin20Tut
#mkdir Bdac_Trin20_workg
#cd Bdac_Trin20_workg
cd Trin20Tut
5.
# concatenate ...
cat 1M_READS_sample/*.left.fq > reads.ALL.left.fq
cat 1M_READS_sample/*.right.fq > reads.ALL.right.fq
6.
# Assemble with Trinity
export TRINITY_HOME=/util/opt/trinity/2.0.6/gcc/4.8.2
echo $TRINITY_HOME
module load compiler/gcc/4.8
module load bowtie/1.1
module load samtools/1.2
module load trinity/2.0
# Q: is this consistent with v 2.0.6 ???????????????????????
$TRINITY_HOME/Trinity --seqType fq --JM 10G \
    --left reads.ALL.left.fq --right reads.ALL.right.fq \
    --SS_lib_type RF --CPU 6

[pterry@c2218.crane Trin20Tut]$ $TRINITY_HOME/Trinity --seqType fq --JM 10G \
>     --left reads.ALL.left.fq --right reads.ALL.right.fq \
>     --SS_lib_type RF --CPU 6
Error, do not understand options: --JM 10G --left reads.ALL.left.fq --right reads.ALL.right.fq --SS_lib_type RF --CPU 6
[pterry@c2218.crane Trin20Tut]$ Trinity -h
# gave bunch details, upshot may be may have to contact support site, for syntax for parameters in error message ??????????????????????
# To try **1st**, manually enter the Trinity command 

$TRINITY_HOME/Trinity.pl --seqType fq --JM 10G --left reads.ALL.left.fq --right reads.ALL.right.fq --SS_lib_type RF --CPU 6

[pterry@c0918.crane Trin20Tut]$ $TRINITY_HOME/Trinity.pl --seqType fq --JM 10G --left reads.ALL.left.fq --right reads.ALL.right.fq --SS_lib_type RF --CPU 6
bash: /util/opt/trinity/2.0/gcc/4.8/Trinity.pl: No such file or directory
[pterry@c0918.crane Trin20Tut]$ 
# perhaps issue is location/definition of $TRINITY_HOME ???????????????????
# Don't find Trinity.pl in /util/opt/trinity/2.0/gcc/4.8
# there is a 'Trinity'
# so try 

$TRINITY_HOME/Trinity --seqType fq --JM 10G --left reads.ALL.left.fq --right reads.ALL.right.fq --SS_lib_type RF --CPU 6

[pterry@c0509.crane Trin20Tut]$ $TRINITY_HOME/Trinity --seqType fq --JM 10G --left reads.ALL.left.fq --right reads.ALL.right.fq --SS_lib_type RF --CPU 6
bash: /util/opt/trinity/2.0/gcc/4.8:/util/opt/trinity/2.0.6/gcc/4.8.2/Trinity: No such file or directory
[pterry@c0509.crane Trin20Tut]$ 
# Q: confusing ?????????????????????????????????????????????????
/util/opt/trinity/2.0/gcc/4.8
/util/opt/trinity/2.0.6/gcc/4.8.2/Trinity
# Q: perhaps just use /util/opt/trinity/2.0.6/gcc/4.8.2/Trinity for Trinity location ??????????????????????
/util/opt/trinity/2.0.6/gcc/4.8.2/Trinity --seqType fq --JM 10G --left reads.ALL.left.fq --right reads.ALL.right.fq --SS_lib_type RF --CPU 6

[pterry@c0509.crane Trin20Tut]$ /util/opt/trinity/2.0.6/gcc/4.8.2/Trinity --seqType fq --JM 10G --left reads.ALL.left.fq --right reads.ALL.right.fq --SS_lib_type RF --CPU 6
Error, do not understand options: --JM 10G --left reads.ALL.left.fq --right reads.ALL.right.fq --SS_lib_type RF --CPU 6
# Q: what to think ?????????????????????????
# Q: are there multiple installs on trinity on crane, confusion from ??????


[pterry@c0918.crane Trin20Tut]$ $TRINITY_HOME/Trinity --seqType fq --JM 10G --left reads.ALL.left.fq --right reads.ALL.right.fq --SS_lib_type RF --CPU 6
Error, do not understand options: --JM 10G --left reads.ALL.left.fq --right reads.ALL.right.fq --SS_lib_type RF --CPU 6
[pterry@c0918.crane Trin20Tut]$ 
Trinity -h

cd /util/opt/trinity/2.0.6/gcc/4.8.2
[pterry@c0918.crane 4.8.2]$ pwd
/util/opt/trinity/2.0.6/gcc/4.8.2
# a 'Trinity' here.
# How to proceed? 
echo $TRINITY_HOME

[pterry@c0918.crane 4.8.2]$ echo $TRINITY_HOME
/util/opt/trinity/2.0/gcc/4.8

# not for 2.0.6 ???????????????????
cd sample_data/test_Trinity_Assembly

STOPPED

08/23/15:
# Rewriting & testing:
ssh -Y pterry@crane.unl.edu
# Rrq096mN
srun --pty --ntasks-per-node=8 --mem 10gb $SHELL  # prompt back immedly
cd /work/amundsen/pterry
cd Trin20Tut
# export TRINITY_HOME=/util/opt/trinity/2.0.6/gcc/4.8.2
# Q: is this appropriate, or should specify ***SOMETHING ELSE*** ????????
# LIKE /util/opt/trinity/2.0/gcc/4.8  ?????????????????????
export TRINITY_HOME=/util/opt/trinity/2.0/gcc/4.8

echo $TRINITY_HOME
module load compiler/gcc/4.8
module load bowtie/1.1
module load samtools/1.2
echo $PATH
module load trinity/2.0
# module load trinity/2.0.6
echo $PATH
# module load trinity/2.0 perhaps not hitting '2.0.6' ????????????????
# but /util/opt/trinity/2.0/gcc/4.8   ?????????????????????
echo $PATH
# LOOKS LIKE hitting different version of Trinity (NOT 2.0.6), need different 'module load trinity/2.0' command ????????????*************????????????????
# BUT **soft link** 2.0 -> 2.0.6 ????????????????????????




$TRINITY_HOME/Trinity --seqType fq --JM 10G --left reads.ALL.left.fq --right reads.ALL.right.fq --SS_lib_type RF --CPU 6

# OR

/util/opt/trinity/2.0.6/gcc/4.8.2/Trinity --seqType fq --JM 10G --left reads.ALL.left.fq --right reads.ALL.right.fq --SS_lib_type RF --CPU 6

# or 

$TRINITY_HOME/Trinity --seqType fq --max_memory 10G --left reads.ALL.left.fq --right reads.ALL.right.fq --SS_lib_type RF --CPU 6

# OR

/util/opt/trinity/2.0.6/gcc/4.8.2/Trinity --seqType fq --max_memory 10G --left reads.ALL.left.fq --right reads.ALL.right.fq --SS_lib_type RF --CPU 6
# 3:36pm -> THIS ONE STARTED RUNNING ???????????******????????????
# WHY ????????????????

# go back check what created in 'Trin20Tut' dir.
ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /work/amundsen/pterry
cd Trin20Tut
ls -al
cd trinity_out_dir
ls -al
# whole bunch new dir's in this new dir.
# Q: Don't see any error messages, but apparently terminated early ??????????
# Q: 2 questions:
# 1) why particular trinity command ran ????????????????
# 2) why did it terminate early, if did, what to do about that ?????????????

08/24/15:
Talked to Adam (HCC)

i. Check if run from 08/23/15 may have finished, but my terminal session perhaps lost contact, did not reflect such.
ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /work/amundsen/pterry
cd Trin20Tut
ls -al
cd trinity_out_dir
ls -al
# Looks like no Trinity.fasta in trinity_out_dir dir. as expected in step 7 of 
http://trinityrnaseq.github.io/trinity_rnaseq_tutorial.html when step 6 finishes.
ii. Try resume 08/23/15 trinity run on Crane. But do with SLURM batch file. So will need create scripts dir in /home/amundsen/pterry on Crane.
mkdir scripts

08/25/15:
# so try 1st to run trinity without erasing directories created in trinity_out_dir dir. in /work/amundsen/pterry/Trin20Tut from 08/23/15 run which apparently did not complete (no Trinity.fasta file produced), Adam says crane may resume where it left off?
# /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing/tut/slurm_trinityexampledatacrane.sh
# Adam, don't export to TRINITY_HOME, says Crane will/may do this itself?

# now go back look how I scp'd slurm script to cluster, ran slurm script, checked on it afterwords
# start at line 418, 962, Sitalica041515.txt
cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing/tut
## TO fix script file, done
scp slurm_trinityexampledatacrane.sh pterry@crane.unl.edu:/home/amundsen/pterry/scripts/
ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /home/amundsen/pterry/scripts
ls -al
sbatch slurm_trinityexampledatacrane.sh  1971803 11:36pm => 12:14am, no longer listed in squeue -u pterry
squeue -u pterry

cd /work/amundsen/pterry/Trin20Tut
ls -l
less job.1971803.err  # 0 bytes
less job.1971803.out  # 1730956
cd trinity_out_dir
# look for Trinity.fasta File
-rw-r--r-- 1 pterry amundsen   11073091 Aug 26 00:04 Trinity.fasta
less Trinity.fasta
>TR1|c0_g1_i1 len=745 path=[723:0-744] [-1, 723, -2]
TAAAAGTATGTTTGTCCTCTAACACTCGTGGAAAAGAATTCCAAAATTGAGAAATTCTTC
TTTTTTTGGTAGCAATTGATGCTAAAATTTAATAATTTTACTTTAATTTCGTTAATTTTT
TCTCAACTAAGAAATTTCTAAGCTGAGCGTCATTTCGGTGAACTTTTATTATTTTCTATT
GAAAAAACATTACAATAGATAAAAAATAAGAAGACTGCATGATTAGAAGATTTTTTCACA
CAATGGGAAGGCAGGATCGTATTTATAAAACGCTTTCAGAAGCCTTGAAAACAGACAAGA
TTACCTTGTATAATGATAGTTATAAACATAGCCATCATATTGCGATGAAAGGCGTACCAG
ACACAAATGAGACTCATTTCCGTTTAGAAATTGTATCACCAGAGTTCTCCGGGATGTCAA
GAGTCGCCCGACATCGACTTGTTTATGGATTACTAAAAGATGAATTTGATGGCGGCCTTC
ATGCTCTCCAAATAACTTCTAGCAAGACTCCTGATGAAGTTTCGTAATTTTCGAAAAGTA
TTCAGGTATATTATTACATTTTTACATTTAGACAATTACATGACAGATTGAATGTGCTTG
CTCGATTGTTTTGTTGCACTTTGTTCGCATGCTTAAATATGAAATACTGCGAAGTGAAAA
GAATTTCACACATATTACAAAAAGGGTGAAACCAAAATAAATCTTATTTTGAGTTGATTC
ACGGCTTAATCAGCGATTATTTACT
>TR2|c0_g1_i1 len=750 path=[728:0-749] [-1, 728, -2]
AAGCTGATTATATTGACTTTACTTACCGAATGATTTAATATATTCCTTTACTATTAATTC
TAAAAAAACCCAGACTTACAACCTAGTCGTTAAATTGTAGGAACCGACTACAACTTCGAC
AGCTGTTTCAAAGCATTTGAAAAACTTACAAAGTGTTTAAGATTGAATCTTTTTTTTAAC
CTGTACTATATTTTTCTCTTGTAATTAGCTCTATTTTCCTTTTCACTATGCCATTTTTGA
AACCTTCAAAGGTTTCACTTAAACGAATTCTCCAAGGAAATCCACCCAAACCAATTGGCT
TAACTGAGTATGGTCATTTGCTGAGGCTCGTTGGTCTTCGTGAAGCAGACTCTAAGGAAG
AGAATGAAAGAACAATTCTAAAACTCAACGAAGGAATCATTCAAATGCATGCAATTGAGA
GACTTGATACATCCTTCATTAAGGAACCATTTCGTACTTTGAATCATGCTATTAATGCGG
...
>TR5742|c0_g2_i1 len=965 path=[1103:0-198 1104:199-219 1105:220-964] [-1, 1103, 1104, 1105, -2]
Trinity.fasta
# apparently 5742 reconstructed transcripts found/assembled in Trinity.fasta
file, Q: is this reasonable ??????????

sacct -j 1971803 -o start,end
[pterry@login.crane trinity_out_dir]$ sacct -j 1971803 -o start,end
              Start                 End 
------------------- ------------------- 
2015-08-25T23:36:03 2015-08-26T00:04:16 
2015-08-25T23:36:03 2015-08-26T00:04:16 
[pterry@login.crane trinity_out_dir]$ 

# perhaps run from scratch again ???????????????
# or proceed to step 7 ???????

08/26/15:
# or proceed to step 7, http://trinityrnaseq.github.io/trinity_rnaseq_tutorial.html
7.
# 'examine the stats' ...
$TRINITY_HOME/util/TrinityStats.pl trinity_out_dir/Trinity.fasta
# Q: perhaps run from /work/amundsen/pterry/Trin20Tut, yes cause trinity_out_dir dir inside ?????????
# So, create a SLURM script to run TrinityStats.pl
cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing/tut
## TO fix script file, done
scp slurm_7TrinityStatsexampdatacrane.sh pterry@crane.unl.edu:/home/amundsen/pterry/scripts/

ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /home/amundsen/pterry/scripts
ls -al
sbatch slurm_7TrinityStatsexampdatacrane.sh  1972265 11:55am => 11:56am, no longer listed in squeue -u pterry
squeue -u pterry

cd /work/amundsen/pterry/Trin20Tut
ls -l
less job.1972265.err  # 0 bytes
less job.1972265.out  # 818 bytes
################################
## Counts of transcripts, etc.
################################
Total trinity 'genes':  9346
Total trinity transcripts:      9537
Percent GC: 38.14

########################################
Stats based on ALL transcript contigs:
########################################

        Contig N10: 3125
        Contig N20: 2544
        Contig N30: 2159
        Contig N40: 1856
        Contig N50: 1603

        Median contig length: 812
        Average contig: 1070.19
        Total assembled bases: 10206444

job.1972265.out 
# Q: 5742 records in Trinity.fasta file, any comment relating this number to these stats from TrinityStats.pl file ?????????????????

# now, steps 8-13, http://trinityrnaseq.github.io/trinity_rnaseq_tutorial.html
# Quality assessment, optional, but recomended.
# For learning purposes, run each step in its own slurm script
9. Prepare the reference transcriptome fasta file as a BLAST database:
# So, create a SLURM script to run TrinityStats.pl
cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing/tut
## TO fix script file, done
scp slurm_8Trinitymakeblastdbexampdatacrane.sh pterry@crane.unl.edu:/home/amundsen/pterry/scripts/
ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /home/amundsen/pterry/scripts
ls -al
sbatch slurm_8Trinitymakeblastdbexampdatacrane.sh  1972371 1:18pm => 11:56am, no longer listed in squeue -u pterry
squeue -u pterry
# initially, got a 'PD' status

cd /work/amundsen/pterry/Trin20Tut
ls -l
less job.1972371.err  # 0 bytes
/var/spool/slurmd/job1972371/slurm_script: line 17: makeblastdb: command not found
job.1972371.err (END) 
# Q: can't find makeblastdb ???????????????????????????????
# perhaps, need module blast ??????????????????
STOPPED
modules avail
module spider blast

less job.1972371.out  # 0 bytes

# retry slurm with 
module load blast/2.2.9
# added to slurm file.
cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing/tut
## TO fix script file, done
scp slurm_8Trinitymakeblastdbexampdatacrane.sh pterry@crane.unl.edu:/home/amundsen/pterry/scripts/
ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /home/amundsen/pterry/scripts
ls -al
sbatch slurm_8Trinitymakeblastdbexampdatacrane.sh 1972627 2:53pm => 3:03pm, no longer listed in squeue -u pterry
squeue -u pterry
cd /work/amundsen/pterry/Trin20Tut
ls -l
less job.1972627.out  # 0 bytes
less job.1972627.out  # 290 bytes
Building a new DB, current time: 08/26/2015 14:54:45
New DB name:   S_pombe_refTrans.fasta
New DB title:  S_pombe_refTrans.fasta
Sequence type: Nucleotide
Keep Linkouts: T
Keep MBits: T
Maximum file size: 1000000000B
Adding sequences from FASTA; added 5163 sequences in 0.619704 seconds.
job.1972627.out (END) 
# new .nhr, .nin, .nsq files in /work/amundsen/pterry/Trin20Tut dir.

10. Run megablast to align the known transcripts to the Trinity assembly:
# create slurm file to accomplish
scp slurm_10Trinityblastnexampdatacrane.sh pterry@crane.unl.edu:/home/amundsen/pterry/scripts/
ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /home/amundsen/pterry/scripts
ls -al
sbatch slurm_10Trinityblastnexampdatacrane.sh 1972739 3:47pm => 3:55pm, no longer listed in squeue -u pterry
cd /work/amundsen/pterry/Trin20Tut
ls -l
job.1972739.err  # 0 bytes
job.1972739.out  # 0 bytes
less Trinity_vs_S_pombe_refTrans.blastn
TR1|c0_g1_i1    SPBC16E9.06c_T0 100.00  309     0       0       219     527     1       309     4e-163    571
TR2|c0_g1_i1    SPCC777.11_T0   100.00  387     0       0       228     614     1       387     0.0       715
TR3|c0_g1_i1    SPAC1556.01c_T0 100.00  298     0       0       1       298     3406    3109    2e-157    551
...
TR5742|c0_g2_i1 SPAC22H10.02_T0 100.00  417     0       0       53      469     1       417     0.0       771
(END) 
Trinity_vs_S_pombe_refTrans.blastn 
# Q: which colm is e value, looks like perhaps colm 11 ???????????????????????

11.  Once megablast has completed, run the script below to examine the length coverage of top database hits: 
# create slurm file to accomplish
scp slurm_11Trinitylengcovexampdatacrane.sh pterry@crane.unl.edu:/home/amundsen/pterry/scripts/
ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /home/amundsen/pterry/scripts
ls -al
sbatch slurm_11Trinitylengcovexampdatacrane.sh 1973257 10:27pm => 10:27pm, no longer listed in squeue -u pterry
squeue -u pterry
cd /work/amundsen/pterry/Trin20Tut
ls -l
job.1973257.err  # 0 bytes  # when changed 'blastn' file name
Error, cannot open file Trinity_vs_S_pombe_genes.blastn at /util/opt/trinity/2.0/gcc/4.8/util/analyze_blastPlus_topHit_coverage.pl line 49.
job.1973226.err (END) 
# perhaps Trinity_vs_S_pombe_genes.blastn from http://trinityrnaseq.github.io/trinity_rnaseq_tutorial.html is a typo, perhaps should be Trinity_vs_S_pombe_refTrans.blastn
# anyway try it, fix slurm file, retry
job.1973257.out
#hit_pct_cov_bin        count_in_bin    >bin_below
100     3398    3398
90      193     3591
80      160     3751
70      202     3953
60      217     4170
50      200     4370
40      159     4529
30      144     4673
20      76      4749
10      15      4764
job.1973257.out (END) 
# Q: how understand this output ???????????????????????????

12.  Examine the number of input RNA-Seq reads that are well represented by the transcriptome assembly. Trinity provides a script ‘alignReads.pl’ that executes Bowtie to align the left and right fragment reads separately to the Trinity contigs and then groups the reads together into pairs while retaining those single read alignments that are not found to be properly paired with their mate. Run ‘alignReads.pl’ by:

# create slurm file to accomplish
scp slurm_12Trinityexampdatacrane.sh pterry@crane.unl.edu:/home/amundsen/pterry/scripts/
ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /home/amundsen/pterry/scripts
ls -al
sbatch slurm_12Trinityexampdatacrane.sh 1973323 11:39pm => 10:27pm, no longer listed in squeue -u pterry
squeue -u pterry
cd /work/amundsen/pterry/Trin20Tut
ls -al
job.1973323.err  # 128 bytes
/var/spool/slurmd/job1973323/slurm_script: line 18: /util/opt/trinity/2.0/gcc/4.8/util/alignReads.pl: No such file or directory
job.1973323.err (END) 
# Note: don't find file alignReads.pl in dir /util/opt/trinity/2.0/gcc/4.8.2/util
# as step 12 is expecting ????????????????????????????????????????????
job.1973323.out  # 0 bytes

13.
# Looks like file to run this step is available, but need step 12 to work 1st ????????????????????????????????????????????????

Abundance estimation using RSEM
14. Don't follow ?????????????????????????????????????????????
15-18.

08/27/15:
15.
# Don't see 'RSEM_util dir containing run_RSEM_align_n_estimate.pl ????????
# guess, could set up a slurm for say step 15, verify if can locate this file or not.
scp slurm_15Trinityexampdatacrane.sh pterry@crane.unl.edu:/home/amundsen/pterry/scripts/
ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /home/amundsen/pterry/scripts
ls -al
sbatch slurm_15Trinityexampdatacrane.sh 1974828  11:55pm => 10:27pm, no longer listed in squeue -u pterry
squeue -u pterry
cd /work/amundsen/pterry/Trin20Tut
ls -al
less job.1974828.err # 153 bytes
/var/spool/slurmd/job1974828/slurm_script: line 17: /util/opt/trinity/2.0/gcc/4.8/util/RSEM_util/run_RSEM_align_n_estimate.pl: No such file or directory
job.1974828.err (END) 
# as anticipated, could not find this file.
# looks like I **send message to support site** concerning missing files for steps 15, 12. ??????????????????????????????
# so currently, can't run 12, 13, 15 - 18, 19 to end without 15 & 12.

19.
# using RSEM output, so RSEM needs to work to do this step ???????????????
#######################################################################
08/29/15: see 08/29/15 in /Users/bterry/githubstuf/githubcomments.txt

# practice update, testing git/github procedure from pro.

# practice update, testing git/github procedure from macbook.
# bit more edit.
########################################################################

09/02/15:
# last night, submitted Q: trinityrnaseq-2.0.6.tar.gz lacks some of the '.pl' files present in earlier versions? Submitted to 
https://groups.google.com/forum/#!forum/trinityrnaseq-users

# *******Response*******:
Hi Pterry
You can find the newer version at:
$TRINITY_HOME/util/align_and_estimate_abundance.pl

This should do the same thing. The instructions are at:
http://trinityrnaseq.github.io/analysis/abundance_estimation.html
# broken link 12/05/15 ?????????????????????????
Thanks, Mark

# So, Some changes from http://trinityrnaseq.github.io/trinity_rnaseq_tutorial.html

# so now, need digest new info in these instructions, proceed. I note, looks like edgeR not part of this new site,
http://trinityrnaseq.github.io/analysis/abundance_estimation.html

# one possible approach, rather than step 12 from 
http://trinityrnaseq.github.io/trinity_rnaseq_tutorial.html
# go to new tutorial, 'Example usage', and follow rec. there. That is, 

It is useful to first run align_and_estimate_abundance.pl to only prep your reference database for alignment, using --prep_reference, and then subsequently running it on each of your sets of reads in parallel to obtain sample-specific abundance estimates.

# so this the 1st two example commands there.

## Just prepare the reference for alignment and abundance estimation
#
#    ./align_and_estimate_abundance.pl --transcripts Trinity.fasta --est_method RSEM --aln_method bowtie --trinity_mode --prep_reference


# Q: Is this starting with Trinity.fasta and S_pombe_refTrans.fasta ??????? Perhaps no 'blastn' like in 9, 10 of 
# So to run this, perhaps pattern as in step 11 from http://trinityrnaseq.github.io/trinity_rnaseq_tutorial.html  ????????????
# Q: but how knows about the ref, S_pombe_refTrans.fasta, no argument for '--prep_reference'   ??????????????

# perhaps write slurm to do, see if runs, 
# ck prev slurm for needed modules ???????????

cd /work/amundsen/pterry/Trin20Tut

$TRINITY_HOME/util/align_and_estimate_abundance.pl --transcripts trinity_out_dir/Trinity.fasta --est_method RSEM --aln_method bowtie --trinity_mode 

09/06/15:
# but wait, start again with:

STOPPED

http://trinityrnaseq.github.io/index.html

09/07/15:
# perhaps 1st, try run 'runMe.sh', get better understanding of Trinity system ??????????
# then, try run some of the 'Downstream analyses' alternatives ???????
-- RSEM, eXpress & IGV
--edgeR, ...,   clarify 'note' before toc, biol'l reps, independently  ??????????????????, looks like run RESM before this (generating exp'n values matrices) ?????????
--Transdecoder ???
--Trinotate ????
--full length ...  ???????????

git add BdactyloidesthruGSEA081615.txt
git commit -m "update 09/07/15 BdactyloidesthruGSEA081615.txt from pro"
git push origin master
git remote -v

09/08/15:
cd ~/planets
git pull origin master

# from pro laptop, looking at trinityrnaseq-2.0.6.tar.gz expansion on pro laptop, run runMeminuseXpress.sh from following dir on crane: /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing/trinityrnaseq-2.0.6/sample_data/test_Trinity_Assembly
# initially here, run from 'shell'.
# place slurm scripts in 'testing' dir in this path.
# 
ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /work/amundsen/pterry/Trin20Tut/trinity_out_dir
mv Trinity.fasta Trinity.fasta_pre090815
# @: how find test_Trinity_Assembly dir on crane, Found
cd /util/opt/trinity/2.0/gcc/4.8/sample_data/test_Trinity_Assembly
srun --pty $SHELL
runMe.sh
./runMe.sh
# Q: what happened/or didn't ??????????????????????

09/09/15:
# What to try? 
# in runMe.sh script, trinity command using 'fq.gz' files, so why need gunzip commands preceding ????????????????
# Q: question where new Trinity.fasta will appear, if just run the trinity command directly ??????????????
# since in /util/opt/trinity/2.0/gcc/4.8/sample_data/test_Trinity_Assembly, in crane installation dir, would like to proceed if do, without messing up the installation (ck Adam ???????????????????????????)
# --output <string>, so could direct output, 
# note: it says, must include 'trinity' in the name as a safety precaution!
# so, if after adam, ok to try, then say output to /work/amundsen/pterry/Trin20Tut/trinity_out_dir  ?????????????

09/10/15:
ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /util/opt/trinity/2.0/gcc/4.8/sample_data/test_Trinity_Assembly
srun --pty $SHELL
# srun --pty --ntasks-per-node=4 --mem 10gb $SHELL
module load compiler/gcc/4.8
module load bowtie/1.1
module load samtools/1.2
module load trinity/2.0


#######################################################
##  Run Trinity to Generate Transcriptome Assemblies ##
#######################################################
../../Trinity --seqType fq --max_memory 2G --left reads.left.fq.gz,reads2.left.fq.gz --right reads.right.fq.gz,reads2.right.fq.gz --SS_lib_type RF --output /work/amundsen/pterry/Trin20Tut/trinity_out_dir/Trinity091015.fasta --CPU 4
# FAILS, still trying to write to /util/opt/trinity/2.0/gcc/4.8/sample_data/test_Trinity_Assembly, which is read only.
# so fix as per my handwritten steps, try again.

09/11/15:
# 1. Give full path to trinity pgm when run
# 2. remove '--output' parameter from trinity run command
# 3. copy /util/opt/trinity/2.0/gcc/4.8/sample_data/test_Trinity_Assembly dir. to /work/amundsen/pterry/Trin20Tut dir.
ssh -Y pterry@crane.unl.edu
# Rrq096mN
srun --pty $SHELL
cd /work/amundsen/pterry/Trin20Tut
cp -r /util/opt/trinity/2.0/gcc/4.8/sample_data/test_Trinity_Assembly .

[pterry@c1523.crane Trin20Tut]$ cp /util/opt/trinity/2.0/gcc/4.8/sample_data/test_Trinity_Assembly .
cp: omitting directory `/util/opt/trinity/2.0/gcc/4.8/sample_data/test_Trinity_Assembly'
[pterry@c1523.crane Trin20Tut]$ 
# Q: why failed ????????????????????????????

philip-terry:test091115 bterry$ cp -r /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing/trinityrnaseq-2.0.6/sample_data/test_Trinity_Assembly .
philip-terry:test091115 bterry$ 
philip-terry:test091115 bterry$ ls -al
total 0
drwxr-xr-x   3 bterry  staff  102 Sep 11 12:40 .
drwxr-xr-x  14 bterry  staff  476 Sep 11 11:59 ..
drwxr-xr-x@ 15 bterry  staff  510 Sep 11 12:40 test_Trinity_Assembly
philip-terry:test091115 bterry$ 
# so worked on test on 'pro'
# ready to try on 'crane'


ssh -Y pterry@crane.unl.edu
# Rrq096mN
srun --pty $SHELL
cd /work/amundsen/pterry/Trin20Tut
cp -r /util/opt/trinity/2.0/gcc/4.8/sample_data/test_Trinity_Assembly .
ls -al
exit
# appears worked ok.
# cd /util/opt/trinity/2.0/gcc/4.8  ## has trinity executable 
srun --pty $SHELL
module load compiler/gcc/4.8
module load bowtie/1.1
module load samtools/1.2
module load trinity/2.0

# 4. cd to /work/amundsen/pterry/Trin20Tut/test_Trinity_Assembly, run trinity command from this dir.
cd /work/amundsen/pterry/Trin20Tut/test_Trinity_Assembly
/util/opt/trinity/2.0/gcc/4.8/Trinity --seqType fq --max_memory 2G --left reads.left.fq.gz,reads2.left.fq.gz --right reads.right.fq.gz,reads2.right.fq.gz --SS_lib_type RF --CPU 4
# error, checked Adam, HCC, thinks need allow more than 1G ram available with std call to SHELL, so retry as follows:

ssh -Y pterry@crane.unl.edu
# Rrq096mN
# check dir, if need clean up qqch before rerun
cd /work/amundsen/pterry/Trin20Tut/test_Trinity_Assembly
ls -al
rm -rf trinity_out_dir
rm *.fq
rm *.readcount
ls -al
srun --pty --ntasks-per-node=4 --mem 4gb $SHELL
module load compiler/gcc/4.8
module load bowtie/1.1
module load samtools/1.2
module load trinity/2.0
cd /work/amundsen/pterry/Trin20Tut/test_Trinity_Assembly
/util/opt/trinity/2.0/gcc/4.8/Trinity --seqType fq --max_memory 2G --left reads.left.fq.gz,reads2.left.fq.gz --right reads.right.fq.gz,reads2.right.fq.gz --SS_lib_type RF --CPU 4
# started 11:46pm => 11:48pm, done.
exit
cd trinity_out_dir
less Trinity.fasta
>TR1|c0_g1_i1 len=281 path=[273:0-146 274:147-280] [-1, 273, 274, -2]
GCCAGTAGAAATGTGGACATGATAAGCCATCGTGTGGCCAAACTAGAGGAGACAAGGAAC
GCTTTTCATCCTCTGTTTTGGAGCCAGGCCATGTCAGTAGCTTTCAGTGGAAAGTCTGAG
GGGACATTTGACTGTCCATGGCTGTAGAGCAGGCACACTGTCCAGGCCGCCTAACTGTTT
GACCAGCACTAATGAAATGTCAGTGTCCTGCACTCACTGTCTGCATGTTGTTCAAATGAT
TTTCTGCATGGTGCTTTGACTTTGGCTGTCCCATGACCCAG
>TR1|c2_g1_i1 len=518 path=[565:0-25 566:26-40 572:41-109 571:110-255 569:256-279 570:280-517] [-1, 565, 566, 572, 571, 569, 570, -2]
CCAGTATGAGTGCTGGGTGTGTGTGTGTTGTGTGTTACCTGTGCATTTGTGTATTATGTG
TGTGCAGGAGAGGAGGTGAGGGCATGCATGTGCATGGGTGTGTGCATGTTGCATGTCTGT
GTGGGTGTGGGTGTGGTGGGGTACTATGGCCTGGAATGGTGATTCAGCCAGCTCAGTGCA
CTTCCCTGTGGTGACTTTTTAGAAGTGTGCAAGTGAGTAGGAGAAGGAAGTGCAAGATGG
CAGCACAGTGTGTTTGATTAACAGTAACACTTTAACTTGTATGATCACTTTTTCTCAGGT
GCTCTGAGTCAGGTGTGGGGCTGACATCATCACTTTCTAGCCAGGTCTCCCTCACAGTAT
CCTTAGAATTTCAGAACTTTGAGGTGTCACAAAGTATGAGCTAAGAGCTAGACAGATTTT
TTTCCTTTTCCAGCGTAATGATGGTTGTCTTAACCAAAACTGGGGGGGGGGGGGATTTTG
TTGTACCCCCTGGTGGTCTTCATTTGAGTGATTTTGAT
>TR1|c3_g1_i1 len=360 path=[495:0-57 501:58-225 487:226-249 500:250-323 498:324-359] [-1, 495, 501, 487, 500, 498, -2]
AAGTGAGCCGGCATTTCCATCAGGTACCTGTGGCTGGTGGCTCCCTCCACGGGGCTGGCT
ATGTAGCTCCCATATGTCCCTTAGAGAGTCTGTCATCCTCTTTACTTTGTCACTAACCCC
TTGTCTTAACCAAGCATCATGTGGGCAAAGATGCAGTTTTCCTTTATTAGATGGCCTGGG
TCTAGATACGCTGGTGGTGGACTTGCCTCACAGGGTTCAGAGTGCTCAGGGAGCTTCCTA
Trinity.fasta


# TO DO: recheck doc for meaning of the fields ??????????????
# see in http://trinityrnaseq.github.io/index.html, 'Output of Trinity' section.
# now run following to 
Obtain basic stats for the number of genes and isoforms and contiguity of the assembly by running:

% $TRINITY_HOME/util/TrinityStats.pl trinity_out_dir/Trinity.fasta

# so,
ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /work/amundsen/pterry/Trin20Tut/test_Trinity_Assembly
ls -al
srun --pty --ntasks-per-node=4 --mem 4gb $SHELL
module load compiler/gcc/4.8
module load bowtie/1.1
module load samtools/1.2
module load trinity/2.0
/util/opt/trinity/2.0/gcc/4.8/util/TrinityStats.pl trinity_out_dir/Trinity.fasta
################################
## Counts of transcripts, etc.
################################
Total trinity 'genes':	67
Total trinity transcripts:	94
Percent GC: 49.44

########################################
Stats based on ALL transcript contigs:
########################################

	Contig N10: 8543
	Contig N20: 8062
	Contig N30: 7195
	Contig N40: 5534
	Contig N50: 3918

	Median contig length: 496.5
	Average contig: 1666.59
	Total assembled bases: 156659


#####################################################
## Stats based on ONLY LONGEST ISOFORM per 'GENE':
#####################################################

	Contig N10: 8757
	Contig N20: 7195
	Contig N30: 5905
	Contig N40: 5399
	Contig N50: 3745

	Median contig length: 378
	Average contig: 1057.79
	Total assembled bases: 70872
# apparently http://trinityrnaseq.github.io/index.html, 'Output of Trinity' section showing results for different input data ???????????????????



[pterry@c0125.crane test_Trinity_Assembly]$ 




09/12/15:
# perhaps next, from runMe.sh, try 'use RSEM to estimate read abundance', run from /work/amundsen/pterry/Trin20Tut/test_Trinity_Assembly
# see ref: http://trinityrnaseq.github.io/analysis/abundance_estimation.html
# note: 1st 'note', Q: what is 'preparation of ref', perhaps just align all the reads to the ref ????????????????????
# ... subsequently run 'align_and_estimate_abundance.pl' on 'on each of your sets of reads in parallel to obtain sample-specific abundance estimates' ???????
# for 95C1-3,T1-3, would their be 2 runs or 6 runs ?????????????????????
# a ***guess***, cat biol reps, then run 'align_and_estimate_abundance.pl' on each of these ?????????????????????????
# appears runMe.sh example, just cat'd all the reads in one file (actually 2, left & right) ???????????????????????????????
# looking thru 'align_and_estimate_abundance.pl'
# Alignment output (bam) section
# The alignment step generates the file **bowtie.bam**, which is then fed directly into either RSEM or eXpress. Note, the alignment step also generates a **bowtie.csorted.bam** file, which is a coordinate-sorted bam file that can be used for visualization using IGV
# perhaps split into 2 steps, see what outputs are ?????????????
# RSEM output
# The RSEM computation generates two primary output files containing the abundance estimation information:
RSEM.isoforms.results  : EM read counts per Trinity transcript
RSEM.genes.results     : EM read counts on a per-Trinity-component (aka... gene) basis, 'gene' used loosely here.
# The output for the isoforms file looks like so:
...
# and the genes file provides expression results on a per-Trinity component basis:
...
# 


09/15/15:
ssh -Y pterry@crane.unl.edu
# Rrq096mN
#cd /work/amundsen/pterry/Trin20Tut/test_Trinity_Assembly
# srun --pty --ntasks-per-node=4 --mem 4gb $SHELL
cd /util/opt/trinity/2.0/gcc/4.8/sample_data
ls -al
cd test_full_edgeR_pipeline
ls -al
cd rnaseq_reads
ls -al
cd /work/amundsen/pterry/Trin20Tut
srun --pty $SHELL
cp -r /util/opt/trinity/2.0/gcc/4.8/sample_data/test_full_edgeR_pipeline .
ls -al
cd test_full_edgeR_pipeline/rnaseq_reads
pwd
ls -al
exit
srun --pty --ntasks-per-node=4 --mem 4gb $SHELL
## /util/opt/trinity/2.0/gcc/4.8/Trinity --seqType fq --max_memory 2G --left reads.left.fq.gz,reads2.left.fq.gz --right reads.right.fq.gz,reads2.right.fq.gz --SS_lib_type RF --CPU 4

module load compiler/gcc/4.8
module load bowtie/1.1
module load samtools/1.2
module load trinity/2.0
cd /work/amundsen/pterry/Trin20Tut/test_full_edgeR_pipeline/rnaseq_reads
pwd
ls -al
/util/opt/trinity/2.0/gcc/4.8/Trinity --seqType fq --max_memory 2G --left Sp_ds.10k.left.fq.gz,Sp_hs.10k.left.fq.gz,Sp_log.10k.left.fq.gz,Sp_plat.10k.left.fq.gz --right Sp_ds.10k.right.fq.gz,Sp_hs.10k.right.fq.gz,Sp_log.10k.right.fq.gz,Sp_plat.10k.right.fq.gz --SS_lib_type RF --CPU 4
# 11:04pm => 11:09pm.
exit
pwd
cd /work/amundsen/pterry/Trin20Tut/test_full_edgeR_pipeline/rnaseq_reads
ls -al
cd trinity_out_dir
ls -al
less Trinity.fasta
>TR1|c0_g1_i1 len=783 path=[761:0-782] [-1, 761, -2]
ACCAAGACGAAATGATTCGTGCTGGTCGTCTTTCTCACCGCTACAAGGGTATTGGTGAGT
GTTTCAAGCGTACTGCTGCTGAAGAAGGTGTTATTTCCCTTTGGAGAGGTAATACCGCTA
ATGTCTTACGTTACTTCCCCACTCAGGCCTTGAACTTTGCTTTCAAGGATAAATTTAAGA
AGATGTTTGGTTACAAGAAGGAAAGGGATGGTTATGCTAAATGGTTTGCCGGTAATTTAG
CCTCTGGTGGTGCTGCTGGTGCCGCTTCCCTTTTGTTTGTCTACTCTCTTGACTATGCCC
GTACCCGTCTTGCCAATGATGCCAAATCCGCCAAGAAGGGAGGTGAACGTCAATTTAACG
GTTTGGTCGATGTCTATCGTAAGACCTATCGTTCTGATGGTTTACGTGGTTTGTACCGTG
GTTTTGGCCCTTCTGTTGTCGGTATTGTTGTTTACCGTGGTTTGTACTTCGGTATGTATG
ATACCTTGAAACCCGTCGTTTTGGTTGGTCCTTTGGAGGGCAACTTCTTGGCCTCCTTCC
TTCTCGGTTGGGCCGTTACCACTGGTTCTGGTGTTGCTTCTTATCCTCTTGATACCATCC
GTCGTCGTATGATGATGACATCTGGTGAAGCCGTCAAGTATAGCTCCTCCTTTGAATGTG
GTCGTCAAATCCTCGCCAAGGAAGGTGCTCGTTCTTTCTTCAAGGGTGCCGGTGCCAACA
TTCTTCGTGGTGTTGCTGGAGCTGGTGTCCTTTCCATTTATGACCAAGTTCAACTTTTGA
TGT
>TR1|c1_g1_i1 len=299 path=[277:0-298] [-1, 277, -2]
GTTTTCCTTTCATATCATCATTTTCTTGTTGTTGTGCTAAGGCTTCATCTCTTTATCTCT
TTTTTTTTCGTACATTTGAACTTATCTATTTACCAGAATTAGTGAAAAATGGCTACTTCA
TCTGCTGCCGCTGCTGCTAGCACCCCCGTGAATGCAAACACCATCACTGAAACAAAGAAC
TCTACTTTCTTCTTTGATTTCATGATGGGTGGTGTTTCTGCTGCTGTATCTAAAACCGCT
GCCGCTCCCATTGAGCGTGTCAAGCTTCTCATTCAAAACCAAGACGAAATGATTCGTGC
>TR1|c2_g1_i1 len=322 path=[300:0-321] [-1, 300, -2]
TTTTGATGTTCGGCAAGAAGTTCTAATTGCCCTAATGTCTTTTCTTTTCAATTGCTTTGC
Trinity.fasta 
srun --pty --ntasks-per-node=4 --mem 4gb $SHELL
module load compiler/gcc/4.8
module load bowtie/1.1
module load samtools/1.2
module load trinity/2.0
/util/opt/trinity/2.0/gcc/4.8/util/TrinityStats.pl trinity_out_dir/Trinity.fasta

# think next, do from http://trinityrnaseq.github.io/analysis/abundance_estimation.html
# p-1, two steps, 

09/16/15:
# 1. Just prepare the reference for alignment and abundance estimation

ssh -Y pterry@crane.unl.edu
# Rrq096mN
srun --pty --ntasks-per-node=4 --mem 4gb $SHELL
module load compiler/gcc/4.8
module load bowtie/1.1
module load samtools/1.2
module load trinity/2.0
cd /work/amundsen/pterry/Trin20Tut/test_full_edgeR_pipeline/rnaseq_reads

/util/opt/trinity/2.0/gcc/4.8/util/align_and_estimate_abundance.pl --transcripts trinity_out_dir/Trinity.fasta --est_method RSEM --aln_method bowtie --trinity_mode --prep_reference

exit
# look for 'prep reference'
ls -al
cd trinity_out_dir
ls -al
# ran from 'rnaseq_reads dir, but bunch of stuff in trinity_out_dir dir. ?????????????????????????
Only prepping reference. Stopping now.
# so looks like may have completed ok.

# 2. Run the alignment and abundance estimation (assumes reference has already been prepped, errors-out if prepped reference not located.)

# Q: will there be an issue with locating needed files for alignment and abundance estimation ??????????????????

ssh -Y pterry@crane.unl.edu
# Rrq096mN
srun --pty --ntasks-per-node=4 --mem 4gb $SHELL
module load compiler/gcc/4.8
module load bowtie/1.1
module load samtools/1.2
module load trinity/2.0

cd /work/amundsen/pterry/Trin20Tut/test_full_edgeR_pipeline/rnaseq_reads

/util/opt/trinity/2.0/gcc/4.8/util/align_and_estimate_abundance.pl --transcripts trinity_out_dir/Trinity.fasta --seqType fq --left Sp_ds.10k.left.fq --right Sp_ds.10k.right.fq --est_method RSEM --aln_method bowtie --trinity_mode

exit
ls -al
cd trinity_out_dir
ls -al

# ok, find a 
-rw-r--r-- 1 pterry amundsen   29693 Sep 16 12:12 RSEM.isoforms.results
file in /work/amundsen/pterry/Trin20Tut/test_full_edgeR_pipeline/rnaseq_reads dir.
# Q: if have 3 more sets of reads to run (http://trinityrnaseq.github.io/analysis/abundance_estimation.html, 'Align Reads and Estimate Abundance' section, what do you do for RSEM.isoforms.results & preceding files, rename, ?????????????????????????
less RSEM.isoforms.results
# Q: how to proceed ?????????????
# note: In http://trinityrnaseq.github.io/analysis/diff_expression_analysis.html, section 'Generating Expression Value Matrices', we see multiple sampleA.RSEM.isoform.results files, so here will similarly rename RSEM.isoforms.results file, run other 3 sets of read files with align_and_estimate_abundance.pl. But I note several files created in this align_and_estimate_abundance.pl step, hopefully, only changing name of RSEM.isoforms.results will not be a problem ??????????????????

# pwd => /work/amundsen/pterry/Trin20Tut/test_full_edgeR_pipeline/rnaseq_reads
# or perhaps cp RSEM.isoforms.results to ds.RSEM.isoforms.results, and RSEM.genes.results to ds.RSEM.genes.results, don't change anything else before running next set read files with align_and_estimate_abundance.pl ??????????????????????????
cp RSEM.isoforms.results ds.RSEM.isoforms.results
cp RSEM.genes.results ds.RSEM.genes.results

# next, run 'hs' sample.
ssh -Y pterry@crane.unl.edu
# Rrq096mN
srun --pty --ntasks-per-node=4 --mem 4gb $SHELL
module load compiler/gcc/4.8
module load bowtie/1.1
module load samtools/1.2
module load trinity/2.0

cd /work/amundsen/pterry/Trin20Tut/test_full_edgeR_pipeline/rnaseq_reads

/util/opt/trinity/2.0/gcc/4.8/util/align_and_estimate_abundance.pl --transcripts trinity_out_dir/Trinity.fasta --seqType fq --left Sp_hs.10k.left.fq --right Sp_hs.10k.right.fq --est_method RSEM --aln_method bowtie --trinity_mode
[pterry@c0406.crane rnaseq_reads]$ /util/opt/trinity/2.0/gcc/4.8/util/align_and_estimate_abundance.pl --transcripts trinity_out_dir/Trinity.fasta --seqType fq --left Sp_hs.10k.left.fq --right Sp_hs.10k.right.fq --est_method RSEM --aln_method bowtie --trinity_mode
CMD: touch RSEM.isoforms.results.ok
# so ***did not run*** ????????????????????????
# so try removing some files ???????????????????????????????
rm -rf RSEM.stat
rm bowtie.bam
rm bowtie.bam.ok
rm RSEM.genes.results
rm RSEM.isoforms.results
rm RSEM.isoforms.results.ok
exit
ls -al
# Q: what to think of this removal step ???????????**********????????????

cp RSEM.isoforms.results hs.RSEM.isoforms.results
cp RSEM.genes.results hs.RSEM.genes.results

09/17/15:
# next, run 'log' sample.
ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /work/amundsen/pterry/Trin20Tut/test_full_edgeR_pipeline/rnaseq_reads
rm -rf RSEM.stat
rm bowtie.bam
rm bowtie.bam.ok
rm RSEM.genes.results
rm RSEM.isoforms.results
rm RSEM.isoforms.results.ok
srun --pty --ntasks-per-node=4 --mem 4gb $SHELL
module load compiler/gcc/4.8
module load bowtie/1.1
module load samtools/1.2
module load trinity/2.0

cd /work/amundsen/pterry/Trin20Tut/test_full_edgeR_pipeline/rnaseq_reads

/util/opt/trinity/2.0/gcc/4.8/util/align_and_estimate_abundance.pl --transcripts trinity_out_dir/Trinity.fasta --seqType fq --left Sp_log.10k.left.fq --right Sp_log.10k.right.fq --est_method RSEM --aln_method bowtie --trinity_mode
exit
ls -al
cp RSEM.isoforms.results log.RSEM.isoforms.results
cp RSEM.genes.results log.RSEM.genes.results

# next, run 'plat' sample.
ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /work/amundsen/pterry/Trin20Tut/test_full_edgeR_pipeline/rnaseq_reads
rm -rf RSEM.stat
rm bowtie.bam
rm bowtie.bam.ok
rm RSEM.genes.results
rm RSEM.isoforms.results
rm RSEM.isoforms.results.ok
srun --pty --ntasks-per-node=4 --mem 4gb $SHELL
module load compiler/gcc/4.8
module load bowtie/1.1
module load samtools/1.2
module load trinity/2.0

cd /work/amundsen/pterry/Trin20Tut/test_full_edgeR_pipeline/rnaseq_reads

/util/opt/trinity/2.0/gcc/4.8/util/align_and_estimate_abundance.pl --transcripts trinity_out_dir/Trinity.fasta --seqType fq --left Sp_plat.10k.left.fq --right Sp_plat.10k.right.fq --est_method RSEM --aln_method bowtie --trinity_mode
ls -al
cp RSEM.isoforms.results plat.RSEM.isoforms.results
cp RSEM.genes.results plat.RSEM.genes.results
ls -al

# Q: section 'How many expressed genes or transcripts do I have?'
# Q: Would like to understand how useful this section might be ??????????

09/18/15:
# now from 'http://trinityrnaseq.github.io/analysis/diff_expression_analysis.html'
p-1, section,
'Generating Expression Value Matrices'

ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /work/amundsen/pterry/Trin20Tut/test_full_edgeR_pipeline/rnaseq_reads
ls -al
srun --pty --ntasks-per-node=4 --mem 4gb $SHELL
module load compiler/gcc/4.8
module load bowtie/1.1
module load samtools/1.2
module load trinity/2.0

cd /work/amundsen/pterry/Trin20Tut/test_full_edgeR_pipeline/rnaseq_reads

/util/opt/trinity/2.0/gcc/4.8/util/abundance_estimates_to_matrix.pl --est_method RSEM  --out_prefix Trinity_trans ds.RSEM.isoforms.results hs.RSEM.isoforms.results log.RSEM.isoforms.results plat.RSEM.isoforms.results
exit
ls -al
# result: got one expected result, not the other ???????????????
# that is, ERRORs after got
Trinity_trans.counts.matrix  : matrix of fragment raw counts
-rw-r--r-- 1 pterry amundsen   16684 Sep 18 15:31 Trinity_trans.counts.matrix

# i.e., did not get the following expected file, i.e., got '0' bytes in
Trinity_trans.TMM.fpkm.matrix : TMM-normalized FPKM expression values
# p-2, reading along, says using code in edgeR, but ***NOT*** LOADING edgeR till next section, 'Identifying Differentially Expressed Transcripts' ????****?????

# Q: when Adam returns next week, try troubleshoot above error ????***????????

09/22/15:
p-2 'Identifying Differentially Expressed Transcripts' section.
ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /work/amundsen/pterry/Trin20Tut/test_full_edgeR_pipeline/rnaseq_reads
ls -al
less Trinity_trans.counts.matrix
        ds.RSEM hs.RSEM log.RSEM        plat.RSEM
TR24|c0_g1_i1   3.00    19.00   0.00    0.00
TR108|c0_g1_i1  2.00    0.00    1.00    2.00
TR30|c0_g1_i1   1.00    0.00    0.00    1.00
TR197|c0_g1_i1  2.00    0.00    0.00    4.00
Trinity_trans.counts.matrix 

srun --pty --ntasks-per-node=4 --mem 4gb $SHELL
module load R/3.2
cd /work/amundsen/pterry/Trin20Tut/test_full_edgeR_pipeline/rnaseq_reads
R   # R ver 3.2.1
source("http://bioconductor.org/biocLite.R")
# Q: ck Adam: 'create personal library ...(y/n)'  # try 'y'

> source("http://bioconductor.org/biocLite.R")
Warning in install.packages("BiocInstaller", repos = a["BioCsoft", "URL"]) :
  'lib = "/util/opt/R/3.2.1/gcc/4.4.7/lib64/R/library"' is not writable
Would you like to use a personal library instead?  (y/n) y
Would you like to create a personal library
~/R/x86_64-unknown-linux-gnu-library/3.2
to install packages into?  (y/n) y
Error in install.packages("BiocInstaller", repos = a["BioCsoft", "URL"]) : 
  unable to create ‘~/R/x86_64-unknown-linux-gnu-library/3.2’
In addition: Warning message:
In dir.create(userdir, recursive = TRUE) :
  cannot create dir '/home/amundsen/pterry/R/x86_64-unknown-linux-gnu-library', reason 'No such file or directory'
> q()
Save workspace image? [y/n/c]: n
[pterry@c0312.crane rnaseq_reads]$ exit
exit
[pterry@login.crane rnaseq_reads]$ 
# Q: how to proceed ????????????????????????????????????????
# no dir '/home/amundsen/pterry', perhaps I should have created ‘~/R/x86_64-unknown-linux-gnu-library/3.2’, then tried:
source("http://bioconductor.org/biocLite.R")
# Q: ????????????????????????????????????????????????????

biocLite('edgeR')
biocLite('ctc')
biocLite('Biobase')
install.packages('gplots’)
install.packages(‘ape’)

10/07/15:
# After check wi Adam at HCC, to retry:

i) abundance_estimates_to_matrix.pl  ## line 1138 above. probably 
module load R/3.2 1st ??????????????
# perhaps, for now, don't try fix 09/18/15, ''Generating Expression Value Matrices', the failure to get 'Trinity_trans.TMM.fpkm.matrix' output file. Since got 'Trinity_trans.counts.matrix', just proceed to 'Identifying Differentially Expressed Transcripts' section of 'http://trinityrnaseq.github.io/analysis/diff_expression_analysis.html'

ii) Identifying Differentially Expressed Transcripts (must load bioconductor packages from **LOGIN** node) (Adam)

ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /work/amundsen/pterry/Trin20Tut/test_full_edgeR_pipeline/rnaseq_reads
ls -al
module load R/3.2
R  # R ver 3.2.1
source("http://bioconductor.org/biocLite.R")
biocLite('edgeR')  # did all here
biocLite('ctc')  ## did none here
biocLite('Biobase')  ## did none here
install.packages("gplots")
# needed double quotes, when trying to select download site, mouse could not manipulate selection of site, clicked on Berlin, bit later, appears to have done the download ?????????????????????
install.packages("ape")  ## did not ask for dnload site, apparently just did it ?????????????????????
q()
logout

STOPPED

p-3
# 'Identifying DE features: With biological replicates (PREFERRED)'
# **prepare** 'samples_described.txt' file (Q: separator for columns??), scp to '/work/amundsen/pterry/Trin20Tut/test_full_edgeR_pipeline/rnaseq_reads' dir on crane.

cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing
## TO fix the file, done
scp samples_described.txt pterry@crane.unl.edu:/work/amundsen/pterry/Trin20Tut/test_full_edgeR_pipeline/rnaseq_reads

ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /work/amundsen/pterry/Trin20Tut/test_full_edgeR_pipeline/rnaseq_reads
ls -al

srun --pty --ntasks-per-node=4 --mem 4gb $SHELL

module load compiler/gcc/4.8
module load bowtie/1.1
module load samtools/1.2
module load trinity/2.0

module load R/3.2
cd /work/amundsen/pterry/Trin20Tut/test_full_edgeR_pipeline/rnaseq_reads

# **to fix**: next command wi correct dir on crane
/util/opt/trinity/2.0/gcc/4.8/Analysis/DifferentialExpression/run_DE_analysis.pl --matrix counts.matrix --method edgeR --samples_file samples_described.txt

[pterry@c1923.crane rnaseq_reads]$ /util/opt/trinity/2.0/gcc/4.8/Analysis/DifferentialExpression/run_DE_analysis.pl --matrix counts.matrix --method edgeR --samples_file samples_described.txt
Error, cannot open file counts.matrix at /util/opt/trinity/2.0/gcc/4.8/Analysis/DifferentialExpression/run_DE_analysis.pl line 312.
[pterry@c1923.crane rnaseq_reads]$ 
# perhaps for '--matrix' parameter, change argument to 'Trinity_trans.counts.matrix'
# to try
/util/opt/trinity/2.0/gcc/4.8/Analysis/DifferentialExpression/run_DE_analysis.pl --matrix Trinity_trans.counts.matrix --method edgeR --samples_file samples_described.txt

# apparently ran ????????
exit
ls -al
# see 1 new dir,
drwxr-xr-x 2 pterry amundsen    4096 Oct  7 12:30 edgeR.223987.dir
# bunch files here
[pterry@login.crane rnaseq_reads]$ cd edgeR.223987.dir/
[pterry@login.crane edgeR.223987.dir]$ ls -al
total 244
drwxr-xr-x 2 pterry amundsen  4096 Oct  7 12:30 .
drwxr-xr-x 5 pterry amundsen  4096 Oct  7 12:30 ..
-rw-r--r-- 1 pterry amundsen   973 Oct  7 12:30 Trinity_trans.counts.matrix.ds_rep1_vs_hs_rep1.ds_rep1.vs.hs_rep1.EdgeR.Rscript
-rw-r--r-- 1 pterry amundsen 23081 Oct  7 12:30 Trinity_trans.counts.matrix.ds_rep1_vs_hs_rep1.edgeR.DE_results
-rw-r--r-- 1 pterry amundsen 10420 Oct  7 12:30 Trinity_trans.counts.matrix.ds_rep1_vs_hs_rep1.edgeR.DE_results.MA_n_Volcano.pdf
-rw-r--r-- 1 pterry amundsen   976 Oct  7 12:30 Trinity_trans.counts.matrix.ds_rep1_vs_log_rep1.ds_rep1.vs.log_rep1.EdgeR.Rscript
-rw-r--r-- 1 pterry amundsen 23903 Oct  7 12:30 Trinity_trans.counts.matrix.ds_rep1_vs_log_rep1.edgeR.DE_results
-rw-r--r-- 1 pterry amundsen 10468 Oct  7 12:30 Trinity_trans.counts.matrix.ds_rep1_vs_log_rep1.edgeR.DE_results.MA_n_Volcano.pdf
-rw-r--r-- 1 pterry amundsen   979 Oct  7 12:30 Trinity_trans.counts.matrix.ds_rep1_vs_plat_rep1.ds_rep1.vs.plat_rep1.EdgeR.Rscript
-rw-r--r-- 1 pterry amundsen 22223 Oct  7 12:30 Trinity_trans.counts.matrix.ds_rep1_vs_plat_rep1.edgeR.DE_results
-rw-r--r-- 1 pterry amundsen  9626 Oct  7 12:30 Trinity_trans.counts.matrix.ds_rep1_vs_plat_rep1.edgeR.DE_results.MA_n_Volcano.pdf
-rw-r--r-- 1 pterry amundsen 20468 Oct  7 12:30 Trinity_trans.counts.matrix.hs_rep1_vs_log_rep1.edgeR.DE_results
-rw-r--r-- 1 pterry amundsen 10382 Oct  7 12:30 Trinity_trans.counts.matrix.hs_rep1_vs_log_rep1.edgeR.DE_results.MA_n_Volcano.pdf
-rw-r--r-- 1 pterry amundsen   976 Oct  7 12:30 Trinity_trans.counts.matrix.hs_rep1_vs_log_rep1.hs_rep1.vs.log_rep1.EdgeR.Rscript
-rw-r--r-- 1 pterry amundsen 22619 Oct  7 12:30 Trinity_trans.counts.matrix.hs_rep1_vs_plat_rep1.edgeR.DE_results
-rw-r--r-- 1 pterry amundsen 10543 Oct  7 12:30 Trinity_trans.counts.matrix.hs_rep1_vs_plat_rep1.edgeR.DE_results.MA_n_Volcano.pdf
-rw-r--r-- 1 pterry amundsen   979 Oct  7 12:30 Trinity_trans.counts.matrix.hs_rep1_vs_plat_rep1.hs_rep1.vs.plat_rep1.EdgeR.Rscript
-rw-r--r-- 1 pterry amundsen 23098 Oct  7 12:30 Trinity_trans.counts.matrix.log_rep1_vs_plat_rep1.edgeR.DE_results
-rw-r--r-- 1 pterry amundsen 10107 Oct  7 12:30 Trinity_trans.counts.matrix.log_rep1_vs_plat_rep1.edgeR.DE_results.MA_n_Volcano.pdf
-rw-r--r-- 1 pterry amundsen   982 Oct  7 12:30 Trinity_trans.counts.matrix.log_rep1_vs_plat_rep1.log_rep1.vs.plat_rep1.EdgeR.Rscript
[pterry@login.crane edgeR.223987.dir]$ 

# next, perhaps do 'less' for the 6 'DE_results' files ????
# seeing some small pvals, 'topTags' from edgeR ????????????
# **to do:** scp the 6 'pdf' files to 'pro', display in 'adobe reader'

cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing
#scp pterry@tusker.unl.edu:/work/amundsen/pterry/brachy_dis/blastn_out/blastn_out6_AstolvsBrachydis .

scp pterry@crane.unl.edu:/work/amundsen/pterry/Trin20Tut/test_full_edgeR_pipeline/rnaseq_reads/edgeR.223987.dir/Trinity_trans.counts.matrix.ds_rep1_vs_hs_rep1.edgeR.DE_results.MA_n_Volcano.pdf .

# displayed in adobe reader. Still some Q's ?????????????????

10/08/15:
# attempt to do **trinotate**. and GOseq.
tar xzvf Trinotate-2.0.2.tar.gz
# ok, should be able to use to find where things located when try use on crane.
# /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/trinotate2.0.2/Trinotate-2.0.2

10/10/15:
# Summary of situation as best understand now, check Keenan on what s/w need, then proceed (will need Adam involvement for using 'crane').

# Trinity
# diff'l_expn_analysis.html
p-4 of 8
# dir. edgeR.223987.dir has results:
--has results & volcano plots for 6 combinations of 4 biol'l samples.
# Q: p-5 of 8, is GO_seq using results from edgeR.223987.dir ???????

# New trinotate doc (last couple weeks)
# trinotate.github.io
p-1
# Q: TrinotateWeb => (Trinity/RSEM/Bioconductor)  => Q: relation to edgeR.223987.dir above ???????????????
p-2
S/W:
trinotate
Trinity (Transdecoder, DE with RSEM, Bioconductor)
sqlite
NCBI Blast+
HMMER/PFAM
p-3
Files needed:
Trinity.fasta
Trinity.fasta.transdecoder.pep (Q: Req'd ?????????????)
p-6
syntax for commands
Trinotate Pre-gen'd sqlite db
Loading transcripts, coding regions ???????
p-7
Load blast homologies ????????
TRinotate: output annotation rept.
--trinotate-annotation-report.xls ????***********???????????
p-8
sample data ?????

.../wiki/Running-GOSeq 
p-1
--blastogo ????????????
Extract GO assignments per gene
GO DAG ?????????????????
--trinolate.xls ?????????*********?????????
Run GOSeq
p-2
factor_labeling.txt
GO-seq on DE features
--DE analysis using a trinity assembly
p-7of9
GO enrichment analysis on DE genes [GOAL, me] ????????
CIRCULAR doc.: what is a direct path to what want ?????????????

10/22/15:
# from githubcomments.txt, did
cd ~/planets
git pull origin master

10/26/15:
https://github.com/trinityrnaseq/trinityrnaseq/wiki/Trinity-Differential-Expression
--7, Gene Ontology (GO) Enrichment Analysis on Differentially Expressed Genes
# ***Q***: do I need a ref. genome to accomplish this goal ????????
**Before** running GO-Seq, you must follow the relevant **Trinotate protocol** (see next url ref) to generate the GO assignments leveraged by this process.
https://github.com/trinityrnaseq/trinityrnaseq/wiki/Running-GOSeq
# Gene Ontology Enrichment using Trinotate and GOseq
# Run Trinotate to Generate an Annotation Report
# Use http://trinotate.sf.net[Trinotate] (***broken*** link????) to generate an annotation report ***'trinotate.xls'***, which includes top-matching blast matches from SwissProt (and optionally UniRef) and any corresponding Gene Ontology (GO) assignments from the TrEMBL/SwissProt databases.
# Q: so what to do ?????????
# perhaps go to basic trinotate web site: http://trinotate.github.io/
which on p-7 of 9, section 
# Trinotate: Output an Annotation Report
# outputs: trinotate_annotation_report.xls, an 'xls' report.

# so if try follow this web site, p-3 of 9, shows need for file: Trinity.fasta.transdecoder.pep. ***Instructions*** for generation of this file can be found here: http://transdecoder.github.io/
# Q: ***WHAT*** USE FOR 'target_transcripts.fasta' ??????????????
# Q: how 'transdecoder' output and next section in 'basic trinotate web site' work ????
# 2. Capturing BLAST Homologies
# Q: where get '.trinotate.pep' files ????????????????????
# Q: also 'transdecoder.pep'  ?????????????????????????
# next probably p-5 of 9, section 'Trinotate: Loading Above Results into a Trinotate SQLite Database'
# p-7 of 9, 'xls' file.

# back to transdecoder web page,

10/27/15:
# The latest release of TransDecoder can be found here:
https://github.com/TransDecoder/TransDecoder/releases

# Running TransDecoder
# Predicting coding regions from a transcript fasta file

# Step 1: extract the long open reading frames
TransDecoder.LongOrfs -t target_transcripts.fasta
# Q: what file is target_transcripts.fasta ????????????????????????
# Trinity.fasta, or one of the initial transcript files ???????????

# Step 3: predict the likely coding regions
TransDecoder.Predict -t target_transcripts.fasta [ homology options ]
# Q: again, what file is target_transcripts.fasta ????????????????????????

# perhaps all need, i.e., don't need next section: ????????????
Starting from a genome-based transcript structure GTF file (eg. cufflinks)
p-2 of 5
# section: Sample data and execution
cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/TransDecoderv2.0.1
tar -xzvf TransDecoder-2.0.1.tar.gz

# so yes, a sample_data dir with runMe.sh file
STOPPED

10/28/15:
# TO DO: ck transDecoder-users site before continue
# did, nothing to help me decide what to use for 'target_transcripts.fasta' in following step ???????????????????????????????????????????

10/30/15:
# From TransDecoder-users support site, 'blastp Warning: Sequence contains no data', appears to be saying 'I have used the latest version of Transdecoder and the script "TransDecoder.LongOrfs -t target_transcripts.fasta" on my freshly created Trinity de novo assembly fasta file' => apparently 'target_transcripts.fasta' placeholder means can substitute 'Trinity.fasta' output from running Trinity ???????

# I note in http://trinotate.github.io/, states in section '1. Software Required', 'Trinity (includes TransDecoder...' ???????
# But in 'http://transdecoder.github.io/', at section 'Obtaining TransDecoder
The latest release of TransDecoder can be found **here**.

# TO DO: at http://transdecoder.github.io/, 
i) have Adam dnload, load TransDecoder.
ii) then in section, 'Running TransDecoder
Predicting coding regions from a transcript fasta file', run Step 1
# Step 1: extract the long open reading frames
TransDecoder.LongOrfs -t target_transcripts.fasta
# I assume substitute Trinity.fasta for placeholder 'target_transcripts.fasta' ???????? OR copy Trinity.fasta to target_transcripts.fasta and use the latter ????

# Q: is step 3 needed ????????????????????????
# Step 3: predict the likely coding regions
TransDecoder.Predict -t target_transcripts.fasta [ homology options ]
# if so, what about the 'homology options' ??????????????????? Perhaps see runMe.sh under /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/TransDecoderv2.0.1/TransDecoder-2.0.1/sample_data
#Note: In https://groups.google.com/forum/#!forum/trinotate-users, 'TransDecoder.LongOrfs or TransDecoder.Predict' question suggests need the final transdecoder pep file, which is generated by TransDecoder.Predict


iii)
# Then, following TransDecoder, back to 'http://trinotate.github.io/', section, '1. Software Required' 
# probably need sqlite, ncbi blast+, HMMER/PHAM 
# Then, in section '2. Sequence Databases Required', looks like need dnload 3 databases ????????????
# dnload on 'pro' just to see what have.
# SwissProt: uniprot_sprot...., keeping .part name ??????????
# not dnloading reliably (14.1, 49.1, always with '.part' at end of name ??????, supposed to be 63.6
# Uniref90: start, 7:01pm =>
# got 136.4 Mb, should be 4.3 Gb ??????????????????
# Pham-A: got 34.3 Mb, supposed to be 220 Mb ????????????????????

# Finally, in section '2. Capturing BLAST Homologies', looks like run blastx & blastp.

# then to .xls file beginning with section 'Trinotate: Loading Above Results into a Trinotate SQLite Database'.

11/02-03/15:
# I note at http://trinotate.github.io/, claims Trinity (includes TransDecoder). I note: TransDecoder is in ***'tar.gz'*** file in trinity-plugins dir. of trinity v2.0.6, but **not**???????? in this subdir. for v2.1.1 ???????????
# note: when dnload transDecoder v2.0.1, found TRansDecoder.LongOrfs & TRansDecoder.Predict **inside** of TRansDecoder-2.0.1 dir.

# so will need get Adam to install Trinity 2.1.1 & TRansDecoder-2.0.1 on crane.
# Then run Trinity on test_Trinity_Assembly data (runMe.sh file), followed by step 1 & step 3 (arrange so if same name output file, they don't mess each other up) so can see what is output. Then back to trinotate, 2. Capturing BLAST Homologies section on way to '.xls' file.

# ck what Jean-Jack has in 'biodata/1.0' on crane at HCC.
ml spider biodata/1.0
module load biodata/1.0
ml spider ZEA_MAYS  
Lmod has detected the following error:  Unable to find: "ZEA_MAYS"
## ?????????????????????????? 

ls $GENOMES  ## to find out what genomes are available.
# but this worked.
# so **check** with JJ, if 3 db's in http://trinotate.github.io/, would he want to put in 'biodata/1.0' ?????
i) uniprot_sprot.trinotate_v2.0.pep.gz (63.6 MB)
ii) uniprot_uniref90.trinotate_v2.0.pep.gz (4.3 GB)
iii) Pfam-A.hmm.gz  (220 MB)

# keenan Q's:
i) what filename he used in the 'transdecoder' command line ??????
ii) what transdecoder command line ?????????????

# check crane dirs preparing to run Transdecoder
cd /work/amundsen/pterry/Trin20Tut/trinity_out_dir
# Note:

# will have to go back thru BdactyloidesthruGSEA081615.txt, more than 1 Trinity.fasta, so need clarify which is which, which can use, or will I need run again ????????????????????

# Note: https://github.com/trinityrnaseq/trinityrnaseq/releases, trinity **v2.1.1** now avail. I have **2.0.6** on laptop.
# so dnload, expand v2.1.1, see what inside.
# trinityrnaseq-2.1.1.tar.gz, 131 Mb
cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing
tar -xzvf trinityrnaseq-2.1.1.tar.gz
# not finding example data with this new trinity doc ?????????????
# in expanded trinity tar.gz, find sample_data/test_data with test data & a Trinity.fasta file (only 260 Kb)
# perhaps use this Trinity.fasta for testing transDecoder & trinotate.
# but dir. test_Trinity_Assembly appears have different sample data ??????
# perhaps rerun to get Trinity.fasta since this new ver. Trinity.

11/04/15:
# to email Adam, about trinity, transDecoder changes for Crane.

11/07/15:
# working with 'module' on Crane
ssh -Y pterry@crane.unl.edu
# Rrq096mN
module avail
# Use "module keyword key1 key2 ..." to search for all possible modules matching
any of the "keys".
module trinity  ## ???????????
module spider trinity
module spider trinity/2.1
# try identify location trinity executable 
module load compiler/gcc/4.8
module load bowtie/1.1
module load samtools/1.2
module load trinity/2.1
echo $PATH
# So probably path name to trinity v2.1 executable on crane is /util/opt/trinity/2.1/gcc/4.8/Trinity ref: line 940 above. 

# now, try set up to run trinity v2.1 on some v2.1 practice data.
# Q: JJ's comments about use of 3 db's he loaded ???????????????????

 11/08/15:
# check some locations on Crane
ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /work/amundsen/pterry/Trin20Tut
# has trinity_out_dir dir.
cd trinity_out_dir  ## has a Trinity.fasta file.
cd test_full_edgeR_pipeline/rnaseq_reads
# ck for location of read files on crane, trinity v2.1
cd /util/opt/trinity/2.1/gcc/4.8  ## Trinity executable is here
cd sample_data/test_Trinity_Assembly ## found 4 gzipped read files here
# that is in /util/opt/trinity/2.1/gcc/4.8/sample_data/test_Trinity_Assembly
# create new dir, Trin21test for trinityrnaseq-2.1.1
mkdir Trin21test
cd Trin21test
cp /util/opt/trinity/2.1/gcc/4.8/sample_data/test_Trinity_Assembly/*.gz .
# ok, copied 4 gzipped read files
# ready try run Trinity on v2.1 sample data

ssh -Y pterry@crane.unl.edu
# Rrq096mN 
# srun --pty --ntasks-per-node=4 --mem 4gb $SHELL  # taking to long to allocate?
# so try with 2 gb
srun --pty --ntasks-per-node=4 --mem 2gb $SHELL


cd /work/amundsen/pterry/Trin21test

module load compiler/gcc/4.8
module load bowtie/1.1
module load samtools/1.2
module load trinity/2.1

/util/opt/trinity/2.1/gcc/4.8/Trinity --seqType fq --max_memory 2G --left reads.left.fq.gz,reads2.left.fq.gz --right reads.right.fq.gz,reads2.right.fq.gz --SS_lib_type RF --CPU 4 --no_cleanup

exit
# Q: last part of error message ??????????????????
* Running CMD: /util/opt/trinity/2.1.1/gcc/4.8.3/trinity-plugins/jellyfish/bin/jellyfish count -t 4 -m 25 -s 304805520  both.fa
sh: line 1: 195135 Killed                  /util/opt/trinity/2.1.1/gcc/4.8.3/trinity-plugins/jellyfish/bin/jellyfish count -t 4 -m 25 -s 304805520 both.fa 2> tmp.194805.stderr
Trinity run failed. Must investigate error above.
[pterry@c0313.crane Trin21test]$ exit
exit
srun: error: c0313: task 0: Exited with exit code 2
                                                   [pterry@login.crane ~]$ 

11/09/15:
# Per Adam, try rerun Trinity with different parameters in 'srun' command. Previous run 'killed', not enough memory. Don't forget to delete stuff put these by previous failed Trinity attempt.

REMOVE PREVIOUS STUFF 1ST !!!!!!!!!!!!!!!!!!!!!!!!!!!!

ssh -Y pterry@crane.unl.edu
# Rrq096mN 
srun --pty --ntasks-per-node=4 --mem 8gb --qos=short $SHELL  # Q: '=' in 'qos' parameter ??????????????
cd /work/amundsen/pterry/Trin21test

module load compiler/gcc/4.8
module load bowtie/1.1
module load samtools/1.2
module load trinity/2.1

/util/opt/trinity/2.1/gcc/4.8/Trinity --seqType fq --max_memory 2G --left reads.left.fq.gz,reads2.left.fq.gz --right reads.right.fq.gz,reads2.right.fq.gz --SS_lib_type RF --CPU 4 --no_cleanup

exit
pwd
cd /work/amundsen/pterry/Trin21test
ls -al
cd trinity_out_dir
ls -al
less Trinity.fasta
# so looks like Trinity from v2.1.1 worked,
-rw-r--r-- 1 pterry amundsen   193199 Nov  9 14:36 Trinity.fasta

# now, to locate transDecoder executables on crane ????????
module spider transdecoder/2.0
module load transdecoder/2.0
echo $PATH
# check if executables under /util/opt/transdecoder/2.0/gcc/4.4/ dir ????????
cd /util/opt/transdecoder/2.0/gcc/4.4
# looks like needed executables in this dir.

ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /util/opt/transdecoder/2.0/gcc/4.4
ls -al
module help transdecoder

(STOPPED)
11/10/15:
ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test
ls -al
mkdir transdecoderLongtest
cd transdecoderLongtest
cp /work/amundsen/pterry/Trin21test/trinity_out_dir/Trinity.fasta .
srun --pty --ntasks-per-node=4 --mem 8gb --qos=short $SHELL
module load transdecoder/2.0
cd /work/amundsen/pterry/Trin21test/transdecoderLongtest
/util/opt/transdecoder/2.0/gcc/4.4/TransDecoder.LongOrfs -t Trinity.fasta
exit
ls -al
cd Trinity.fasta.transdecoder_dir
ls -al

# examine output
ls -al
# check for '.transdecoder.' files preparing for 'blastp in trinotate/2. Capturing BLAST Homologies section' ???????????
-rw-r--r-- 1 pterry amundsen  56472 Nov 10 22:46 longest_orfs.pep
# the expected output from step 1, from TransDecoder.LongOrfs executable.
# Q: why not 'optional', cause looks like *only* use is in the 'optional' *step 2* ??????????????????????????????????

11/11/15:
# ok, for now *skip* step 2 whose directions are in section 'Including homology searches as ORF retention criteria'.
# Q: looks like link there to dnload the db's, but several, ****which**** ?????????
# Q: diff. homologies here in step 2 & blastp in trinotate.github.io, section '2. Capturing BLAST Homologies' ??????????????????????????????????????????

# So proceed with step 3:

ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test
ls -al
mkdir transdecoderPredicttest
ls -al
cd transdecoderPredicttest
cp /work/amundsen/pterry/Trin21test/trinity_out_dir/Trinity.fasta .
ls -al
srun --pty --ntasks-per-node=4 --mem 8gb --qos=short $SHELL
module load transdecoder/2.0
cd /work/amundsen/pterry/Trin21test/transdecoderPredicttest
/util/opt/transdecoder/2.0/gcc/4.4/TransDecoder.Predict -t Trinity.fasta
exit

[pterry@c0710.crane transdecoderPredicttest]$ /util/opt/transdecoder/2.0/gcc/4.4/TransDecoder.Predict -t Trinity.fasta
Error, cannot find directory: Trinity.fasta.transdecoder_dir,  be sure to first run TransDecoder.LongOrfs before TransDecoder.Predict

# Looks like perhaps try this command from 
cd /work/amundsen/pterry/Trin21test/transdecoderLongtest
# dir. then try 
/util/opt/transdecoder/2.0/gcc/4.4/TransDecoder.Predict -t Trinity.fasta
# see if it finds dir Trinity.fasta.transdecoder_dir and perhaps uses longest_orfs.pep file there ??????????????????

ssh -Y pterry@crane.unl.edu
# Rrq096mN 
srun --pty --ntasks-per-node=4 --mem 8gb --qos=short $SHELL
module load transdecoder/2.0
cd /work/amundsen/pterry/Trin21test/transdecoderLongtest
/util/opt/transdecoder/2.0/gcc/4.4/TransDecoder.Predict -t Trinity.fasta
# looks like ran! SO need run 'step 1' before 'step 3'.
# finishes in /work/amundsen/pterry/Trin21test/transdecoderLongtest/Trinity.fasta.transdecoder_dir
exit
ls -al
# places desired output file in 
/work/amundsen/pterry/Trin21test/transdecoderLongtest/Trinity.fasta.transdecoder.pep
# so do need to run 'step 1' before 'step 3'.

ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test
ls -al
# COMPARE: (size (wc), content (less), ???) 
TRinity.fasta,
cd trinity_out_dir
ls -al
-rw-r--r-- 1 pterry amundsen 193199 Nov 10 22:44 Trinity.fasta
wc Trinity.fasta
  2898   5360 193199 Trinity.fasta
less Trinity.fasta
cd cd transdecoderLongtest/
longest_orfs.pep,
-rw-r--r-- 1 pterry amundsen  56472 Nov 10 22:46 longest_orfs.pep
wc longest_orfs.pep
  232   812 56472 longest_orfs.pep
less longest_orfs.pep
Trinity.fasta.transdecoder.pep
-rw-r--r-- 1 pterry amundsen  47385 Nov 11 11:25 Trinity.fasta.transdecoder.pep
wc Trinity.fasta.transdecoder.pep
  680  1224 47385 Trinity.fasta.transdecoder.pep
less Trinity.fasta.transdecoder.pep
# what to make of these files ?????????????????????????



# OK, now switch back to http://trinotate.github.io/, section: 2. Capturing BLAST Homologies
# 1st, run non-optional blastx

ssh -Y pterry@crane.unl.edu
# Rrq096mN 
srun --pty --ntasks-per-node=8 --mem 8gb --qos=short $SHELL
cd /work/amundsen/pterry/Trin21test
ls -al
cd trinity_out_dir  ## location of Trinity.fasta
module load blast/2.2.29
module load trinotate/2.0  ## here probably need for location of database ??

# search Trinity transcripts
 

blastx -query Trinity.fasta -db $TRINOTATE_SP -num_threads 8 -max_target_seqs 1 -outfmt 6 > blastx.outfmt6
# 12:01pm => 12:03pm, prompt back, but some **error** messages ????????????????
[pterry@c0523.crane trinity_out_dir]$ blastx -query Trinity.fasta -db $TRINOTATE_SP -num_threads 8 -max_target_seqs 1 -outfmt 6 > blastx.outfmt6
Error: (1431.1) FASTA-Reader: Warning: FASTA-Reader: Title is very long: 1654 characters (max is 1000)
Error: (1431.1) FASTA-Reader: Warning: FASTA-Reader: Title is very long: 1654 characters (max is 1000)
# WHAT to think of these errors ???????????????????????
exit
ls -al
-rw-r--r-- 1 pterry amundsen     7316 Nov 12 12:03 blastx.outfmt6
less blastx.outfmt6
wc blastx.outfmt6
#  100 1200 7316 blastx.outfmt6
# compare: Trinity.fasta has 2898 rows ??????????????????

# now blastp ...
ssh -Y pterry@crane.unl.edu
# Rrq096mN 
srun --pty --ntasks-per-node=8 --mem 8gb --qos=short $SHELL
cd /work/amundsen/pterry/Trin21test
ls -al
cd transdecoderLongtest  ## location of Trinity.fasta.transdecoder.pep
ls -al
module load blast/2.2.29
module load trinotate/2.0  ## here probably need for location of database ??
# now search Transdecoder-predicted proteins

blastp -query Trinity.fasta.transdecoder.pep -db $TRINOTATE_SP -num_threads 8 -max_target_seqs 1 -outfmt 6 > blastp.outfmt6
# 10:01pm => 10:02pm
exit
ls -al
-rw-r--r-- 1 pterry amundsen   5305 Nov 12 22:02 blastp.outfmt6
wc blastp.outfmt6
  69  828 5305 blastp.outfmt6
# compare: Trinity.fasta.transdecoder.pep has 680 lines ???????????????
less blastp.outfmt6

11/13/15:
# Next, in http://trinotate.github.io/, in section 'Trinotate: Loading Above Results into a 'Trinotate SQLite Database', need setup 'Trinotate SQLite Database'.
p-6 of 9
# 1. Retrieve the Trinotate Pre-generated Resource SQLite database
# create a directory to wget the sqlite db to.

11/16/15:
ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test
mkdir sqlitedbtest
cd sqlitedbtest
wget "https://data.broadinstitute.org/Trinity/Trinotate_v2.0_RESOURCES/Trinotate.sprot_uniref90.20150131.boilerplate.sqlite.gz" -O Trinotate.sqlite.gz
ls -al
gunzip Trinotate.sqlite.gz  ## ~1.5 to ~6.1 gb


# 2. Load transcripts and coding regions, 3 data types/files ???????
# Trinity.fasta ?????????????
# Trinity.fasta.transdecoder.pep
# Trinity.fasta.gene_trans_map

# *To do*, substitute actual path for $TRINITY_HOME
# Q: what in this 3rd file ???????????????????
# line 1582 above, did 
# module load trinity/2.1
# do anything ??????????????*************????????????************
# error trying to Load
module spider trinity/2.1
srun --pty --ntasks-per-node=8 --mem 8gb --qos=short $SHELL
pwd
module load compiler/gcc/4.8
module load bowtie/1.1
module load samtools/1.2
module load trinity/2.1

# no such module listed on crane, BUT think Adam installed it ??????????**?????

# $TRINITY_HOME/util/support_scripts/get_Trinity_gene_to_trans_map.pl Trinity.fasta >  Trinity.fasta.gene_trans_map
# cd /util/opt/trinity/2.1/gcc/4.8  ## think the path for trinity v2.1.1, but need verify ??????????******??????????????
# from dir wi Trinity.fasta, 
# /work/amundsen/pterry/Trin21test/transdecoderLongtest
cd /work/amundsen/pterry/Trin21test/transdecoderLongtest

/util/opt/trinity/2.1/gcc/4.8/util/support_scripts/get_Trinity_gene_to_trans_map.pl Trinity.fasta >  Trinity.fasta.gene_trans_map

module load trinotate/2.0
# Load these info into the Trinotate sqlite database like so (example, using Trinity assemblies):
# Q: cp Trinity.fasta, Trinity.fasta.gene_trans_map, and Trinity.fasta.transdecoder.pep to 
/work/amundsen/pterry/Trin21test/sqlitedbtest dir.
cd /work/amundsen/pterry/Trin21test/sqlitedbtest
cp /work/amundsen/pterry/Trin21test/transdecoderLongtest/Trinity.fasta .
cp /work/amundsen/pterry/Trin21test/transdecoderLongtest/Trinity.fasta.gene_trans_map .
cp /work/amundsen/pterry/Trin21test/transdecoderLongtest/Trinity.fasta.transdecoder.pep .

Trinotate Trinotate.sqlite init --gene_trans_map Trinity.fasta.gene_trans_map --transcript_fasta Trinity.fasta --transdecoder_pep Trinity.fasta.transdecoder.pep
# ***error*** message ??????????????????????????
# p-7 of 9
# 3. Loading BLAST homologies
# load protein hits
# cp .../blastp.outfmt6 .  ## to get path ??????????????
Trinotate Trinotate.sqlite LOAD_swissprot_blastp blastp.outfmt6

# co .../blastx.outfmt6 .  ## to get path ??????????????
Trinotate Trinotate.sqlite LOAD_swissprot_blastx blastx.outfmt6

# Trinotate: Output an Annotation Report
Trinotate Trinotate.sqlite report [opts] > trinotate_annotation_report.xls

# Q: check this the .xls file actually need ??????????????????????

11/16/15:
# Q: ok, read thru trinity, trinotate, transDecoder webpage doc., drew graph of paths for analyzing a Trinity.fasta output file. 
# To try: locate 4 biol'l rep samples, resulting Trinity.fasta file ran thru at least edgeR step. Take this thru transDecoder, ..., to '.xls' file. Then combining this .xls output with the edgeR path output, try continue on with 'GOseq', try see what get ?????????????????????


11/18/15:
# to check on failure tranotate sqlite db to run, perhaps install sqlite db engine ??????????
# talked to Jingchao about SQLite error message, from 11/16/15.
# Rather than try dnload precompiled SQLite binaries to crane, suggested:
# install a perl module, DBD::SQLite from cran, see HCC doc., 'Installing Perl modules'
# Initial configuration of local::lib
ssh -Y pterry@crane.unl.edu
# Rrq096mN 
ls -al
less .bashrc
cp .bashrc bashrctest
# use vi to add 'eval $(perl -Mlocal::lib)' at end of file 
vi bashrctest
# add new line at end.
i, to end, 'o', write line, esc, :wq
cat bashrctest
mv .bashrc bashtmp
mv bashrctest .bashrc
# logout and login to load your .bashrc

# To configure local::lib, add the following line to the end of your ~/.bashrc file in your home directory.
eval $(perl -Mlocal::lib)
# Next, logout and login to load your .bashrc. This will create a local Perl module directory, ~/perl5, inside your home directory and set environment variables to use it.

# look for & inside ~/perl5 dir
# yes, have it.
cd perl5
# has one file

11/19/15:
# Installing a module from CPAN
# before start, how exit 'cpan' ?????????????????


ssh -Y pterry@crane.unl.edu
# Rrq096mN 
$ cpan
# bunch of things to set, did automatic by mistake, couple Q: i) where it put general 'biold & cache' dir, ii) Autoconfigured everything but 'urllist'.
Please call 'o conf init urllist' to configure your CPAN server(s) now!

11/20/15:
# What to do, ck Jingchao ??????????????????
# Jingchao: just go with what have in cpan install above.
ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cpan
# cpan> install My::Module
install DBD::SQLite
# how exit 'cpan' 'q'
# don't know if install of DBD::SQLite worked, so go try run it.
# I assume ready try run 'TRinotate Trinotate.sqlite init ...' ???????????
# repeat/resume 11/16/15 above.

ssh -Y pterry@crane.unl.edu
# Rrq096mN 
# srun --pty --ntasks-per-node=8 --mem 8gb --qos=short $SHELL
# error message ????????????????
cd /work/amundsen/pterry/Trin21test/sqlitedbtest
module load trinotate/2.0
Trinotate Trinotate.sqlite init --gene_trans_map Trinity.fasta.gene_trans_map --transcript_fasta Trinity.fasta --transdecoder_pep Trinity.fasta.transdecoder.pep
# without srun, **don't** see error messages
# p-7 of 9
# 3. Loading BLAST homologies
# load protein hits

# cd /work/amundsen/pterry/Trin21test/transdecoderLongtest
ls -al
cd /work/amundsen/pterry/Trin21test/sqlitedbtest

cp /work/amundsen/pterry/Trin21test/transdecoderLongtest/blastp.outfmt6 .  
Trinotate Trinotate.sqlite LOAD_swissprot_blastp blastp.outfmt6
# appears to have worked.
# /work/amundsen/pterry/Trin21test/trinity_out_dir

cp /work/amundsen/pterry/Trin21test/trinity_out_dir/blastx.outfmt6 .  
Trinotate Trinotate.sqlite LOAD_swissprot_blastx blastx.outfmt6
# appears to have worked.

# Trinotate: Output an Annotation Report
# Trinotate Trinotate.sqlite report [opts] > trinotate_annotation_report.xls
# omit '[opts]', see what happens
Trinotate Trinotate.sqlite report > trinotate_annotation_report.xls

-rw-r--r-- 1 pterry amundsen      64155 Nov 20 23:13 trinotate_annotation_report.xls
less trinotate_annotation_report.xls
wc trinotate_annotation_report.xls
#   140  5563 64155 trinotate_annotation_report.xls

(STOPPED)

# Q: how check this the .xls file actually need ??????????????????????
# perhaps scp over to laptop, examine it bit more ????????
# perhaps look over this info? Trinotate: Sample data and execution









# meantime practice with https://github.com/trinityrnaseq/trinityrnaseq/wiki/Running-GOSeq
# Run Trinotate to Generate an Annotation Report
# prevly used trinotate to generate a '.xls' report.
# using Example Data from 'TRINITY_HOME/sample_data/test_GOSeq_trinotate_pipe/Spombe/', 
# Extract GO assignments per gene

# check '.xls' file for such GO assignments
# '.xls' file complicated ???????????????????????????????????

11/22/15:
# before try run following, perhaps identify what to replace placeholders with, examine what in some of these files ????????????????
ssh -Y pterry@crane.unl.edu
# Rrq096mN 
srun --pty --ntasks-per-node=8 --mem 8gb --qos=short $SHELL
# get error message, but gives back prompt wi resources asking for ??????
module load trinotate/2.0
# echo $TRINOTATE_HOME  ## /util/opt/trinotate/2.0
# cd $WORK
# ls -al
# /work/amundsen/pterry/Trin21test, perhaps work inside this dir
# run from say /work/amundsen/pterry/Trin21test/sampdataGOtest,
cd /work/amundsen/pterry/Trin21test
mkdir sampdataGOtest
ls -al
cd sampdataGOtest
# ck location of Trinotate_report.xls
# looks like 
cp /util/opt/trinity/2.1/gcc/4.8/sample_data/test_GOSeq_trinotate_pipe/Spombe/Trinotate_report.xls . 
ls -al

a trinotate script, perhaps copy from /spomb dir, needed files to where plan to run this sample data ?????????????????? 

# ${TRINOTATE_HOME}/util/extract_GO_assignments_from_Trinotate_xls.pl \
                         --Trinotate_xls trinotate.xls \
                         -G --include_ancestral_terms \
                         > go_annotations.txt
# fix ${TRINOTATE_HOME}, Q: how use this env var??, or perhaps just use actual path ??????

/util/opt/trinotate/2.0/util/extract_GO_assignments_from_Trinotate_xls.pl --Trinotate_xls Trinotate_report.xls -G --include_ancestral_terms > go_annotations.txt
Total transcript entries: 9426
Found obo: /util/opt/trinotate/2.0.2/util/../PerlLib/obo/go-basic.obo.gz
Warning, cannot parse parent info: regulates ! regulates
Warning, cannot parse parent info: regulates ! regulates
[95.48] processed.      

Done processing, writing output.

Finished.
# Q: what to think or warnings ????????????????????????????????????????
exit
cd sampdataGOtest
ls -al
cd /work/amundsen/pterry/Trin21test/sampdataGOtest
ls -al
less go_annotations.txt

# now section: Run GOseq in https://github.com/trinityrnaseq/trinityrnaseq/wiki/Running-GOSeq#example-data
# think need arrange install bioc. GOseq package before can proceed. Reference 09/22/15 above.

ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /work/amundsen/pterry/Trin21test/sampdataGOtest
ls -al
module load R/3.2
R  # R ver 3.2.1
source("http://bioconductor.org/biocLite.R")
biocLite("goseq")
# a ton of output came over the screen, after say 6 min, asked if want to update, saying 'a' ??????????????????????????????????????
  'lib = "/util/opt/R/3.2.1/gcc/4.4.7/lib64/R/library"' is not writable
Would you like to use a personal library instead?  (y/n) 
# guess I will say 'y'
# ... installing to /home/amundsen/pterry/R/x86_64-unknown-linux-gnu-library/3.2/mgcv/libs
# Q: ?
sessionInfo()
q()
logout

# 1st, examine the 3 files in the runMe.sh file am following ?????????

hs_induced_vs_log.factors  ## Q: how come up with the factor labeling files ????

Trinotate_report.xls.trans.gene_ontology  # Q: how get, perhaps from '.xls' file, 'go.annotations.txt ??????????????

Trinity.seq_lengths  ## Q: An indication given of how to get.

ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /work/amundsen/pterry/Trin21test/sampdataGOtest
# cp /util/opt/trinity/2.0/gcc/4.8/sample_data/test_GOSeq_trinotate_pipe/Spombe/hs_induced_vs_log.factors .
# cp /util/opt/trinity/2.0/gcc/4.8/sample_data/test_GOSeq_trinotate_pipe/Spombe/ds_induced_vs_log.factors .
# cp /util/opt/trinity/2.0/gcc/4.8/sample_data/test_GOSeq_trinotate_pipe/Spombe/Trinotate_report.xls.trans.gene_ontology .
# cp /util/opt/trinity/2.0/gcc/4.8/sample_data/test_GOSeq_trinotate_pipe/Spombe/Trinity.seq_lengths .
ls -al

srun --pty --ntasks-per-node=4 --mem 4gb $SHELL
# always a problem wi lib.pm ???????????????????????????????????????????????
cd /work/amundsen/pterry/Trin21test/sampdataGOtest
ls -al
module load compiler/gcc/4.8
module load bowtie/1.1
module load samtools/1.2
module load trinity/2.1

module load R/3.2

_______________________________________
# **to fix**: next command wi correct dir on crane
/util/opt/trinity/2.0/gcc/4.8/Analysis/DifferentialExpression/run_DE_analysis.pl --matrix counts.matrix --method edgeR --samples_file samples_described.txt

[pterry@c1923.crane rnaseq_reads]$ /util/opt/trinity/2.0/gcc/4.8/Analysis/DifferentialExpression/run_DE_analysis.pl --matrix counts.matrix --method edgeR --samples_file samples_described.txt
Error, cannot open file counts.matrix at /util/opt/trinity/2.0/gcc/4.8/Analysis/DifferentialExpression/run_DE_analysis.pl line 312.
[pterry@c1923.crane rnaseq_reads]$ 
# perhaps for '--matrix' parameter, change argument to 'Trinity_trans.counts.matrix'
# to try
/util/opt/trinity/2.0/gcc/4.8/Analysis/DifferentialExpression/run_DE_analysis.pl --matrix Trinity_trans.counts.matrix --method edgeR --samples_file samples_described.txt

# apparently ran ????????
______________________________________________
# ${TRINITY_HOME}/Analysis/DifferentialExpression/run_GOseq.pl \
                       --factor_labeling  factor_labeling.txt \
                       --GO_assignments go_annotations.txt \
                       --lengths gene.lengths.txt

# before run following replace wi correct files, examine files 1st ????????

# to replace preceding by two commands in .../Spombe/runMe.sh

/util/opt/trinity/2.0/gcc/4.8/Analysis/DifferentialExpression/run_GOseq.pl --factor_labeling hs_induced_vs_log.factors --GO_assignments Trinotate_report.xls.trans.gene_ontology --lengths Trinity.seq_lengths

# giving an error ??????????????????????????????????????????
# see line 2002, need to get qvalue package ????????????????

/util/opt/trinity/2.0/gcc/4.8/Analysis/DifferentialExpression/run_GOseq.pl --factor_labeling ds_induced_vs_log.factors --GO_assignments Trinotate_report.xls.trans.gene_ontology --lengths Trinity.seq_lengths

exit

11/25/15:
ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /work/amundsen/pterry/Trin21test/sampdataGOtest
ls -al
module load R/3.2
R  # R ver 3.2.1
source("http://bioconductor.org/biocLite.R")
Bioconductor version 3.1 (BiocInstaller 1.18.5), ?biocLite for help
A newer version of Bioconductor is available for this version of R,
  ?BiocUpgrade for help
# so do upgrade
source("http://bioconductor.org/biocLite.R")
biocLite("BiocUpgrade")
Upgrade all packages to Bioconductor version 3.2? [y/n]: 
# y
The downloaded source packages are in
	‘/tmp/RtmpyPnADG/downloaded_packages’
Warning in install.packages(update[instlib == l, "Package"], l, contriburl = contriburl,  :
  'lib = "/util/opt/R/3.2.1/gcc/4.4.7/lib64/R/library"' is not writable
Would you like to use a personal library instead?  (y/n) Y
# preceding taking > 10 min.
# to do, logout, start install of qvalue package again.
q()
logout

ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /work/amundsen/pterry/Trin21test/sampdataGOtest
ls -al
module load R/3.2
R  # R ver 3.2.1
source("http://bioconductor.org/biocLite.R")
biocLite("qvalue")
# again taking sevl min. ????????????????????????????????????????
# ... installing to /home/amundsen/pterry/R/x86_64-unknown-linux-gnu-library/3.2/mgcv/libs
# less than a Mb in file mgcv.so ??????????????
# Q: ?
sessionInfo()
q()
logout

# ready to try 'run_GOseq.pl' again.

ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /work/amundsen/pterry/Trin21test/sampdataGOtest
ls -al

srun --pty --ntasks-per-node=4 --mem 4gb $SHELL
# always a problem wi lib.pm ???????????????????????????????????????????????
cd /work/amundsen/pterry/Trin21test/sampdataGOtest
ls -al
module load compiler/gcc/4.8
module load bowtie/1.1
module load samtools/1.2
module load trinity/2.1

module load R/3.2

/util/opt/trinity/2.0/gcc/4.8/Analysis/DifferentialExpression/run_GOseq.pl --factor_labeling hs_induced_vs_log.factors --GO_assignments Trinotate_report.xls.trans.gene_ontology --lengths Trinity.seq_lengths

ls -al

/util/opt/trinity/2.0/gcc/4.8/Analysis/DifferentialExpression/run_GOseq.pl --factor_labeling ds_induced_vs_log.factors --GO_assignments Trinotate_report.xls.trans.gene_ontology --lengths Trinity.seq_lengths
ls -al
exit
# 5 new files, Q: should I have saved Rplots.pdf after run 'hs', and 'ds' ?????

# what now, 

# perhaps examine the 5 new files above,
less heatshock.GOseq.depleted
# not exactly like section 'Output format', of page https://github.com/trinityrnaseq/trinityrnaseq/wiki/Running-GOSeq
# ??????????

11/28/15:
# scp Rplots.pdf ...
scp pterry@crane.unl.edu:/work/amundsen/pterry/Trin21test/sampdataGOtest/Rplots.pdf .
# Q: what looking at in Rplots.pdf ???????????????????????????????????? 

# see p-5 of 9

# then, perhaps back to wepage that called this one, https://github.com/trinityrnaseq/trinityrnaseq/wiki/Trinity-Differential-Expression, 
# see p- 7 of 9, section: Gene Ontology (GO) Enrichment Analysis on Differentially Expressed Genes, 

but question, may have to coordinate which sample examples, may want to go back, run the example wi biol'l reps thru all the steps preceding before proceding with this webpage, section 'Gene Ontology (GO) Enrichment Analysis on Differentially Expressed Genes' ??????????????????????????

11/29/15:
# perhaps 1st, outline steps as per my pencil diagram to start with multibiol'l example.
# Then actually run the example thru the steps.

12/04-05/15:
# working from Trinity Wiki Home, https://github.com/trinityrnaseq/trinityrnaseq/wiki
# & ref, line 1489 above, 1574, 1584,

ssh -Y pterry@crane.unl.edu
# Rrq096mN 
# Q: start new dir, biolrepexamp ????????????????
cd /work/amundsen/pterry/Trin21test
#mkdir multbiolexamp
cd multbiolexamp
# cp /util/opt/trinity/2.1/gcc/4.8/sample_data/test_DATA/*.gz .

srun --pty --ntasks-per-node=4 --mem 8gb --qos=short $SHELL  # Q: '=' in 'qos' parameter ??????????????
# never got resources, Fri nite ???????????????????????????
# ok, sat morning, but usual error 'Can't locate local/lib.pm in @INC...' ???
# perhaps will need slurm ?????????????????????????????


module load compiler/gcc/4.8
module load bowtie/1.1
module load samtools/1.2
module load trinity/2.1

# /util/opt/trinity/2.1/gcc/4.8/Trinity --seqType fq --max_memory 2G --left reads.left.fq.gz,reads2.left.fq.gz --right reads.right.fq.gz,reads2.right.fq.gz --SS_lib_type RF --CPU 4 --no_cleanup

/util/opt/trinity/2.1/gcc/4.8/Trinity --seqType fq --max_memory 2G --left Sp_ds.10k.left.fq.gz,Sp_hs.10k.left.fq.gz,Sp_log.10k.left.fq.gz,Sp_plat.10k.left.fq.gz --right Sp_ds.10k.right.fq.gz,Sp_hs.10k.right.fq.gz,Sp_log.10k.right.fq.gz,Sp_plat.10k.right.fq.gz --SS_lib_type RF --CPU 4
# 9:05 - 9:08am
exitp
pwd
cd /work/amundsen/pterry/Trin21test/multbiolexamp
ls -al
cd trinity_out_dir
ls -al
wc Trinity.fasta  ##   4851   8084 284846 Trinity.fasta
# note: wc of Trinity.fasta in test_DATA dir gives   4443    7594  259708, bit different number of lines.
less Trinity.fasta
# top file different from laptop Trinity.fasta in test_DATA dir file.
# anyway, so looks like Trinity from v2.1.1 worked,
-rw-r--r-- 1 pterry amundsen   284846 Dec  5 09:08 Trinity.fasta

################################################################
# for now, **skip** down to 'Downstream Analyses' section, skipping 'Assenbly Quality Assessment' section.
#################################################################

12/06/15:
# Within 'Downstream Analysis' section,

# 'Trinity Transcript Quantification' section (09/16/15 above):
# 1. Just prepare the reference for alignment and abundance estimation

ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /work/amundsen/pterry/Trin21test/multbiolexamp
srun --pty --ntasks-per-node=4 --mem 8gb --qos=short $SHELL
# not getting resources, 10;50am, try
srun --pty --ntasks-per-node=4 --mem 4gb --qos=short $SHELL

module load compiler/gcc/4.8
module load bowtie/1.1
module load samtools/1.2
module load trinity/2.1

cd /work/amundsen/pterry/Trin21test/multbiolexamp
# cd /work/amundsen/pterry/Trin20Tut/test_full_edgeR_pipeline/rnaseq_reads

/util/opt/trinity/2.0/gcc/4.8/util/align_and_estimate_abundance.pl --transcripts trinity_out_dir/Trinity.fasta --est_method RSEM --aln_method bowtie --trinity_mode --prep_reference
exit
# 528 lines on screen, last one 'Only prepping reference. Stopping now.'
# look for 'prep reference' files
ls -al
cd trinity_out_dir
ls -al
# ran from 'Trin21test/multbiolexamp' dir, but 15 new files in trinity_out_dir dir. ?????????????????????????
# so looks like may have completed '--prep_reference' ok.

# 2. Run the alignment and abundance estimation (assumes reference has already been prepped, errors-out if prepped reference not located.)

ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /work/amundsen/pterry/Trin21test/multbiolexamp
srun --pty --ntasks-per-node=4 --mem 4gb --qos=short $SHELL
module load compiler/gcc/4.8
module load bowtie/1.1
module load samtools/1.2
module load trinity/2.1

cd /work/amundsen/pterry/Trin21test/multbiolexamp

/util/opt/trinity/2.0/gcc/4.8/util/align_and_estimate_abundance.pl --transcripts trinity_out_dir/Trinity.fasta --seqType fq --left Sp_ds.10k.left.fq --right Sp_ds.10k.right.fq --est_method RSEM --aln_method bowtie --trinity_mode --output_prefix ds
# ran 9/16/15 above, but error today ?????????????????????
exit
gunzip Sp_ds.10k.left.fq.gz
gunzip Sp_ds.10k.right.fq.gz
# retry align_and_estimate_abundance.pl
# looks like ran ok 'CMD: touch ds.isoforms.results.ok'

ls -al
cd trinity_out_dir
ls -al
# 5 'ds' files, 1 'ds' dir in 'multbiolexamp' dir, appears no changes in 'trinity_out_dir'.

# TO do, repeat 'align_and_estimate_abundance.pl' for 'hs', 'log' & 'plat'.
ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /work/amundsen/pterry/Trin21test/multbiolexamp
gunzip Sp_hs.10k.left.fq.gz
gunzip Sp_hs.10k.right.fq.gz

srun --pty --ntasks-per-node=4 --mem 4gb --qos=short $SHELL
module load compiler/gcc/4.8
module load bowtie/1.1
module load samtools/1.2
module load trinity/2.1

cd /work/amundsen/pterry/Trin21test/multbiolexamp

/util/opt/trinity/2.0/gcc/4.8/util/align_and_estimate_abundance.pl --transcripts trinity_out_dir/Trinity.fasta --seqType fq --left Sp_hs.10k.left.fq --right Sp_hs.10k.right.fq --est_method RSEM --aln_method bowtie --trinity_mode --output_prefix hs
exit

# looks like ran ok 'CMD: touch hs.isoforms.results.ok'

ls -al
cd trinity_out_dir
ls -al
# 5 'hs' files, 1 'hs' dir in 'multbiolexamp' dir, appears no changes in 'trinity_out_dir'.

(STOPPED)

# now quantitate transcript abundance for **'log'** biol'l '.fq' files

ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /work/amundsen/pterry/Trin21test/multbiolexamp
gunzip Sp_log.10k.left.fq.gz
gunzip Sp_log.10k.right.fq.gz

srun --pty --ntasks-per-node=4 --mem 4gb --qos=short $SHELL
# 5:04pm => 5:10pm
module load compiler/gcc/4.8
module load bowtie/1.1
module load samtools/1.2
module load trinity/2.1

cd /work/amundsen/pterry/Trin21test/multbiolexamp

/util/opt/trinity/2.0/gcc/4.8/util/align_and_estimate_abundance.pl --transcripts trinity_out_dir/Trinity.fasta --seqType fq --left Sp_log.10k.left.fq --right Sp_log.10k.right.fq --est_method RSEM --aln_method bowtie --trinity_mode --output_prefix log
exit

# looks like ran ok 'CMD: touch log.isoforms.results.ok'

ls -al
cd trinity_out_dir
ls -al
# 5 'log' files, 1 'log' dir in 'multbiolexamp' dir, appears no changes in 'trinity_out_dir'.

# now quantitate transcript abundance for **'plat'** biol'l '.fq' files

ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /work/amundsen/pterry/Trin21test/multbiolexamp
gunzip Sp_plat.10k.left.fq.gz
gunzip Sp_plat.10k.right.fq.gz

srun --pty --ntasks-per-node=4 --mem 4gb --qos=short $SHELL
# 5:17pm => 5:18pm
module load compiler/gcc/4.8
module load bowtie/1.1
module load samtools/1.2
module load trinity/2.1

cd /work/amundsen/pterry/Trin21test/multbiolexamp

/util/opt/trinity/2.0/gcc/4.8/util/align_and_estimate_abundance.pl --transcripts trinity_out_dir/Trinity.fasta --seqType fq --left Sp_plat.10k.left.fq --right Sp_plat.10k.right.fq --est_method RSEM --aln_method bowtie --trinity_mode --output_prefix plat
exit

# looks like ran ok 'CMD: touch plat.isoforms.results.ok'

ls -al
cd trinity_out_dir
ls -al
# 5 'plat' files, 1 'plat' dir in 'multbiolexamp' dir, appears no changes in 'trinity_out_dir'.

# Note: perhaps should have specified 'plat.RSEM' as --output_prefix rather than just 'plat' ???????????????????????????????????????????????????

# 'Build Transcript and Gene Expression Matrices' section. (ref: 09/18/15, line 1121 =>)

ssh -Y pterry@crane.unl.edu
# Rrq096mN
# cd /work/amundsen/pterry/Trin20Tut/test_full_edgeR_pipeline/rnaseq_reads
cd /work/amundsen/pterry/Trin21test/multbiolexamp
ls -al
srun --pty --ntasks-per-node=4 --mem 4gb --qos=short $SHELL

module load compiler/gcc/4.8
module load bowtie/1.1
module load samtools/1.2
module load trinity/2.1
module load R/3.2


/util/opt/trinity/2.0/gcc/4.8/util/abundance_estimates_to_matrix.pl --est_method RSEM  --out_prefix Trinity_trans ds.isoforms.results hs.isoforms.results log.isoforms.results plat.isoforms.results
# got error message, 'R: command not found'
# perhaps need add:
module load R/3.2
# to try
exit
ls -al
-rw-r--r-- 1 pterry amundsen   24232 Dec  7 00:01 Trinity_trans.counts.matrix
-rw-r--r-- 1 pterry amundsen   28181 Dec  7 00:01 Trinity_trans.not_cross_norm.fpkm.tmp
-rw-r--r-- 1 pterry amundsen     226 Dec  7 00:01 Trinity_trans.not_cross_norm.fpkm.tmp.TMM_info.txt
-rw-r--r-- 1 pterry amundsen   30413 Dec  7 00:01 Trinity_trans.TMM.fpkm.matrix
[pterry@login.crane multbiolexamp]$ 
# Q: did I get the expected 3 files ?????????????????????????????

12/07/15:
Try look at files output, see if helps to see what they look like?
Trinity_trans.counts.matrix  ## may be the raw counts will need below.
Trinity_trans.not_cross_norm.fpkm.tmp
Trinity_trans.not_cross_norm.fpkm.tmp.TMM_info.txt
Trinity_trans.TMM.fpkm.matrix  ## relation to expected 'trans_counts.TMM.EXPR.matrix' ??????????????????????????????????
# **Q:** so do have 2 of the 3 expected output files ?????????????????????????

# so **before** going to section 'Counting Numbers of Expressed Transcripts or Genes', need determine if I got needed output file from prev section, 'Build Transcript and Gene Expression Matrices' ?????????????????????????????????

# so moving on to 'Quality Check Your Samples and Replicates' in Trinity outline,/04-05/15, delete dir 
# 'Compare replicates for each of your samples' section:

*********************ERROR*****************
Error from line 2229 onward mixing trinity /2.0 and /2.1. so go back to line 2164, 12/04-05/15, for now, create new dir multbiol4examp, re run all steps from then to now starting with Trinity (12/04-5/15) thru to this error note.
**********************ERROR********************

12/08/15:
ssh -Y pterry@crane.unl.edu
# Rrq096mN 
# Q: start new dir, multbiol4examp ????????????????
cd /work/amundsen/pterry/Trin21test
mkdir multbiol4examp
cd multbiol4examp
# cp /util/opt/trinity/2.1/gcc/4.8/sample_data/test_DATA/*.gz .

srun --pty --ntasks-per-node=4 --mem 8gb --qos=short $SHELL  # Q: '=' in 'qos' parameter ??????????????
# ok, Tues nite, but usual error 'Can't locate local/lib.pm in @INC...' ???

module load compiler/gcc/4.8
module load bowtie/1.1
module load samtools/1.2
module load trinity/2.1

/util/opt/trinity/2.1/gcc/4.8/Trinity --seqType fq --max_memory 2G --left Sp_ds.10k.left.fq.gz,Sp_hs.10k.left.fq.gz,Sp_log.10k.left.fq.gz,Sp_plat.10k.left.fq.gz --right Sp_ds.10k.right.fq.gz,Sp_hs.10k.right.fq.gz,Sp_log.10k.right.fq.gz,Sp_plat.10k.right.fq.gz --SS_lib_type RF --CPU 4
# 10:14 - 10:19pm
exit
pwd
cd /work/amundsen/pterry/Trin21test/multbiol4examp
ls -al
cd trinity_out_dir
ls -al
wc Trinity.fasta  ##   4851   8084 284846 Trinity.fasta
# Preceding when ran 12/04-05/15
# following when ran just now (Q: why the difference ??????????????)
  4842   8051 284264 Trinity.fasta

# note: wc of Trinity.fasta in test_DATA dir gives   4443    7594  259708, bit different number of lines.
less Trinity.fasta
# top of file different from laptop Trinity.fasta in test_DATA dir file ?????
# anyway, so looks like Trinity from v2.1.1 worked,
-rw-r--r-- 1 pterry amundsen   284264 Dec  8 22:18 Trinity.fasta

################################################################
# for now, **skip** down to 'Downstream Analyses' section, skipping 'Assenbly Quality Assessment' section.
#################################################################

# Within 'Downstream Analysis' section,

# 'Trinity Transcript Quantification' section (09/16/15 above):
# 1. Just prepare the reference for alignment and abundance estimation

ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /work/amundsen/pterry/Trin21test/multbiol4examp
#srun --pty --ntasks-per-node=4 --mem 8gb --qos=short $SHELL
srun --pty --ntasks-per-node=4 --mem 4gb --qos=short $SHELL

module load compiler/gcc/4.8
module load bowtie/1.1 
module load samtools/1.2
module load trinity/2.1

cd /work/amundsen/pterry/Trin21test/multbiol4examp
# cd /work/amundsen/pterry/Trin20Tut/test_full_edgeR_pipeline/rnaseq_reads

#/util/opt/trinity/2.1/gcc/4.8/util/align_and_estimate_abundance.pl --transcripts trinity_out_dir/Trinity.fasta --est_method RSEM --aln_method bowtie --trinity_mode --prep_reference
# error (did not get wi v2.0.6)
Error, must specify output directory name via: --output_dir    at /util/opt/trinity/2.1/gcc/4.8/util/align_and_estimate_abundance.pl line 285.
# so specify where went wi v2.0 unspecified ?????
/util/opt/trinity/2.1/gcc/4.8/util/align_and_estimate_abundance.pl --transcripts trinity_out_dir/Trinity.fasta --est_method RSEM --aln_method bowtie --trinity_mode --prep_reference --output_dir trinity_out_dir
# Error, see output to screen ??????????? Need check with Adam.
exit

12/09/15:
# Adam installed RSEM, probably v1.2.25, to be available by specifying 
module load rsem/1.2
# check wi module available

ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /work/amundsen/pterry/Trin21test/multbiol4examp
srun --pty --ntasks-per-node=4 --mem 4gb --qos=short $SHELL
module load compiler/gcc/4.8
module load bowtie/1.1 
module load samtools/1.2
module load trinity/2.1
module load rsem/1.2

cd /work/amundsen/pterry/Trin21test/multbiol4examp

/util/opt/trinity/2.1/gcc/4.8/util/align_and_estimate_abundance.pl --transcripts trinity_out_dir/Trinity.fasta --est_method RSEM --aln_method bowtie --trinity_mode --prep_reference --output_dir trinity_out_dir

# Only prepping reference. Stopping now.
# so looks like ran ok.
exit
# look for 'prep reference' files
ls -al  # don't see any new ones here.
cd trinity_out_dir
ls -al
# ran from 'Trin21test/multbiol4examp' dir, but 15 new files in trinity_out_dir dir. ?????????????????????????
# so looks like may have completed '--prep_reference' ok.

# 2. Run the alignment and abundance estimation (assumes reference has already been prepped, errors-out if prepped reference not located.)

ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /work/amundsen/pterry/Trin21test/multbiol4examp
gunzip Sp_ds.10k.left.fq.gz
gunzip Sp_ds.10k.right.fq.gz
ls -al
srun --pty --ntasks-per-node=4 --mem 4gb --qos=short $SHELL
module load compiler/gcc/4.8
module load bowtie/1.1
module load samtools/1.2
module load trinity/2.1
# don't know if needed, did RSEM above ?????????????????????
module load rsem/1.2

cd /work/amundsen/pterry/Trin21test/multbiol4examp

/util/opt/trinity/2.1/gcc/4.8/util/align_and_estimate_abundance.pl --transcripts trinity_out_dir/Trinity.fasta --seqType fq --left Sp_ds.10k.left.fq --right Sp_ds.10k.right.fq --est_method RSEM --aln_method bowtie --trinity_mode --output_prefix ds --output_dir /work/amundsen/pterry/Trin21test/multbiol4examp
#Error, must specify output directory name via: --output_dir
exit
# looks like ran ok 'CMD: touch ds.isoforms.results.ok'
ls -al
#cd trinity_out_dir
ls -al
# 5 'ds' files, 1 'ds' dir in 'multbiolexamp' dir, appears no changes in 'trinity_out_dir'.
 
# TO do, repeat 'align_and_estimate_abundance.pl' for 'hs', 'log' & 'plat'.
'hs' next

ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /work/amundsen/pterry/Trin21test/multbiol4examp
gunzip Sp_hs.10k.left.fq.gz
gunzip Sp_hs.10k.right.fq.gz
ls -al

srun --pty --ntasks-per-node=4 --mem 4gb --qos=short $SHELL
module load compiler/gcc/4.8
module load bowtie/1.1
module load samtools/1.2
module load trinity/2.1
# don't know if needed, did RSEM above ?????????????????????
module load rsem/1.2

cd /work/amundsen/pterry/Trin21test/multbiol4examp

/util/opt/trinity/2.1/gcc/4.8/util/align_and_estimate_abundance.pl --transcripts trinity_out_dir/Trinity.fasta --seqType fq --left Sp_hs.10k.left.fq --right Sp_hs.10k.right.fq --est_method RSEM --aln_method bowtie --trinity_mode --output_prefix hs --output_dir /work/amundsen/pterry/Trin21test/multbiol4examp
exit

# looks like ran ok 'CMD: touch hs.isoforms.results.ok'

ls -al
cd trinity_out_dir
ls -al
# 5 'hs' files, 1 'hs' dir in 'multbiol4examp' dir, appears no changes in 'trinity_out_dir'.

# now quantitate transcript abundance for **'log'** biol'l '.fq' files

ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /work/amundsen/pterry/Trin21test/multbiol4examp
gunzip Sp_log.10k.left.fq.gz
gunzip Sp_log.10k.right.fq.gz
ls -al

srun --pty --ntasks-per-node=4 --mem 4gb --qos=short $SHELL
module load compiler/gcc/4.8
module load bowtie/1.1
module load samtools/1.2
module load trinity/2.1
# don't know if needed, did RSEM above ?????????????????????
module load rsem/1.2

cd /work/amundsen/pterry/Trin21test/multbiol4examp

/util/opt/trinity/2.1/gcc/4.8/util/align_and_estimate_abundance.pl --transcripts trinity_out_dir/Trinity.fasta --seqType fq --left Sp_log.10k.left.fq --right Sp_log.10k.right.fq --est_method RSEM --aln_method bowtie --trinity_mode --output_prefix log --output_dir /work/amundsen/pterry/Trin21test/multbiol4examp
exit

# looks like ran ok 'CMD: touch log.isoforms.results.ok'

ls -al
cd trinity_out_dir
ls -al
# 5 'log' files, 1 'log' dir in 'multbiol4examp' dir, appears no changes in 'trinity_out_dir'.

# now quantitate transcript abundance for **'plat'** biol'l '.fq' files

ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /work/amundsen/pterry/Trin21test/multbiol4examp
gunzip Sp_plat.10k.left.fq.gz
gunzip Sp_plat.10k.right.fq.gz
ls -al

srun --pty --ntasks-per-node=4 --mem 4gb --qos=short $SHELL
module load compiler/gcc/4.8
module load bowtie/1.1
module load samtools/1.2
module load trinity/2.1
# don't know if needed, did RSEM above ?????????????????????
module load rsem/1.2

cd /work/amundsen/pterry/Trin21test/multbiol4examp

/util/opt/trinity/2.1/gcc/4.8/util/align_and_estimate_abundance.pl --transcripts trinity_out_dir/Trinity.fasta --seqType fq --left Sp_plat.10k.left.fq --right Sp_plat.10k.right.fq --est_method RSEM --aln_method bowtie --trinity_mode --output_prefix plat --output_dir /work/amundsen/pterry/Trin21test/multbiol4examp
exit

# looks like ran ok 'CMD: touch plat.isoforms.results.ok'

ls -al
cd trinity_out_dir
ls -al
# 5 'plat' files, 1 'plat' dir in 'multbiol4examp' dir, appears no changes in 'trinity_out_dir'.

# 'Build Transcript and Gene Expression Matrices' section. (ref: 09/18/15, line 1121 =>)

ssh -Y pterry@crane.unl.edu
# Rrq096mN
# cd /work/amundsen/pterry/Trin20Tut/test_full_edgeR_pipeline/rnaseq_reads
cd /work/amundsen/pterry/Trin21test/multbiol4examp
ls -al
srun --pty --ntasks-per-node=4 --mem 4gb --qos=short $SHELL

module load compiler/gcc/4.8
module load bowtie/1.1
module load samtools/1.2
module load trinity/2.1
module load R/3.2
cd /work/amundsen/pterry/Trin21test/multbiol4examp


/util/opt/trinity/2.1/gcc/4.8/util/abundance_estimates_to_matrix.pl --est_method RSEM  --out_prefix Trinity_trans ds.isoforms.results hs.isoforms.results log.isoforms.results plat.isoforms.results
exit
ls -al
# looks like I got the expected 3 files!
-rw-r--r-- 1 pterry amundsen   23844 Dec 10 23:47 Trinity_trans.counts.matrix
# note: almost all zeros in right hand 4 colms ???????????????????????????
        ds      hs      log     plat
TRINITY_DN270_c0_g1_i1  0.00    0.00    0.00    0.00
TRINITY_DN521_c1_g1_i1  0.00    0.00    0.00    0.00
...
Trinity_trans.counts.matrix 

-rw-r--r-- 1 pterry amundsen   26092 Dec 10 23:47 Trinity_trans.TMM.EXPR.matrix
-rw-r--r-- 1 pterry amundsen   17218 Dec 10 23:47 Trinity_trans.TPM.not_cross_norm

(STOPPED)

******************************************************
# so proceed wi section: 'Counting Numbers of Expressed Transcripts or Genes'
# but Q: what to replace the placeholder file names by ???????????????????
# perhaps a question to support site ?????????????????
************************************************************
# For moment skip on to 

12/11/15:

# so moving on to 'Quality Check Your Samples and Replicates' in Trinity outline,/04-05/15, delete dir 
# 'Compare replicates for each of your samples' section:


cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing
scp samples.txt pterry@crane.unl.edu:/work/amundsen/pterry/Trin21test/multbiol4examp/

(STOPPED)

ssh -Y pterry@crane.unl.edu
# Rrq096mN
# cd /work/amundsen/pterry/Trin20Tut/test_full_edgeR_pipeline/rnaseq_reads
cd /work/amundsen/pterry/Trin21test/multbiol4examp
ls -al
srun --pty --ntasks-per-node=4 --mem 4gb --qos=short $SHELL

module load compiler/gcc/4.8
module load bowtie/1.1
module load samtools/1.2
module load trinity/2.1
module load R/3.2

# % $TRINITY_HOME/Analysis/DifferentialExpression/PtR --matrix counts.matrix \
                  --samples samples.txt --CPM --log2 --compare_replicates

cd /work/amundsen/pterry/Trin21test/multbiol4examp

/util/opt/trinity/2.1/gcc/4.8/Analysis/DifferentialExpression/PtR --matrix Trinity_trans.counts.matrix --samples samples.txt --CPM --log2 --compare_replicates
exit
ls -al
# two new files, neither a '.pdf' file as suggested in this section, and one is '0' bytes ?????????
-rw-r--r-- 1 pterry amundsen       0 Dec 11 20:11 Trinity_trans.counts.matrix.minCol10.minRow10.CPM.log2.dat
-rw-r--r-- 1 pterry amundsen    4563 Dec 11 20:11 Trinity_trans.counts.matrix.R
less Trinity_trans.counts.matrix.R
less Trinity_trans.counts.matrix  ## almost all zeros in right most 4 colms ????????????????????????????????????????????????
# note: lots of values in the example file: $TRINITY_HOME/sample_data/test_DE_analysis/Trinity_trans.counts.matrix.
# so, perhaps try this this command with that file to test this step with its example 'samples.txt' file ?????????????????????
# perhaps create little dir by self for this test ????????????

cd /work/amundsen/pterry/Trin21test/multbiol4examp
mkdir qc_comp_reps
cd qc_comp_reps
cp /util/opt/trinity/2.1/gcc/4.8/sample_data/test_DE_analysis/samples.txt .
cp /util/opt/trinity/2.1/gcc/4.8/sample_data/test_DE_analysis/Trinity_trans.counts.matrix .
ls -al
srun --pty --ntasks-per-node=4 --mem 4gb --qos=short $SHELL
module load compiler/gcc/4.8
module load bowtie/1.1
module load samtools/1.2
module load trinity/2.1
module load R/3.2

cd /work/amundsen/pterry/Trin21test/multbiol4examp/qc_comp_reps

/util/opt/trinity/2.1/gcc/4.8/Analysis/DifferentialExpression/PtR --matrix Trinity_trans.counts.matrix --samples samples.txt --CPM --log2 --compare_replicates
exit
ls -al
# output looks appropriate, to scp '.pdf' files over to look at.
cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing/trinity211_qc_testing
scp pterry@crane.unl.edu:/work/amundsen/pterry/Trin21test/multbiol4examp/qc_comp_reps/wt_37.rep_compare.pdf .

scp pterry@crane.unl.edu:/work/amundsen/pterry/Trin21test/multbiol4examp/qc_comp_reps/wt_GSNO.rep_compare.pdf .
scp pterry@crane.unl.edu:/work/amundsen/pterry/Trin21test/multbiol4examp/qc_comp_reps/wt_ph8.rep_compare.pdf .
# 4 plots each '.pdf' file, 1st seems useful, Q: what about the 4th one ?????????

12/12/15:
# section: 'Compare Replicates Across Samples'

ssh -Y pterry@crane.unl.edu
# Rrq096mN
# cd /work/amundsen/pterry/Trin20Tut/test_full_edgeR_pipeline/rnaseq_reads
cd /work/amundsen/pterry/Trin21test/multbiol4examp/qc_comp_reps
ls -al
srun --pty --ntasks-per-node=4 --mem 4gb --qos=short $SHELL

module load compiler/gcc/4.8
module load bowtie/1.1
module load samtools/1.2
module load trinity/2.1
module load R/3.2

cd /work/amundsen/pterry/Trin21test/multbiol4examp/qc_comp_reps

/util/opt/trinity/2.1/gcc/4.8/Analysis/DifferentialExpression/PtR --matrix Trinity_trans.counts.matrix -s samples.txt --log2 --sample_cor_matrix
exit
ls -al
# To view 'Trinity_trans.counts.matrix.minCol10.minRow10.log2.sample_cor_matrix.pdf'
logout
cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing/trinity211_qc_testing
scp pterry@crane.unl.edu:/work/amundsen/pterry/Trin21test/multbiol4examp/qc_comp_reps/Trinity_trans.counts.matrix.minCol10.minRow10.log2.sample_cor_matrix.pdf .

# PCA Analysis

ssh -Y pterry@crane.unl.edu
# Rrq096mN
# cd /work/amundsen/pterry/Trin20Tut/test_full_edgeR_pipeline/rnaseq_reads
cd /work/amundsen/pterry/Trin21test/multbiol4examp/qc_comp_reps
ls -al
srun --pty --ntasks-per-node=4 --mem 4gb --qos=short $SHELL

module load compiler/gcc/4.8
module load bowtie/1.1
module load samtools/1.2
module load trinity/2.1
module load R/3.2

cd /work/amundsen/pterry/Trin21test/multbiol4examp/qc_comp_reps

/util/opt/trinity/2.1/gcc/4.8/Analysis/DifferentialExpression/PtR --matrix Trinity_trans.counts.matrix -s samples.txt --log2 --prin_comp 3
exit
ls -al
# To view ??????
'Trinity_trans.counts.matrix.minCol10.minRow10.log2.principal_components.pdf'
logout
cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing/trinity211_qc_testing
scp pterry@crane.unl.edu:/work/amundsen/pterry/Trin21test/multbiol4examp/qc_comp_reps/Trinity_trans.counts.matrix.minCol10.minRow10.log2.principal_components.pdf .

12/13/15:
# 'Differential Expression Analysis Using a Trinity Assembly' section.
# assume have prevly installed R packages needed in section 'Running Differential Expression Analysis'
# Note: 'full' example has 4 biol'l samples, BUT NO reps ??????????????
# Q: could they mean 'biol'l reps' here, tho each sample has different trtmnt ???????????????????????????????????????????????????????

****************************************************************
# **thinking** just take 95 C1-3, 95 T1-3 (subsequent to trimmomatic step), start run with these, try work thru trinity/trinotate/transDecoder this way?

# to find trimmed 95C1-3, 95T1-3
ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /work/amundsen/pterry/Sitalica26/bufgrass/
ls -al
# look for output95C1_GATCAG_L006_R1_001.trimmed.fastq.gz file.
# looks like found the 6 trimmed files there.
-rw-r--r-- 1 pterry amundsen 4292886820 Aug 19 10:40 
output95C1_GATCAG_L006_R1_001.trimmed.fastq
-rw-r--r-- 1 pterry amundsen 4323022386 Aug 19 10:40 output95C2_TAGCTT_L007_R1_001.trimmed.fastq
-rw-r--r-- 1 pterry amundsen 4802473397 Aug 19 10:41 output95C3_GGCTAC_L007_R1_001.trimmed.fastq
-rw-r--r-- 1 pterry amundsen 6183099523 Aug 19 10:41 output95T1_AGTCAA_L005_R1_001.trimmed.fastq
-rw-r--r-- 1 pterry amundsen 5377105021 Aug 19 10:42 output95T2_AGTTCC_L005_R1_001.trimmed.fastq
-rw-r--r-- 1 pterry amundsen 6070497421 Aug 19 10:43 output95T3_ATGTCA_L006_R1_001.trimmed.fastq
# spot checked these files with fastQC, see Sitalica_041515.txt, line 494.


12/14/15:
# next, arrange run trinity step on these 6, create Trinity.fasta file.
# So, create a dir. for this project:

#cd /work/amundsen/pterry/Trin21test
# mkdir 95C1-3T1-3
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3
# ref: 'Running Trinity' section of 'https://github.com/trinityrnaseq/trinityrnaseq/wiki/Running%20Trinity'

cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing
scp slurm_trinity95C1-3T1-3crane.sh pterry@crane.unl.edu:/home/amundsen/pterry/scripts/

# ref: line 2395
# from 12/08/15:
ssh -Y pterry@crane.unl.edu
# Rrq096mN 

cd /work/amundsen/pterry/Trin21test/95C1-3T1-3
cp /work/amundsen/pterry/Sitalica26/bufgrass/*.fastq .
cp /work/amundsen/pterry/Sitalica26/bufgrass/output95C1*.fastq .
cp /work/amundsen/pterry/Sitalica26/bufgrass/output95C2*.fastq .
cp /work/amundsen/pterry/Sitalica26/bufgrass/output95C3*.fastq .
cp /work/amundsen/pterry/Sitalica26/bufgrass/output95T1*.fastq .
cp /work/amundsen/pterry/Sitalica26/bufgrass/output95T2*.fastq .
cp /work/amundsen/pterry/Sitalica26/bufgrass/output95T3*.fastq .
logout



# run slurm ???????

# from line 357
ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /home/amundsen/pterry/scripts
ls -al
sbatch slurm_trinity95C1-3T1-3crane.sh  2762140 11:53pm => ??:??am, no longer listed in squeue -u pterry
squeue -u pterry
[pterry@login.crane scripts]$ squeue -u pterry
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
[pterry@login.crane scripts]$


cd /work/amundsen/pterry/Trin21test/95C1-3T1-3
ls -l
less job.2762121.err  # 0 bytes
less job.2762121.out  # 70 bytes
Error, with --single reads, the --SS_lib_type can be 'F' or 'R' only.
job.2762121.out (END) 
# :Strand-specific RNA-Seq read orientation. Not knowing if 95C1-3T1-3 samples have any specific orientation [**CK Keenan** ?????????????????????????, and 'typical Trinity command' omits this parameter, so let me also omit it, and rerun sbatch.

[pterry@login.crane scripts]$ squeue -u pterry
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           2762140     batch TJob_tri   pterry  R       0:51      1 c1219
[pterry@login.crane scripts]$ 

# so new try is running: 2762140 11:53pm => ??:??am


12/15/15:
# had relogin to crane 
ssh -Y pterry@crane.unl.edu
# Rrq096mN
squeue -u pterry
[pterry@login.crane ~]$ squeue -u pterry
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
# so apparently job no longer running.             
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3
ls -l
less job.2762140.err  # 99 bytes
slurmstepd: error: *** JOB 2762140 CANCELLED AT 2015-12-15T05:53:08 DUE TO TIME LIMIT on c1219 ***
job.2762140.err (END) 
less job.2762140.out  # 900382 bytes
sacct -j 2762140 -o start,end
[pterry@login.crane 95C1-3T1-3]$ sacct -j 2762140 -o start,end
              Start                 End 
------------------- ------------------- 
2015-12-14T23:52:49 2015-12-15T05:53:08 
2015-12-14T23:52:49 2015-12-15T05:53:21 
[pterry@login.crane 95C1-3T1-3]$ 
# so ran 6 hrs
# Q: can one estimate how to change slurm file for rerun ????????????????
# Note: less job.2762140.out file indicates stopped when running in 'Trinity Phase 2: assembling clusters of reads', ~ 20% complete.
# Keenan, Adam, try resume this Trinity run, just resubmit slurm file, only set time for 72:00:00.
# can use 'tail job.2762140.out' to monitor progress.

cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing
re-scp modified slurm script file.
scp slurm_trinity95C1-3T1-3crane.sh pterry@crane.unl.edu:/home/amundsen/pterry/scripts/

ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /home/amundsen/pterry/scripts
ls -al
sbatch slurm_trinity95C1-3T1-3crane.sh  2764994 1:31pm => ??:??am, on 12/15/15
squeue -u pterry
[pterry@login.crane scripts]$ squeue -u pterry
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           2764994     batch TJob_tri   pterry  R       0:53      1 c1208
# check
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3
ls -al
tail job.2764994.out
head job.2764994.out
# Q: warnings:
WARNING, cannot remove output directory /lustre/work/amundsen/pterry/Trin21test/95C1-3T1-3/trinity_out_dir/read_partitions/Fb_0/CBin_192/c19264.trinity.reads.fa.out, since not created in this run. (safety precaution)
# presumably this message ok ??????????????????????????????????????????????????

# to check progress of trinity run
ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3
squeue -u pterry
tail job.2764994.out  ## 28% complete. Still getting WARNINGs.
# looks like started these %'s at zero upon this resubmission, not at ~ 20% where 1st slurm submission stopped ???????????????

# to check progress of trinity run, midnight, betw Dec 15 & 16
ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3
[pterry@login.crane 95C1-3T1-3]$ squeue -u pterry
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           2764994     batch TJob_tri   pterry  R   10:38:16      1 c1208
squeue -u pterry
tail job.2764994.out  ## 34% complete. Still getting WARNINGs.

12/16/15:
# to check progress of trinity run, 9:45am, Dec 16
ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3
squeue -u pterry
[pterry@login.crane 95C1-3T1-3]$ squeue -u pterry
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           2764994     batch TJob_tri   pterry  R   20:12:15      1 c1208
tail job.2764994.out  ## 38% complete. Still getting WARNINGs.
# Q: taking long time, will my 72 hr time be enough, can I restart it again if not enough time ?????????

# to check progress of trinity run, 10:15pm, Dec 16
ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3
squeue -u pterry
[pterry@login.crane 95C1-3T1-3]$ squeue -u pterry
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
tail job.2764994.out  ## looks like no error at end of file.
# so apparently done, and 
sacct -j 2764994 -o start,end
[pterry@login.crane 95C1-3T1-3]$ sacct -j 2764994 -o start,end
              Start                 End 
------------------- ------------------- 
2015-12-15T13:30:36 2015-12-16T13:51:53 
2015-12-15T13:30:36 2015-12-16T13:51:53 
# so ran for **24:20** hrs:min

cd trinity_out_dir
-rw-r--r-- 1 pterry amundsen   194832811 Dec 16 13:51 Trinity.fasta
# so ~ **195 Mb**
less Trinity.fasta
>TRINITY_DN10610_c0_g1_i1 len=460 path=[946:0-169 948:170-236 943:237-459] [-1, 946, 948, 943, -2]
CGCATGCTGTTTGTGCAGTGGTGCAGTTCAGAGCGTTGGTGTTGAGCCGGGAAATGGGTA

cd /work/amundsen/pterry/Trin21test/95C1-3T1-3
ls -al
cd trinity_out_dir
ls -al
wc Trinity.fasta
[pterry@login.crane trinity_out_dir]$ wc Trinity.fasta
  2459588   8071010 194832811 Trinity.fasta

# Next, perhaps skip 'Assessing the Read Content of the Transcriptome Assembly' & 'Assessing the Read Content of the Transcriptome Assembly' **for now**.
# ... Post- Transcriptome Assembly Downstream Analyses, 

# Trinity Transcript Quantification
# Plan try RSEM method. Run abundance seprately for each sample.
# section: Estimating Transcript Abundance

# 1. Just prepare the reference for alignment and abundance estimation
# ref: 12/08/15 above

scp slurm_align_est_abun_prepref.sh pterry@crane.unl.edu:/home/amundsen/pterry/scripts/

(STOPPED)

ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /home/amundsen/pterry/scripts
ls -al
sbatch slurm_align_est_abun_prepref.sh  2816536 11:36pm => ??:??am, on 12/15/15
squeue -u pterry
[pterry@login.crane ~]$ squeue -u pterry
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
# Q: 9:30am, Dec 18, does this mean, stopped, not complete ??????????????????
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3
ls -al
less job.2816536.err
Only prepping reference. Stopping now.
# so looks like ran ok ???????????????????
less job.2816536.out

sacct -j 2816536 -o start,end
              Start                 End 
------------------- ------------------- 
2015-12-18T00:05:56 2015-12-18T00:22:13 
2015-12-18T00:05:56 2015-12-18T00:22:13 
# so ran bit over 16 min, started ~ 30 min after submission.

cd trinity_out_dir
ls -al
# lot new stuff in dir trinity_out_dir, so probably ran ok.
# Q: any way judge if job would have run sooner if ask for fewer resources? Since job ran in ~ 16 min, in future could ask for fewer resources, test how well would run.

12/18/15:

# 2. Run the alignment and abundance estimation (assumes reference has already been prepped, errors-out if prepped reference not located.)

scp slurm_align_est_abun_95C1.sh pterry@crane.unl.edu:/home/amundsen/pterry/scripts/

ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /home/amundsen/pterry/scripts
ls -al
sbatch slurm_align_est_abun_95C1.sh  2820246 1:27pm => ??:??am, on 12/15/15
squeue -u pterry  ## running
squeue -u pterry  ## when checked at 6pm
[pterry@login.crane 95C1-3T1-3]$ squeue -u pterry
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3
ls -al
less job.2820246.err
CMD: set -o pipefail && bowtie -q --all --best --strata -m 300 --chunkmbs 512 -S -p 4 /lustre/work/amundsen/pterry/Trin21test/95C1-3T1-3/trinity_out_dir/Trinity.fasta.bowtie /lustre/work/amundsen/pterry/Trin21test/95C1-3T1-3/output95C1_GATCAG_L006_R1_001.trimmed.fastq | samtools view -F 4 -S -b -o 95C1.bowtie.bam -
# reads processed: 19381393
# reads with at least one reported alignment: 17265440 (89.08%)
# reads that failed to align: 2115953 (10.92%)
Reported 30221873 alignments to 1 output stream(s)
CMD: touch 95C1.bowtie.bam.ok
CMD: rsem-calculate-expression     -p 4    --no-bam-output --bam 95C1.bowtie.bam /lustre/work/amundsen/pterry/Trin21test/95C1-3T1-3/trinity_out_dir/Trinity.fasta.RSEM 95C1 
CMD: touch 95C1.isoforms.results.ok
job.2820246.err (END) 
# Q: anything should note in 'less' output ???????????????????
sacct -j 2820246 -o start,end
              Start                 End 
------------------- ------------------- 
2015-12-18T13:27:03 2015-12-18T14:29:03 
2015-12-18T13:27:03 2015-12-18T14:29:03 
[pterry@login.crane 95C1-3T1-3]
# 1:02 hrs to run
ls -al
# 5 '95C1' files, 1 '95C1' dir in '95C1-3T1-3' dir, appears no changes in 'trinity_out_dir'.
wc output95C1_GATCAG_L006_R1_001.trimmed.fastq
  77525572   96906965 4292886820 output95C1_GATCAG_L006_R1_001.trimmed.fastq
# Q: why discrepancy with 'reads processed: 19381393' ?????????????????????


# now for alignment and abundance estimation on 2nd input file, output95C2_TAGCTT_L007_R1_001.trimmed.fastq

cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing
scp slurm_align_est_abun_95C2.sh pterry@crane.unl.edu:/home/amundsen/pterry/scripts/

ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /home/amundsen/pterry/scripts
ls -al
sbatch slurm_align_est_abun_95C2.sh 2821099 7:12pm => ??:??am, on 12/18/15
squeue -u pterry  ## running

cd /work/amundsen/pterry/Trin21test/95C1-3T1-3
less job.2821099.err
CMD: set -o pipefail && bowtie -q --all --best --strata -m 300 --chunkmbs 512 -S -p 4 /lustre/work/amundsen/pterry/Trin21test/95C1-3T1-3/trinity_out_dir/Trinity.fasta.bowtie /lustre/work/amundsen/pterry/Trin21test/95C1-3T1-3/output95C2_TAGCTT_L007_R1_001.trimmed.fastq | samtools view -F 4 -S -b -o 95C2.bowtie.bam -
# reads processed: 19517268
# reads with at least one reported alignment: 17600885 (90.18%)
# reads that failed to align: 1916383 (9.82%)
Reported 30025634 alignments to 1 output stream(s)
CMD: touch 95C2.bowtie.bam.ok
CMD: rsem-calculate-expression     -p 4    --no-bam-output --bam 95C2.bowtie.bam /lustre/work/amundsen/pterry/Trin21test/95C1-3T1-3/trinity_out_dir/Trinity.fasta.RSEM 95C2 
CMD: touch 95C2.isoforms.results.ok
job.2821099.err (END) 
# 5 '95C2' files, 1 '95C2' dir in '95C1-3T1-3' dir, appears no changes in 'trinity_out_dir'.
sacct -j 2821099 -o start,end
              Start                 End 
------------------- ------------------- 
2015-12-18T19:18:10 2015-12-18T20:10:29 
2015-12-18T19:18:10 2015-12-18T20:10:29 
# ~ 52 min


# now for alignment and abundance estimation on 3rd input file, output95C3_GGCTAC_L007_R1_001.trimmed.fastq

cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing
scp slurm_align_est_abun_95C3.sh pterry@crane.unl.edu:/home/amundsen/pterry/scripts/

ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /home/amundsen/pterry/scripts
ls -al
sbatch slurm_align_est_abun_95C3.sh 2821101 7:23pm => ??:??am, on 12/18/15
squeue -u pterry  ## running
less job.2821101.err
CMD: set -o pipefail && bowtie -q --all --best --strata -m 300 --chunkmbs 512 -S -p 4 /lustre/work/amundsen/pterry/Trin21test/95C1-3T1-3/trinity_out_dir/Trinity.fasta.bowtie /lustre/work/amundsen/pterry/Trin21test/95C1-3T1-3/output95C3_GGCTAC_L007_R1_001.trimmed.fastq | samtools view -F 4 -S -b -o 95C3.bowtie.bam -
# reads processed: 21681817
# reads with at least one reported alignment: 19222537 (88.66%)
# reads that failed to align: 2459280 (11.34%)
Reported 32248349 alignments to 1 output stream(s)
CMD: touch 95C3.bowtie.bam.ok
CMD: rsem-calculate-expression     -p 4    --no-bam-output --bam 95C3.bowtie.bam /lustre/work/amundsen/pterry/Trin21test/95C1-3T1-3/trinity_out_dir/Trinity.fasta.RSEM 95C3 
CMD: touch 95C3.isoforms.results.ok
job.2821101.err (END) 
# 5 '95C3' files, 1 '95C3' dir in '95C1-3T1-3' dir
sacct -j 2821101 -o start,end
              Start                 End 
------------------- ------------------- 
2015-12-18T19:23:35 2015-12-18T20:16:42 
2015-12-18T19:23:35 2015-12-18T20:16:42 
~ 53 min



# now for alignment and abundance estimation on 4th input file, output95T1_AGTCAA_L005_R1_001.trimmed.fastq

cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing
scp slurm_align_est_abun_95T1.sh pterry@crane.unl.edu:/home/amundsen/pterry/scripts/

ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /home/amundsen/pterry/scripts
ls -al
sbatch slurm_align_est_abun_95T1.sh 2821138 8:07pm => ??:??am, on 12/18/15
squeue -u pterry  ## PD
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3
less job.2821138.err
CMD: set -o pipefail && bowtie -q --all --best --strata -m 300 --chunkmbs 512 -S -p 4 /lustre/work/amundsen/pterry/Trin21test/95C1-3T1-3/trinity_out_dir/Trinity.fasta.bowtie /lustre/work/amundsen/pterry/Trin21test/95C1-3T1-3/output95T1_AGTCAA_L005_R1_001.trimmed.fastq | samtools view -F 4 -S -b -o 95T1.bowtie.bam -
# reads processed: 27915998
# reads with at least one reported alignment: 25125553 (90.00%)
# reads that failed to align: 2790445 (10.00%)
Reported 46585714 alignments to 1 output stream(s)
CMD: touch 95T1.bowtie.bam.ok
CMD: rsem-calculate-expression     -p 4    --no-bam-output --bam 95T1.bowtie.bam /lustre/work/amundsen/pterry/Trin21test/95C1-3T1-3/trinity_out_dir/Trinity.fasta.RSEM 95T1 
CMD: touch 95T1.isoforms.results.ok
job.2821138.err (END) 
# 5 '95T1' files, 1 '95T1' dir in '95C1-3T1-3' dir
sacct -j 2821138 -o start,end
              Start                 End 
------------------- ------------------- 
2015-12-18T20:10:29 2015-12-18T21:32:25 
2015-12-18T20:10:29 2015-12-18T21:32:25 
~ 1 hr & 22 min


# now for alignment and abundance estimation on 5th input file, output95T2_AGTTCC_L005_R1_001.trimmed.fastq

cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing
scp slurm_align_est_abun_95T2.sh pterry@crane.unl.edu:/home/amundsen/pterry/scripts/

ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /home/amundsen/pterry/scripts
ls -al
sbatch slurm_align_est_abun_95T2.sh 2821224 9:45pm => ??:??am, on 12/18/15
squeue -u pterry  ## PD
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3
less job.2821224.err
CMD: set -o pipefail && bowtie -q --all --best --strata -m 300 --chunkmbs 512 -S -p 4 /lustre/work/amundsen/pterry/Trin21test/95C1-3T1-3/trinity_out_dir/Trinity.fasta.bowtie /lustre/work/amundsen/pterry/Trin21test/95C1-3T1-3/output95T2_AGTTCC_L005_R1_001.trimmed.fastq | samtools view -F 4 -S -b -o 95T2.bowtie.bam -
# reads processed: 24276992
# reads with at least one reported alignment: 21721173 (89.47%)
# reads that failed to align: 2555819 (10.53%)
Reported 41023010 alignments to 1 output stream(s)
CMD: touch 95T2.bowtie.bam.ok
CMD: rsem-calculate-expression     -p 4    --no-bam-output --bam 95T2.bowtie.bam /lustre/work/amundsen/pterry/Trin21test/95C1-3T1-3/trinity_out_dir/Trinity.fasta.RSEM 95T2 
CMD: touch 95T2.isoforms.results.ok
job.2821224.err (END) 
# 5 '95T2' files, 1 '95T2' dir in '95C1-3T1-3' dir
sacct -j 2821224 -o start,end
              Start                 End 
------------------- ------------------- 
2015-12-18T21:45:12 2015-12-18T22:48:44 
2015-12-18T21:45:12 2015-12-18T22:48:44 
~ 1 hr 3 min




# now for alignment and abundance estimation on 6th input file, output95T3_ATGTCA_L006_R1_001.trimmed.fastq

cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing
scp slurm_align_est_abun_95T3.sh pterry@crane.unl.edu:/home/amundsen/pterry/scripts/

ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /home/amundsen/pterry/scripts
ls -al
sbatch slurm_align_est_abun_95T3.sh 2821232 9:54pm => ??:??am, on 12/18/15
squeue -u pterry  ## PD
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3
less job.2821232.err
CMD: set -o pipefail && bowtie -q --all --best --strata -m 300 --chunkmbs 512 -S -p 4 /lustre/work/amundsen/pterry/Trin21test/95C1-3T1-3/trinity_out_dir/Trinity.fasta.bowtie /lustre/work/amundsen/pterry/Trin21test/95C1-3T1-3/output95T3_ATGTCA_L006_R1_001.trimmed.fastq | samtools view -F 4 -S -b -o 95T3.bowtie.bam -
# reads processed: 27406970
# reads with at least one reported alignment: 24481044 (89.32%)
# reads that failed to align: 2925926 (10.68%)
Reported 45979768 alignments to 1 output stream(s)
CMD: touch 95T3.bowtie.bam.ok
CMD: rsem-calculate-expression     -p 4    --no-bam-output --bam 95T3.bowtie.bam /lustre/work/amundsen/pterry/Trin21test/95C1-3T1-3/trinity_out_dir/Trinity.fasta.RSEM 95T3 
CMD: touch 95T3.isoforms.results.ok
job.2821232.err (END) 
# 5 '95T3' files, 1 '95T3' dir in '95C1-3T1-3' dir
sacct -j 2821232 -o start,end
              Start                 End 
------------------- ------------------- 
2015-12-18T21:54:00 2015-12-18T23:08:51 
2015-12-18T21:54:00 2015-12-18T23:08:51
~ 1 hr & 14 min


# section 'Build Transcript and Gene Expression Matrices' of outline section 'Trinity Transcript Quantification'
# ck line 2348 =>

cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing
scp slurm_bld_tx_expn_matrix.sh pterry@crane.unl.edu:/home/amundsen/pterry/scripts/

ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /home/amundsen/pterry/scripts
ls -al
sbatch slurm_bld_tx_expn_matrix.sh 2823955 11:06pm => ??:??am, on 12/18/15
squeue -u pterry  ## PD
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3
less job.2823955.err
more job.2823955.err
cat job.2823955.err
# so got the expected **3** files, 
-rw-r--r--  1 pterry amundsen    9495163 Dec 19 23:06 Trinity_trans.counts.matrix
-rw-r--r--  1 pterry amundsen   10187631 Dec 19 23:06 Trinity_trans.TMM.EXPR.matrix
-rw-r--r--  1 pterry amundsen    8155802 Dec 19 23:06 Trinity_trans.TPM.not_cross_norm
-rw-r--r--  1 pterry amundsen        321 Dec 19 23:06 Trinity_trans.TPM.not_cross_norm.TMM_info.txt
# and got a 4th, 
less Trinity_trans.TPM.not_cross_norm.TMM_info.txt 
group   lib.size        norm.factors    eff.lib.size
95C1    999977  0.883874641930173       883854.312813409
95C2    1000301 0.882696475460211       882962.167099324
95C3    998550  0.834140792372941       832931.288224001
95T1    999664  1.13104358832889        1130663.55768321
95T2    1000371 1.15966847286907        1160098.7098725
95T3    999781  1.17150832834834        1171251.76802443
Trinity_trans.TPM.not_cross_norm.TMM_info.txt (END) 
# what should I make of this, content of output to .err file, don't see any error messages, looks like using edgeR to build this count table ?????????????
# Perhaps check edgeR doc ????????????????????????????
# note: ***looks like using edgeR for this task from the job.2823955.err file content.***


# could try 'Counting Numbers of Expressed Transcripts or Genes' section before moving on to 'Quality Check Your Samples and Replicates section.

# but for the 'trans' version, what to make of the part following 'tee' ??????
# so skip to 'Quality Check Your Samples and Replicates section' section.


12/21/15:
# 'Quality Check Your Samples and Replicates section' section' of 'https://github.com/trinityrnaseq/trinityrnaseq/wiki/Trinity-Transcript-Quantification'. Then 'Compare replicates for each of your samples' section.

ssh -Y pterry@crane.unl.edu
# Rrq096mN
# cd /work/amundsen/pterry/Trin20Tut/test_full_edgeR_pipeline/rnaseq_reads
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3
mkdir qc_comp_reps
cd qc_comp_reps
cp /work/amundsen/pterry/Trin21test/95C1-3T1-3/Trinity_trans.counts.matrix .
ls -al
logout

cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing
scp slurm_comp_reps_for_each_sample.sh pterry@crane.unl.edu:/home/amundsen/pterry/scripts/

scp samples.txt pterry@crane.unl.edu:/work/amundsen/pterry/Trin21test/95C1-3T1-3/qc_comp_reps

ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /home/amundsen/pterry/scripts
ls -al
sbatch slurm_comp_reps_for_each_sample.sh 2826393 2:16pm => ??:??am, on 12/18/15
squeue -u pterry  ## PD
[pterry@login.crane scripts]$ squeue -u pterry
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
# not working ??????
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/qc_comp_reps
less job.2826393.err  # don't see an error ?????
less job.2826393.out
ls -al
# don't see expected 6 pdf files ?????????????????
# got expected results prevly with example input files, see line 2706-11, 12/11/15 above.
# Apparently uses 'Trinity_trans.counts.matrix.R' file specific to '--compare_replicates', etc. specification ???????????????????
# note: 'if' stmnt before 'pdf...' in this file, perhaps reason not creating expected 'pdf' files ???????????????????
# **BUT NOTE**, in $TRINITY_HOME/sample_data/test_DE_analysis dir, samples.txt file, 1st colm, each biol'l sample NO VARIATION in 1st colm.
# SO, **RERUN** WITH THAT CORRECTION in samples.txt file. mv Trinity_trans.counts.matrix.minCol10.minRow10.CPM.log2.dat to Trinity_trans.counts.matrix.minCol10.minRow10.CPM.log2.dat_bad_samples.txt_file
# modify left colm so only two values (biol'l trtmnts), 95C & 95T.


cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing
scp samples.txt pterry@crane.unl.edu:/work/amundsen/pterry/Trin21test/95C1-3T1-3/qc_comp_reps

ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /home/amundsen/pterry/scripts
ls -al
sbatch slurm_comp_reps_for_each_sample.sh 2826862 10:06pm => ??:??am, 
squeue -u pterry  ## PD
[pterry@login.crane scripts]$ squeue -u pterry
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/qc_comp_reps
less job.2826862.err
more job.2826862.out
# have the 2 expected .pdf files,
-rw-r--r--  1 pterry amundsen  5963833 Dec 21 22:06 95C.rep_compare.pdf
-rw-r--r--  1 pterry amundsen  7057759 Dec 21 22:06 95T.rep_compare.pdf
# so, scp over to macbook pro to view /.../testing/trinitypdf_qc95CandT

cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing/trinity211pdf_qc95CandT
scp pterry@crane.unl.edu:/work/amundsen/pterry/Trin21test/95C1-3T1-3/qc_comp_reps/95C.rep_compare.pdf .

scp pterry@crane.unl.edu:/work/amundsen/pterry/Trin21test/95C1-3T1-3/qc_comp_reps/95T.rep_compare.pdf .
# so looks like '--compare_replicates' worked.
# to try '--sample_cor_matrix'
# i.e., 'Compare Replicates Across Samples' section.

cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing
scp slurm_comp_reps_for_each_sample_sampcormatrix.sh pterry@crane.unl.edu:/home/amundsen/pterry/scripts/

ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /home/amundsen/pterry/scripts
ls -al
sbatch slurm_comp_reps_for_each_sample_sampcormatrix.sh 2826924 11:10pm => ??:??am, 
squeue -u pterry  ## PD
[pterry@login.crane scripts]$ squeue -u pterry
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/qc_comp_reps
-rw-r--r--  1 pterry amundsen     6157 Dec 21 23:09 Trinity_trans.counts.matrix.minCol10.minRow10.log2.sample_cor_matrix.pdf
# so scp over, view

cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing/trinity211pdf_qc95CandT
scp pterry@crane.unl.edu:/work/amundsen/pterry/Trin21test/95C1-3T1-3/qc_comp_reps/Trinity_trans.counts.matrix.minCol10.minRow10.log2.sample_cor_matrix.pdf .
# as expect, replicates are more highly correlated within samples than between samples.

# now PCA plot:

cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing
scp slurm_comp_reps_for_each_sample_PCA.sh pterry@crane.unl.edu:/home/amundsen/pterry/scripts/

ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /home/amundsen/pterry/scripts
ls -al
sbatch slurm_comp_reps_for_each_sample_PCA.sh 2826963 11:42pm => ??:??am, 
squeue -u pterry  ## PD
# PD for about 10 min, so forget for tonight.

cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/qc_comp_reps
ls -al
-rw-r--r--  1 pterry amundsen     3611 Dec 22 00:14 Trinity_trans.counts.matrix.minCol10.minRow10.log2.principal_components.pdf
# so scp to macbook pro, look at it
cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing/trinity211pdf_qc95CandT
scp pterry@crane.unl.edu:/work/amundsen/pterry/Trin21test/95C1-3T1-3/qc_comp_reps/Trinity_trans.counts.matrix.minCol10.minRow10.log2.principal_components.pdf .
# corrupt file, Adobe can't read ??????????????????

12/22/15:
# Try pCA creation again ??
ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/qc_comp_reps
cp Trinity_trans.counts.matrix.minCol10.minRow10.log2.principal_components.pdf Trinity_trans.counts.matrix.minCol10.minRow10.log2.principal_components.pdf_corrupt
rm Trinity_trans.counts.matrix.minCol10.minRow10.log2.principal_components.pdf
cd /home/amundsen/pterry/scripts
ls -al
sbatch slurm_comp_reps_for_each_sample_PCA.sh 2828155 9:36pm => ??:??am, 
squeue -u pterry  ## PD
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/qc_comp_reps
-rw-r--r--  1 pterry amundsen     3611 Dec 22 09:35 Trinity_trans.counts.matrix.minCol10.minRow10.log2.principal_components.pdf
# so try scp this to macbook pro to view
scp pterry@crane.unl.edu:/work/amundsen/pterry/Trin21test/95C1-3T1-3/qc_comp_reps/Trinity_trans.counts.matrix.minCol10.minRow10.log2.principal_components.pdf .
# 2nd attempt, this pdf file also corrupt, Adobe can't read ????????
# Note : with the 'example data', dir .../testing/trinity211_qc_testing, the PCA pdf file can be read by Adobe reader ????????????????????????
# should I try 'globus' rather than 'scp' ?????????????

# On to 'Differential Expression Analysis Using a Trinity Assembly' section.
# looks like indicating need prevly have prepared (the 6 '.isoforms.results' files ?????????????????
 Or perhaps the 'counts.matrix' file ????????# in 
 -rw-r--r--  1 pterry amundsen    9495163 Dec 19 23:06 Trinity_trans.counts.matrix
# file in /work/amundsen/pterry/Trin21test/95C1-3T1-3 dir or subdir qc_comp_reps

# 'Running Differential Expression Analysis' section.
Prevly installed: edgeR, R, add'l R packages
# Q: difference, 'transcripts.counts.matrix' file & 'genes.counts.matrix' file ?????????????????????????????
# 'Identifying DE features: With biological replicates (PREFERRED)' section.

12/24/15:
cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing
scp slurm_run_DE_analysis.sh pterry@crane.unl.edu:/home/amundsen/pterry/scripts/

ssh -Y pterry@crane.unl.edu
# Rrq096mN
#mkdir DEanalysis
#cd DEanalysis
#cp ../Trinity_trans.counts.matrix .
#cp ../qc_comp_reps/samples.txt .
#ls -al
# now code to run slurm
cd /home/amundsen/pterry/scripts
ls -al
sbatch slurm_run_DE_analysis.sh 2840120 10:18am => ??:??am, 
squeue -u pterry  ## PD
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/DEanalysis
ls -al
more job.2840120.err  ## no apparent errors flagged
more job.2840120.out
cd edgeR.115118.dir 
ls -al
-rw-r--r-- 1 pterry amundsen     1033 Dec 24 10:18 Trinity_trans.counts.matrix.95C_vs_95T.95C.vs.95T.EdgeR.Rscript

-rw-r--r-- 1 pterry amundsen 15079499 Dec 24 10:18 Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results

-rw-r--r-- 1 pterry amundsen  2100598 Dec 24 10:18 Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.MA_n_Volcano.pdf

# so looks like what expecting from section 'Differential Expression Output Explained'. Tho, repeat of '95C.vs.95T' in R script name not as in 'Differential Expression Output Explained' ????
less Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results
# **how** calc columns logCPM, PValue, FDR ??????????????????
# Q: looks like 5 'number' colm headings, but only 4 number fields in file table ?????????????????????????????????????? 

cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing
scp pterry@crane.unl.edu:/work/amundsen/pterry/Trin21test/95C1-3T1-3/DEanalysis/edgeR.115118.dir/Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.MA_n_Volcano.pdf .
# 2.1 Mb
# p-5 of section 'Differential Expression Output Explained', why only 2 plots in 'Differential Expression Output Explained', but 4 in pdf file ????????????????????
# Note: 'insufficient memory in printer to print page' ???????????????

STOPPED

12/25/15:
# Next, 'Extracting and clustering differentially expressed transcripts' section.
# 'cluster the transcripts according to their patterns of differential expression across the samples', Q: like to know bit more ????????
# To do this, you can run the following from within the DE output directory (edgeR.115118.dir), by running the script inside 'slurm_analyze_diff_expr.sh' file.

cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing
scp slurm_analyze_diff_expr.sh pterry@crane.unl.edu:/home/amundsen/pterry/scripts/

ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /home/amundsen/pterry/scripts
ls -al
sbatch slurm_analyze_diff_expr.sh 2857620 11:01am => ??:??am, 
squeue -u pterry  ## PD
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/DEanalysis/edgeR.115118.dir
# error, need --samples parameter
# running wi --samples param., don't see error mesages

12/26/15:
# to check: files output, see p-6 of 9
# which will extract all genes that have P-values at most 1e-3 (meaning this context ?????) and are at least 2^2 fold differentially expressed.
# 1st,
-rw-r--r-- 1 pterry amundsen    308395 Dec 25 11:01 Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95C-UP.subset
id      logFC   logCPM  PValue  FDR     95C1    95C2    95C3    95T1    95T2    95T3
TRINITY_DN31372_c0_g1_i1        -13.303565262659        9.83961096097471        6.64875466320565e-40    1.06371431230228e-34    286.387 488.956 206.128 0.000   0.000   0.085
# 2nd
-rw-r--r-- 1 pterry amundsen    547935 Dec 25 11:01 Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95T-UP.subset
# 3rd,
-rw-r--r-- 1 pterry amundsen    616505 Dec 25 11:01 diffExpr.P1e-3_C2.matrix.log2.dat
# All features found DE in any of these pairwise comparisons consolidated into a single expression matrix:
95C1    95C2    95C3    95T1    95T2    95T3
TRINITY_DN44017_c0_g1_i2        5.02427534791448        5.25179482264146        5.54460902638193        3.12416267883585        2.46205231879643        2.35698889179248
# 4th,
-rw-r--r-- 1 pterry amundsen       612 Dec 25 11:01 diffExpr.P1e-3_C2.matrix.log2.sample_cor.dat
# A Pearson correlation matrix for pairwise sample comparisons based on this set of DE features.
# Q: view what supposed to get in 5th, next, 'pdf'
# 5th,
-rw-r--r-- 1 pterry amundsen      6122 Dec 25 11:01 diffExpr.P1e-3_C2.matrix.log2.sample_cor_matrix.pdf
# clustered heatmap showing the above sample correlation matrix.
# 6th,
-rw-r--r-- 1 pterry amundsen    325281 Dec 25 11:01 diffExpr.P1e-3_C2.matrix.log2.centered.genes_vs_samples_heatmap.pdf
# clustered heatmap of DE genes vs. sample replicates.
# Q: what is this ?????????????????????????????????????????
# Q: 'all.RData' compared to '.RData' ???????????????????????
# So scp to 'pdf' files over for viewing.

cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing/trinity211pdf_qc95CandT

scp pterry@crane.unl.edu:/work/amundsen/pterry/Trin21test/95C1-3T1-3/DEanalysis/edgeR.115118.dir/diffExpr.P1e-3_C2.matrix.log2.sample_cor_matrix.pdf .
# viewing ok wi adobe, looks ok as per p-6 of 9 example.
scp pterry@crane.unl.edu:/work/amundsen/pterry/Trin21test/95C1-3T1-3/DEanalysis/edgeR.115118.dir/diffExpr.P1e-3_C2.matrix.log2.centered.genes_vs_samples_heatmap.pdf .
# viewing ok wi adobe, looks ok as per p-7 of 9 example.

# 'all.RData', is it the following ???????????????????????????
-rw-r--r-- 1 pterry amundsen 145702813 Dec 25 11:01 diffExpr.P1e-3_C2.matrix.RData

# Next, section ***'Gene Ontology (GO) Enrichment Analysis on Differentially Expressed Genes'***
# ***Before*** running GO-Seq, you must follow the relevant **Trinotate** protocol to generate the GO assignments leveraged by this process.
# https://github.com/trinityrnaseq/trinityrnaseq/wiki/Running-GOSeq

Use http://trinotate.sf.net[Trinotate] to generate an annotation report ***'trinotate.xls'***, which includes top-matching blast matches from SwissProt (and optionally UniRef) and any corresponding Gene Ontology (GO) assignments from the TrEMBL/SwissProt databases.
# go to
http://trinotate.github.io/

12/29-30/15:
TransDecoder identifies candidate coding regions within transcript sequences, such as those generated by de novo RNA-Seq transcript assembly using Trinity

1. Files needed for execution (trinotate)

    Trinity.fasta - Final product containing all the transcripts assembled by Trinity

    Trinity.fasta.transdecoder.pep - Most likely Longest-ORF peptide candidates generated from the Trinity Assembly. Instructions for generation of this file can be found here: http://transdecoder.github.io/

# so, go to obtain Trinity.fasta.transdecoder.pep, go to
# http://transdecoder.github.io/

Running TransDecoder
# needed Adam to install Trinity 2.1.1 & TransDecoder-2.0.1 on Crane

Predicting coding regions from a transcript fasta file

# Step 1: extract the long open reading frames
# TransDecoder.LongOrfs -t target_transcripts.fasta

ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3
mkdir transdecoder
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/transdecoder
# cp ../Trinity.fasta .  # may perhaps access without copying ????
# create slurm

cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing
scp slurm_run_transdecoderLong.sh pterry@crane.unl.edu:/home/amundsen/pterry/scripts/

ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /home/amundsen/pterry/scripts
ls -al
sbatch slurm_run_transdecoderLong.sh 2915071 7:24pm => ??:??am, 
squeue -u pterry  ## PD
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/transdecoder
cd Trinity.fasta.transdecoder_dir
-rw-r--r-- 1 pterry amundsen  55091096 Dec 30 19:31 longest_orfs.pep
cd ..
sacct -j 2915071 -o start,end
              Start                 End 
------------------- ------------------- 
2015-12-30T19:24:14 2015-12-30T19:31:19 
2015-12-30T19:24:14 2015-12-30T19:31:19 
# ~ 7 min run
more job.2915071.out
more job.2915071.err
...
#################################
### Done preparing long ORFs.  ###
##################################

	Use file: Trinity.fasta.transdecoder_dir/longest_orfs.pep  for Pfam and/
or BlastP searches to enable homology-based coding region identification.

	Then, run TransDecoder.Predict for your final coding region predictions.
**********************************************************
# So, ***SKIP*** 'step 2' foe now, ***BUT***, later will want to try. Note: ***HOW*** access '-db uniprot_sprot.fasta' when want to try step 2 ???????????????????????????
***********************************************************

# step 3
# run 'Predict' from 'transdecoder' dir.
# create slurm script

cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing
scp slurm_run_transdecoderPredict_95C1-T3.sh pterry@crane.unl.edu:/home/amundsen/pterry/scripts/

ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /home/amundsen/pterry/scripts
ls -al
sbatch slurm_run_transdecoderPredict_95C1-T3.sh 2915529 11:28pm => ??:??am, 
squeue -u pterry  ## PD
more job.2915529.err
tail job.2915529.err
transdecoder is finished.  See output files Trinity.fasta.transdecoder.*
more job.2915529.out
sacct -j 2915529 -o start,end
              Start                 End 
------------------- ------------------- 
2015-12-30T23:37:39 2015-12-31T00:14:21 
2015-12-30T23:37:39 2015-12-31T00:14:21 
# so ~ 37 min run.

cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/transdecoder
-rw-r--r--  1 pterry amundsen  36511970 Dec 31 00:12 Trinity.fasta.transdecoder.pep
# so looks like ran ok.
Ck sizes of files:
wc Trinity.fasta.transdecoder.pep
  458936  1054848 36511970 Trinity.fasta.transdecoder.pep
cd Trinity.fasta.transdecoder_dir
wc longest_orfs.pep
  316734  1108569 55091096 longest_orfs.pep
cd ..
cd ..
cd trinity_out_dir
wc Trinity.fasta
  2459588   8071010 194832811 Trinity.fasta
# what to think ?????????????????????


12/31/15:
# back to http://trinotate.github.io/,
# section '2. Capturing BLAST Homologies'

(STOPPED)

cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing
scp slurm_run_trinotate_blastx_95C1-T3.sh pterry@crane.unl.edu:/home/amundsen/pterry/scripts/


ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3
mkdir trinotate

cd /home/amundsen/pterry/scripts
ls -al
sbatch slurm_run_trinotate_blastx_95C1-T3.sh 2918371 6:20pm => ??:??am, 
squeue -u pterry  ## PD

less job.2918371.err
Selenocysteine (U) at position 690 replaced by X
Selenocysteine (U) at position 690 replaced by X
Selenocysteine (U) at position 192 replaced by X
Error: (1431.1) FASTA-Reader: Warning: FASTA-Reader: Title is very long: 1237 characters (max is 1000)
Error: (1431.1) FASTA-Reader: Warning: FASTA-Reader: Title is very long: 1180 characters (max is 1000)
Error: (1431.1) FASTA-Reader: Warning: FASTA-Reader: Title is very long: 1260 characters (max is 1000)
...
# end of file has same output
# What to think of the 'errors' ????????????????
# tail job.2918371.err
more job.2918371.out  ## zero bytes
sacct -j  2918371 -o start,end
              Start                 End 
------------------- ------------------- 
2015-12-31T18:20:21 2016-01-01T21:11:43 
2015-12-31T18:20:21 2016-01-01T21:11:43 
# so 26 hrs 52 min. to run.

-rw-r--r--  1 pterry amundsen 12722936 Jan  1 21:11 blastx.outfmt6
less blastx.outfmt6
TRINITY_DN10610_c0_g1_i1        ARGO_PECCP      41.18   34      19      1       317     415     121     154     6.3     30.4
TRINITY_DN10610_c0_g2_i1        ARGO_PECCP      41.18   34      19      1       315     413     121     154     6.3     30.4
...
TRINITY_DN38713_c0_g1_i2        APX8_ORYSJ      82.76   29      5       0       1       87      330     358     4e-08   55.1
TRINITY_DN38713_c0_g2_i1        APX7_ORYSJ      91.79   268     22      0       794     1597    91      358     0.0       525
(END) 
# need go, find defs of columns again ????????????????????


01/01/16:
# prev still running, now 18 hrs, note, did not match nodes wi threads in slurm_run_trinotate_blastx_95C1-T3.sh ???????????????????????????????

# mean time proceed to 'blastp non-optional step, section '2. Capturing BLAST Homologies', http://trinotate.github.io/

cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing
scp slurm_run_trinotate_blastp_95C1-T3.sh pterry@crane.unl.edu:/home/amundsen/pterry/scripts/


ssh -Y pterry@crane.unl.edu
# Rrq096mN
#cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/trinotate
#mkdir blastp

cd /home/amundsen/pterry/scripts
ls -al
sbatch slurm_run_trinotate_blastp_95C1-T3.sh 2920667 1:58pm => ??:??am, 
squeue -u pterry  ## PD
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/trinotate/blastp

# two jobs running when went to Mex.
# both done 2am, 01/02/16

#Note: module help trinotate

less job.2920667.err
Selenocysteine (U) at position 523 replaced by X
Selenocysteine (U) at position 106 replaced by X
Selenocysteine (U) at position 106 replaced by X
...

sacct -j  2920667 -o start,end
              Start                 End 
------------------- ------------------- 
2016-01-01T14:03:30 2016-01-01T20:54:14 
2016-01-01T14:03:30 2016-01-01T20:54:14 
## 6 hrs 51 min.

-rw-r--r-- 1 pterry amundsen 6857589 Jan  1 20:54 blastp.outfmt6
less blastp.outfmt6
TRINITY_DN10001_c0_g1_i1|m.106285       POF11_SCHPO     25.69   471     252     12      292     713     76      497     3e-47     179
TRINITY_DN10001_c0_g2_i1|m.106290       POF11_SCHPO     25.69   471     252     12      292     713     76      497     3e-47     179

# perhaps should do bit more looking, V. Buffalo bk, ????????????


01/13/16:
# now section, Trinotate: Loading Above Results into a Trinotate SQLite Database
# 1. Retrieve the Trinotate Pre-generated Resource SQLite database
# create a directory to wget the sqlite db to.

STOPPED

01/15/16:
# ref: 11/16/15: above
ssh -Y pterry@crane.unl.edu
# Rrq096mN 
# cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/trinotate
# mkdir sqlitedb95C1-T3
#cd sqlitedb95C1-T3
srun --pty --ntasks-per-node=4 --mem 4gb --qos=short $SHELL
[pterry@login.crane sqlitedb95C1-T3]$ srun --pty --ntasks-per-node=4 --mem 4gb --qos=short $SHELL
Can't locate local/lib.pm in @INC (@INC contains: /home/amundsen/pterry/perl5/lib/perl5/x86_64-linux-thread-multi /home/amundsen/pterry/perl5/lib/perl5/x86_64-linux-thread-multi /home/amundsen/pterry/perl5/lib/perl5 /usr/local/lib64/perl5 /usr/local/share/perl5 /usr/lib64/perl5/vendor_perl /usr/share/perl5/vendor_perl /usr/lib64/perl5 /usr/share/perl5 .).
BEGIN failed--compilation aborted.
[pterry@c0907.crane sqlitedb95C1-T3]$ 
# get resources but ERROR message ???????????????????????????

cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/trinotate/sqlitedb95C1-T3
wget "https://data.broadinstitute.org/Trinity/Trinotate_v2.0_RESOURCES/Trinotate.sprot_uniref90.20150131.boilerplate.sqlite.gz" -O Trinotate.sqlite.gz
# started 8:59pm => 
unix command stopped at 97%, hit return after a while, => 'broken pipe', left me at 'laptop' prompt, if log back in, can I do a check sum for this dwnload ??????????????????????????????
# Q: should I have used 'srun' for wget task ?????????????????
# 2nd attempt, ran wget with 'srun'. This time 'broken pipe' after hit return after command line 'stopped' at 35% ???????????????? 
-rw-r--r-- 1 pterry amundsen  916897792 Jan 15 21:38 Trinotate.sqlite.gz
-rw-r--r-- 1 pterry amundsen 1488153633 Feb  5  2015 Trinotate.sqlite.gz_prev
# fewer bytes transferred than prev attempt ???????????????
# could I use the /work/amundsen/pterry/Trin21test/sqlitedbtest
-rw-r--r--  1 pterry amundsen 6145534976 Nov 20 23:09 Trinotate.sqlite
from Nov 20, 2015 ??????????????????????????????????
# Try on macbook laptop thru firefox browser, start 10:20 pm => aborts after min. or two ????

01/19/16:
# talked to Adam(HCC), thinks source server may be dropping link before wget whole file transferred. Note: so he successfully got thr file today, same length as one of my two attempts.
# Note: looks like his dnload did not change the name from 
Trinotate.sprot_uniref90.20150131.boilerplate.sqlite.gz
# to
Trinotate.sqlite.gz
-rw-r--r-- 1 pterry amundsen 1488153633 Jan 19 11:49 Trinotate.sprot_uniref90.20150131.boilerplate.sqlite.gz
-rw-r--r-- 1 pterry amundsen 1488153633 Feb  5  2015 Trinotate.sqlite.gz_prev
# so change now
cp Trinotate.sprot_uniref90.20150131.boilerplate.sqlite.gz Trinotate.sqlite.gz

# so resume from Adam's dnload, try **not** using 'srun'. Perhaps later try with?

ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/trinotate/sqlitedb95C1-T3
ls -al
-rw-r--r-- 1 pterry amundsen 1488153633 Jan 19 11:49 Trinotate.sprot_uniref90.20150131.boilerplate.sqlite.gz
-rw-r--r-- 1 pterry amundsen 1488153633 Jan 19 23:27 Trinotate.sqlite.gz
-rw-r--r-- 1 pterry amundsen 1488153633 Feb  5  2015 Trinotate.sqlite.gz_prev

gunzip Trinotate.sqlite.gz  ## ~1.5 to ~6.1 gb
# Note: **difference**, Nov 20, & Jan 19 in size Trinotate.sqlite is 277,504 ******????????????????????*****************???????????????????
# anyway, proceed with following: 

01/20/16:
ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/trinotate/sqlitedb95C1-T3
ls -al

# sec 2
# note: line 1893, not using 'srun' to run following
module load trinotate/2.0
/util/opt/trinity/2.1/gcc/4.8/util/support_scripts/get_Trinity_gene_to_trans_map.pl ../../trinity_out_dir/Trinity.fasta > Trinity.fasta.gene_trans_map
ls -al
# got 
-rw-r--r-- 1 pterry amundsen    7754524 Jan 20 09:59 Trinity.fasta.gene_trans_map

#Trinotate Trinotate.sqlite init --gene_trans_map Trinity.fasta.gene_trans_map --transcript_fasta Trinity.fasta --transdecoder_pep Trinity.fasta.transdecoder.pep

Trinotate Trinotate.sqlite init --gene_trans_map Trinity.fasta.gene_trans_map --transcript_fasta ../../trinity_out_dir/Trinity.fasta --transdecoder_pep ../../transdecoder/Trinity.fasta.transdecoder.pep

# Loading complete..
# looks like everything ok.
ls -al  ### no new files in current dir.
# without srun, **don't** see error messages
# p-7 of 9
# 3. Loading BLAST homologies
# load protein hits

# resume copying line 1904 ...
Trinotate Trinotate.sqlite LOAD_swissprot_blastp ../blastp/blastp.outfmt6
BlastDbase loading complete..
# so looks like ok.
# from line 1909
Trinotate Trinotate.sqlite LOAD_swissprot_blastx ../blastx.outfmt6
BlastDbase loading complete..
# so looks like ok.

# from line 1912
# Trinotate: Output an Annotation Report
# Trinotate Trinotate.sqlite report [opts] > trinotate_annotation_report.xls
# omit '[opts]', see what happens
Trinotate Trinotate.sqlite report > trinotate_annotation_report.xls
# from login node, ran 20 min, 
-rw-r--r-- 1 pterry amundsen   49090560 Jan 20 10:34 trinotate_annotation_report.xls
# but did not finish.
# so while not logging out, try 'srun'
cp trinotate_annotation_report.xls trinotate_annotation_report.xls_prev
rm trinotate_annotation_report.xls

srun --pty --ntasks-per-node=4 --mem 4gb --qos=short $SHELL
# got usual @INC error message ??????
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/trinotate/sqlitedb95C1-T3
module load trinotate/2.0
Trinotate Trinotate.sqlite report > trinotate_annotation_report.xls
# start 10:46am => 11:21am
exit
# **to do** following for 95C1-T3 data
-rw-r--r-- 1 pterry amundsen   78676610 Jan 20 11:13 trinotate_annotation_report.xls
less trinotate_annotation_report.xls
wc trinotate_annotation_report.xls
  178728  6371013 78676610 trinotate_annotation_report.xls
# Q: how handle .xls file on crane ??????????????????????????

01/21/16:
# Now section **'Gene Ontology (GO) Enrichment Analysis on Differentially Expressed Genes'** of 
https://github.com/trinityrnaseq/trinityrnaseq/wiki/Trinity-Differential-Expression#gene-ontology-go-enrichment-analysis-on-differentially-expressed-genes

# Before running GO-Seq, you must follow the **relevant Trinotate** protocol to generate the GO assignments leveraged by this process.
# **relevant Trinotate**, a link to
https://github.com/trinityrnaseq/trinityrnaseq/wiki/Running-GOSeq
# 'Running GOSeq'

# prevly generated 'trinotate.xls' report. (see 01/20/16 above.
# ... which includes top-matching blast matches from SwissProt (and optionally UniRef) and any corresponding Gene Ontology (GO) assignments from the TrEMBL/SwissProt databases.

# 'Extract GO assignments per gene' section.
# ${TRINOTATE_HOME}/util/extract_GO_assignments_from_Trinotate_xls.pl --Trinotate_xls trinotate.xls -G --include_ancestral_terms > go_annotations.txt

ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/trinotate/sqlitedb95C1-T3
mkdir GOassigns
cd GOassigns
srun --pty --ntasks-per-node=4 --mem 4gb --qos=short $SHELL
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/trinotate/sqlitedb95C1-T3/GOassigns
module load trinotate/2.0

/util/opt/trinotate/2.0/util/extract_GO_assignments_from_Trinotate_xls.pl --Trinotate_xls ../trinotate_annotation_report.xls -G --include_ancestral_terms > go_annotations.txt

Done processing, writing output.

Finished.
# looks like ran ok.
exit
ls -al
# examine output file ???????
less go_annotations.txt
# looks like for each trinity transcript, a list of GO assignments are associated.
-rw-r--r-- 1 pterry amundsen 17377720 Jan 21 23:23 go_annotations.txt

wc go_annotations.txt
   31816    63632 17377720 go_annotations.txt
# so ~ 32k trinity transcripts(debruign graphs) ?????????????????

# Q: what next ????????????
# a guess, go down to 'GO-Seq on Differentially Expressed Features', skip 'Run GOseq' section' ????????????????????????????
# This section links circularly back: See **DE analysis** link for instructions on automatically running GO-Seq on significantly DE features.
# **Assuming** this means go back to 'Gene Ontology (GO) Enrichment Analysis on Differentially Expressed Genes' section of https://github.com/trinityrnaseq/trinityrnaseq/wiki/Trinity-Differential-Expression#gene-ontology-go-enrichment-analysis-on-differentially-expressed-genes
# Q: 'gene lengths', check did I do transcript lengths, any confusion here ????????????????? ?????????????
# apparently, see like 95C1.genes.results, etc. But have 5 more files like this in dir 95C1-3T1-3 ????????????
# am I ready to run 'analyze_diff_expr.pl' script ??????????????????????

01/24/16:
# do some checking on files which may create a 'genes.lengths.txt' file from (see section run GOseq in 'Running GOSeq' in https://github.com/trinityrnaseq/trinityrnaseq/wiki/Running-GOSeq)
# so compare say 95C1.genes.results with 95T1.genes.results files. Initially colm 1 from each.

ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3
more 95C1.genes.results
more 95T1.genes.results
wc 95C1.genes.results
  115192   806344 10089771 95C1.genes.results
wc 95T1.genes.results
  115192   806344 10112734 95T1.genes.results
# so same number of lines
cat 95C1.genes.results | cut -f 1 > 95C1_colm1.txt
cat 95T1.genes.results | cut -f 1 > 95T1_colm1.txt
wc 95C1_colm1.txt
wc 95T1_colm1.txt
more 95C1_colm1.txt
more 95T1_colm1.txt
diff -u 95C1_colm1.txt 95T1_colm1.txt > diffC1T1.txt
# 0 bytes in diffC1T1.txt
# so assume/conclude all 6 95??.genes.results files have same gene IDs for all rows in the files.

# to be complete, check if colm 3 is same betw. 95C1.genes.results & 95T1.genes.results
cat 95C1.genes.results | cut -f 3 > 95C1_colm3.txt
cat 95T1.genes.results | cut -f 3 > 95T1_colm3.txt
wc 95C1_colm3.txt
wc 95T1_colm3.txt
more 95C1_colm3.txt
more 95T1_colm3.txt
diff -u 95C1_colm3.txt 95T1_colm3.txt > diffC1T1_colm3.txt
-rw-r--r--  1 pterry amundsen     556059 Jan 24 14:30 diffC1T1_colm3.txt
# what to think
more diffC1T1_colm3.txt
# so 1st 4 changes betw files in colm3 are
-10, +31, +4.02, +0.01
# percentages are: 4.1,1.4,1.8,.036
# so mean percent difference = 1.834%, range is 4.1% to 0.036%
# conclude if these 4 are representative of diffs in gene lengths, can just use values from 95C1.genes.results file. **Q**: is this ok ??????????????

STOPPED

# Q: do I have goseq installed, see line 1208 above ???????????????? Need check if installed (perhaps 'library(GOseq)' after do 'module load R/3.2') ??????
ssh -Y pterry@crane.unl.edu
# Rrq096mN 



#modify analyze_diff_expr.pl by adding 3 addl parameters, place in slurm run,
# Q: what files expect in output ???????
# do in new dir to keep output just for this step easily distinguishable.

ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3
cd DEanalysis
cd edgeR.115118.dir
mkdir GOseqonDEgenes
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/DEanalysis/edgeR.115118.dir/GOseqonDEgenes

module load compiler/gcc/4.8
module load bowtie/1.1
module load samtools/1.2
module load trinity/2.1
module load R/3.2

R
library(goseq)
# it loaded, so apparently prevly installed.

# So go forward with creating 'genes.lengths.txt' file using 95C1.genes.results.
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/DEanalysis/edgeR.115118.dir/GOseqonDEgenes
cat ../../../95C1.genes.results | cut -f 1,3 > genes.lengths.txt
-rw-r--r-- 1 pterry amundsen 3345152 Jan 24 21:06 genes.lengths.txt
more genes.lengths.txt
gene_id	length
TRINITY_DN10001_c0_g1	3179.00
TRINITY_DN10001_c0_g2	3178.00
wc genes.lengths.txt
 115192  230384 3345152 genes.lengths.txt

#modify slurm analyze_diff_expr.pl by adding 3 addl parameters, place in slurm run,
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/trinotate/sqlitedb95C1-T3/GOassigns
ls -al

# Ready try run
logout
cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing
scp slurm_analyze_diff_expr_wiGO.sh pterry@crane.unl.edu:/home/amundsen/pterry/scripts/

ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /home/amundsen/pterry/scripts
ls -al
sbatch slurm_analyze_diff_expr_wiGO.sh 3120381 11:07pm => ??:??am, 
squeue -u pterry  ## PD still at 11:30pm
[pterry@login.crane GOseqonDEgenes]$ squeue -u pterry
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           3120381     batch TJob_ana   pterry PD       0:00      1 (ReqNodeNotAvail(Unavailable:c1
[pterry@login.crane GOseqonDEgenes]$ 
# What does this mean ??????????????????

01/25/16:
# crane to go down for maintenance 9am, 01/26/16. To do submit slurm with say 15 hr time.
cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing
scp slurm_analyze_diff_expr_wiGO_15hr.sh pterry@crane.unl.edu:/home/amundsen/pterry/scripts/
ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /home/amundsen/pterry/scripts
ls -al
sbatch slurm_analyze_diff_expr_wiGO_15hr.sh 3123392 12:23pm => ??:??am, 
squeue -u pterry  ## PD still at 11:30pm
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/DEanalysis/edgeR.115118.dir/GOseqonDEgenes
ls -al
less job.3123392.err
Error, no DE_results files!  This needs to be run in the edgeR or DESeq output directory at /util/opt/trinity/2.1/gcc/4.8/Analysis/DifferentialExpression/analyze_diff_expr.pl line 127.
job.3123392.err (END) 

# ok, fixed slurm to be run in edgeR.115118.dir directory.
cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing
scp slurm_analyze_diff_expr_wiGO_12hr.sh pterry@crane.unl.edu:/home/amundsen/pterry/scripts/
ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /home/amundsen/pterry/scripts
ls -al
sbatch slurm_analyze_diff_expr_wiGO_12hr.sh 3128028 3:39pm => ??:??am, 
squeue -u pterry  ## R
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/DEanalysis/edgeR.115118.dir
less job.3128028.err
more job.3128028.err
more job.3128028.out
# no error messages apparent in .err or .out Files
# Q: how to examine directory, determine what have ??????????????
# Note: 4 GOseq.depleted or GOseq.enriched files have only headers, no data in rows below ???????????????????????
# To do, check out the 4 pdf files ????????????

sacct -j  3128028 -o start,end
              Start                 End 
------------------- ------------------- 
2016-01-25T15:38:52 2016-01-25T15:40:59 
2016-01-25T15:38:52 2016-01-25T15:40:59 
# 2 min 7 sec

02/01/16:
#Think make **plan** to examine files from Trinity.fasta to run of 
sbatch slurm_analyze_diff_expr_wiGO_12hr.sh
# see if can determine why 4 GOseq.depleted or GOseq.enriched files have only headers, no data in rows below ???????????????????????

02/08/16:
# try apply what learned from V. Buffalo book, p-194 thru 247.
# initially try understand bit more about Trinity.fasta file in 

# from 12/16/15,
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/trinity_out_dir
-rw-r--r-- 1 pterry amundsen   194832811 Dec 16 13:51 Trinity.fasta
# so ~ **195 Mb**
less Trinity.fasta
>TRINITY_DN10610_c0_g1_i1 len=460 path=[946:0-169 948:170-236 943:237-459] [-1, 946, 948, 943, -2]
CGCATGCTGTTTGTGCAGTGGTGCAGTTCAGAGCGTTGGTGTTGAGCCGGGAAATGGGTA
wc Trinity.fasta
[pterry@login.crane trinity_out_dir]$ wc Trinity.fasta
  2459588   8071010 194832811 Trinity.fasta
# Q: would understanding what in the ">" lines help me ??????????????

STOPPED

02/10/16:
ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/trinity_out_dir
grep -c "^>" Trinity.fasta
165459
# 2459588/165459 = 14.86524

# Next file,
# from 01/24/16,
95C1.isoforms.results
95C1.genes.results
# To do: examine these files
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3
more 95C1.genes.results
gene_id	transcript_id(s)	length	effective_length	expected_count	
TPM	FPKM
TRINITY_DN10001_c0_g1	TRINITY_DN10001_c0_g1_i1	3179.00	3179.00	0.00	
0.00	0.00
TRINITY_DN10001_c0_g2	TRINITY_DN10001_c0_g2_i1	3178.00	3178.00	0.00	
0.00	0.00
wc 95C1.genes.results
  115192   806344 10089771 95C1.genes.results
grep -c "^TR" 95C1.genes.results
115191    ## so diff of 1 probably the header line.
# difference 'genes' & 'isoforms' files ??????????????????
# apparently, for 1 thing, 1st two columns in **reverse** order, 'transcript_id' & 'gene_id'
# Q: diff. 'transcript_id' & 'gene_id' ??????????????????******?????????


02/10/16:
ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3
srun --pty --ntasks-per-node=4 --mem 4gb --qos=short $SHELL
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3

module load R/3.2  ## 3.2.1
R
# attempt analyze in R on crane ???????????
getwd()
# setwd("/work/amundsen/pterry/Trin21test/95C1-3T1-3")  # if need to ???????????????
genes95C1 <- read.delim("95C1.genes.results", header=TRUE)
colnames(genes95C1)
head(genes95C1, n=3)
dim(genes95C1)
summary(genes95C1$expected_count)
     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
     0.00      0.00      1.00     75.27      6.25 270700.00
# skewed to right, a **lot**.     
q()
exit
# perhaps a plot of expected_count colm.
module load R/3.2  ## 3.2.1
R
getwd()
# install.packages("ggplot2")
library(ggplot2)
genes95C1 <- read.delim("95C1.genes.results", header=TRUE)
dim(genes95C1)
ggplot(genes95C1, aes(x=gene_id, y=expected_count)) + geom_point()
# need update xquartz ...,7 to ....2.7.8 ...dmg ?????????????????????
# perhaps find num. counts > 6.25, 3rd Qu.

02/13/16:
# find num. reads in output95C1_GATCAG_L006_R1_001.trimmed.fastq file.
ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3
wc output95C1_GATCAG_L006_R1_001.trimmed.fastq
  77525572   96906965 4292886820 output95C1_GATCAG_L006_R1_001.trimmed.fastq
less output95C1_GATCAG_L006_R1_001.trimmed.fastq
@HWI-ST1023:164:D1FJNACXX:6:1101:1189:2079 1:N:0:GATCAG
GGGATGGTTACTGGAAGTGGTTTGCTGGCAACCTTGCCTCCGGTGGTGCTGCCGGTGCTTCCTCCCTGTTTTTCGTGTAC
+
CCCFFFFDHHHHHJJJJEIIHHJIIGHIIJJIJJJIJJIJIJJDHI;FEGIIIII;BACECDDECDCE@CACBC@A19<A
# so Trinity.fasta record names **don't obviously relate** to those in 'reads' file. BUT, should there not be some relationship ?????????????????
ls -al
-rw-r--r--  1 pterry amundsen 4292886820 Dec 14 22:24 output95C1_GATCAG_L006_R1_001.trimmed.fastq
grep -c "^@HWI" output95C1_GATCAG_L006_R1_001.trimmed.fastq
19381393
# so, Trinity.fasta 165,459 "^>" records, 95C1 read/fastq file has 19,381,393 records.

srun --pty --ntasks-per-node=4 --mem 4gb --qos=short $SHELL
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3

module load R/3.2  ## 3.2.1
R
# attempt analyze in R on crane ???????????
getwd()
# setwd("/work/amundsen/pterry/Trin21test/95C1-3T1-3")  # if need to ???????????????
genes95C1 <- read.delim("95C1.genes.results", header=TRUE)
colnames(genes95C1)
[1] "gene_id"          "transcript_id.s." "length"           "effective_length"
[5] "expected_count"   "TPM"              "FPKM"        
head(genes95C1, n=3)
                gene_id         transcript_id.s. length effective_length
1 TRINITY_DN10001_c0_g1 TRINITY_DN10001_c0_g1_i1   3179             3179
  expected_count TPM FPKM
1              0   0    0
dim(genes95C1)
[1] 115191      7
summary(genes95C1$TPM)
     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
    0.000     0.000     0.440     8.681     2.100 23860.000 
sum(genes95C1$TPM)  ## expect 1,000,000, and got it.
[1] 1e+06
library(ggplot2)
ggplot(genes95C1, aes(x=gene_id, y=TPM)) + geom_point()
sessionInfo()
> sessionInfo()
R version 3.2.1 (2015-06-18)
Platform: x86_64-unknown-linux-gnu (64-bit)
Running under: Scientific Linux release 6.7 (Carbon)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] ggplot2_1.0.1

loaded via a namespace (and not attached):
 [1] labeling_0.3     MASS_7.3-45      colorspace_1.2-6 scales_0.3.0    
 [5] magrittr_1.5     plyr_1.8.3       tools_3.2.1      gtable_0.1.2    
 [9] reshape2_1.4.1   Rcpp_0.12.2      stringi_1.0-1    grid_3.2.1      
[13] stringr_1.0.0    digest_0.6.8     proto_0.3-10     munsell_0.4.2   
> 
q()
exit
# count reads aligning 95C1 fastq file to Trinity.fasta file.
# ref. p-370, Vbuffalo book
srun --pty --ntasks-per-node=4 --mem 4gb --qos=short $SHELL
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3

module load compiler/gcc/4.8
#module load bowtie/1.1
module load samtools/1.2

samtools flags UNMAP
0x4	4	UNMAP
samtools view -F 4 95C1.bowtie.bam | head -n 3
HWI-ST1023:164:D1FJNACXX:6:1101:1236:2247	0	TRINITY_DN46485_c0_g1_i3117	255	80M	*	0	0	CACAAACTTGGCTATGGAAACTGGGATGAACTTAAAGCTGCATTCCGCATGTCTCCCTTGTTCCGATTCGATTGGTTTGT	CC@FFFFFHGHHGGJIIIIJIJBHIFIJJJJIIIIIJEEIJGIJG@GFGBGGIEIFGEHEHGIGBBGHHHHHFFBDFC<;	XA:i:0	MD:Z:80NM:i:0
# Q: mapping a read to qqch in Trinity, each record beginning wi 'HWI' ???? ??????????????
# note: bam file ~ 1.5 Gb
-rw-r--r--  1 pterry amundsen 1499094344 Dec 18 13:33 95C1.bowtie.bam
samtools view -F 4 95C1.bowtie.bam > 95C1onlyaligned.txt
ls -al
-rw-r--r--  1 pterry amundsen 8289992814 Feb 13 12:12 95C1onlyaligned.txt
# 8 GB
less 95C1onlyaligned.txt
HWI-ST1023:164:D1FJNACXX:6:1101:1236:2247       0       TRINITY_DN46485_c0_g1_i1        3117    255     80M     *       0       0       CACAAACTTGGCTATGGAAACTGGGATGAACTTAAAGCTGCATTCCGCATGTCTCCCTTGTTCCGATTCGATTGGTTTGT        CC@FFFFFHGHHGGJIIIIJIJBHIFIJJJJIIIIIJEEIJGIJG@GFGBGGIEIFGEHEHGIGBBGHHHHHFFBDFC<;        XA:i:0  MD:Z:80 NM:i:0
HWI-ST1023:164:D1FJNACXX:6:1101:1189:2079       16      TRINITY_DN37623_c0_g1_i1        1357    255     80M     *       0       0       GTACACGAAAAACAGGGAGGAAGCACCGGCAGCACCACCGGAGGCAAGGTTGCCAGCAAACCACTTCCAGTAACCATCCC        A<91A@CBCAC@ECDCEDDCECAB;IIIIIGEF;IHDJJIJIJJIJJJIJJIIHGIIJHHIIEJJJJHHHHHDFFFFCCC        XA:i:0  MD:Z:80 NM:i:0
wc 95C1onlyaligned.txt
  30221873  423106222 8289992814 95C1onlyaligned.txt
grep -c "^HWI" 95C1onlyaligned.txt
30221873
#30221873/19381393
# Q: **WHY** more aligned reads than reads in output95C1_GATCAG_L006_R1_001.trimmed.fastq reads file ???????*****????????
# multiple sligning reads ??????????????????

STOPPED

# do for 'isoforms' since created these files with 'isoforms' ???????
02/14/16:
# section 'Build Transcript and Gene Expression Matrices' of outline section 'Trinity Transcript Quantification'
# investigating files created here.
ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3
# mkdir vbufalo
#cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo

-rw-r--r--  1 pterry amundsen    9495163 Dec 19 23:06 Trinity_trans.counts.matrix
wc Trinity_trans.counts.matrix
 165460 1158219 9495163 Trinity_trans.counts.matrix
less Trinity_trans.counts.matrix
        95C1    95C2    95C3    95T1    95T2    95T3
TRINITY_DN44017_c0_g1_i2        252.87  293.76  403.97  108.04  57.49   60.78
TRINITY_DN48025_c0_g1_i1        29.25   78.98   27.97   25.48   72.45   67.83
grep -c "^TRI" Trinity_trans.counts.matrix
165459
head -n 3 Trinity_trans.counts.matrix
	95C1	95C2	95C3	95T1	95T2	95T3
TRINITY_DN44017_c0_g1_i2	252.87	293.76	403.97	108.04	57.49	60.78
# to check if 7 colms when in R

-rw-r--r--  1 pterry amundsen   10187631 Dec 19 23:06 Trinity_trans.TMM.EXPR.matrix
wc Trinity_trans.TMM.EXPR.matrix
  165460  1158219 10187631 Trinity_trans.TMM.EXPR.matrix
less Trinity_trans.TMM.EXPR.matrix
        95C1    95C2    95C3    95T1    95T2    95T3
TRINITY_DN44017_c0_g1_i2        31.543  37.102  45.676  7.719   4.510   4.123
TRINITY_DN48025_c0_g1_i1        3.858   10.536  3.345   1.927   6.002   4.866
grep -c "^TRI" Trinity_trans.TMM.EXPR.matrix
165459

-rw-r--r--  1 pterry amundsen    8155802 Dec 19 23:06 Trinity_trans.TPM.not_cross_norm
wc Trinity_trans.TPM.not_cross_norm
 165460 1158219 8155802 Trinity_trans.TPM.not_cross_norm
less Trinity_trans.TPM.not_cross_norm
        95C1    95C2    95C3    95T1    95T2    95T3
TRINITY_DN44017_c0_g1_i2        27.88   32.75   38.1    8.73    5.23    4.83
TRINITY_DN48025_c0_g1_i1        3.41    9.3     2.79    2.18    6.96    5.7
# note **differences** top 2 lines of he 3 files.
# Q: Would note p-6 of 8, kallisto '.tsv' file similar to 'isoforms' file as input to prepn of 2 'matrix' files, 1 'TPM' file ?????????????***********?????????????????
grep -c "^TRI" Trinity_trans.TPM.not_cross_norm
165459

srun --pty --ntasks-per-node=4 --mem 4gb --qos=short $SHELL
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3

module load R/3.2  ## 3.2.1
R
# attempt analyze in R on crane ???????????
getwd()
# setwd("/work/amundsen/pterry/Trin21test/95C1-3T1-3")  # if need to ???????????????
# read csv or delim ??????????????????????? p-196, vbuffalo bk
iso95C1cts <- read.delim("Trinity_trans.counts.matrix", header=TRUE)
colnames(iso95C1cts)
[1] "X"     "X95C1" "X95C2" "X95C3" "X95T1" "X95T2" "X95T3"
head(iso95C1cts, n=3)
                         X  X95C1  X95C2  X95C3  X95T1 X95T2 X95T3
1 TRINITY_DN44017_c0_g1_i2 252.87 293.76 403.97 108.04 57.49 60.78
dim(iso95C1cts)
[1] 165459      7
# same as Trinity.fasta, 'isoforms' above.
summary(iso95C1cts$X95C1)
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
     0.0      0.0      1.0     52.4     10.0 270700.0 
summary(iso95C1cts$X95T1)
     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
     0.00      1.00      4.00     75.86     22.02 116500.00      
library(ggplot2)
# may have to assign colm label to colm 1, or R may have done
# so could plot x=colm1, y=95C1
ggplot(iso95C1cts, aes(x=X, y=X95C1)) + geom_point()
# repeat, wi y=X95T1
ggplot(iso95C1cts, aes(x=X, y=X95T1)) + geom_point()
sum(iso95C1cts$X95C1)
[1] 8669922
sum(iso95C1cts$X95T1)
[1] 12551158
# Q: X95T1 colm more total cts, but max point < 1/2 of max for X95C1 ??????????????????

STOPPED

# repeat for other 2 files, impt so can compare basis TPM.

ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3
srun --pty --ntasks-per-node=4 --mem 4gb --qos=short $SHELL
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3

module load R/3.2  ## 3.2.1
R
# attempt analyze in R on crane ???????????
getwd()
# setwd("/work/amundsen/pterry/Trin21test/95C1-3T1-3")  # if need to ???????????????
# read csv or delim ??????????????????????? p-196, vbuffalo bk
iso95C1TMM <- read.delim("Trinity_trans.TMM.EXPR.matrix", header=TRUE)
colnames(iso95C1TMM)
[1] "X"     "X95C1" "X95C2" "X95C3" "X95T1" "X95T2" "X95T3"
head(iso95C1TMM, n=3)
                         X  X95C1  X95C2  X95C3 X95T1 X95T2 X95T3
1 TRINITY_DN44017_c0_g1_i2 31.543 37.102 45.676 7.719 4.510 4.123
2 TRINITY_DN48025_c0_g1_i1  3.858 10.536  3.345 1.927 6.002 4.866
dim(iso95C1TMM)
[1] 165459      7
# same as Trinity.fasta, 'isoforms' above.
summary(iso95C1TMM$X95C1)
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
   0.000    0.000    0.566    6.838    2.489 9704.000 
summary(iso95C1TMM$X95T1)
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
   0.000    0.239    0.990    5.344    2.891 4518.000 
library(ggplot2)
# may have to assign colm label to colm 1, or R may have done
# so could plot x=colm1, y=95C1
ggplot(iso95C1TMM, aes(x=X, y=X95C1)) + geom_point()
# repeat, wi y=X95T1
ggplot(iso95C1TMM, aes(x=X, y=X95T1)) + geom_point()
sum(iso95C1TMM$X95C1)
[1] 1131382
sum(iso95C1TMM$X95T1)
[1] 884141.5
# Q: WHY don't these last two total 1,000,000, perhaps cause normalize across 6 colms  ?????????????????????????
# Q: what difference, TMM, TPM ???????????*********????????????
q()
exit

02/15/16:
ssh -Y pterry@crane.unl.edu
# Rrq096mN 
# ref line 3425, 'Extracting and clustering differentially expressed transcripts'
# Compare two files:
-rw-r--r-- 1 pterry amundsen    308395 Jan 25 15:38 Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95C-UP.subset
-rw-r--r-- 1 pterry amundsen    547935 Jan 25 15:38 Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95T-UP.subset

cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo
#cp ../DEanalysis/edgeR.115118.dir/Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95C-UP.subset .
#cp ../DEanalysis/edgeR.115118.dir/Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95T-UP.subset .

STOPPED

less Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95C-UP.subset
id      logFC   logCPM  PValue  FDR     95C1    95C2    95C3    95T1    95T2    95T3
TRINITY_DN31372_c0_g1_i1        -13.303565262659        9.83961096097471        6.64875466320565e-40    1.06371431230228e-34    286.387 488.956 206.128 0.000   0.000   0.085
less Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95T-UP.subset
id      logFC   logCPM  PValue  FDR     95C1    95C2    95C3    95T1    95T2    95T3
TRINITY_DN42864_c1_g1_i1        10.9011095379641        6.52933145958951        4.64962937243796e-35    3.71940127204116e-30    0.091   0.079   0.000   109.103 99.779  137.430
wc Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95C-UP.subset
  2186  24046 308395 Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95C-UP.subset
wc Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95T-UP.subset
  3972  43692 547935 Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95T-UP.subset
grep -c "^TRI" Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95C-UP.subset
2185
grep -c "^TRI" Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95T-UP.subset
3971

srun --pty --ntasks-per-node=4 --mem 4gb --qos=short $SHELL
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo

module load R/3.2  ## 3.2.1
R
# attempt analyze in R on crane ???????????
getwd()
# setwd("/work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo")  # if need to ???????????????
de95C_up <- read.delim("Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95C-UP.subset", header=TRUE)
colnames(de95C_up)
 [1] "id"     "logFC"  "logCPM" "PValue" "FDR"    "X95C1"  "X95C2"  "X95C3" 
 [9] "X95T1"  "X95T2"  "X95T3" 
head(de95C_up, n=2)
                        id     logFC   logCPM       PValue          FDR   X95C1
1 TRINITY_DN31372_c0_g1_i1 -13.30357 9.839611 6.648755e-40 1.063714e-34 286.387
2 TRINITY_DN35725_c0_g1_i1 -10.43986 8.363475 1.112486e-33 4.472129e-29 771.082
    X95C2    X95C3 X95T1 X95T2 X95T3
1 488.956  206.128 0.000 0.000 0.085
2 617.234 1395.999 0.442 0.647 1.067
dim(de95C_up)
[1] 2185   11
#summary(de95C_up$????????????)

de95T_up <- read.delim("Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95T-UP.subset", header=TRUE)
colnames(de95T_up)
 [1] "id"     "logFC"  "logCPM" "PValue" "FDR"    "X95C1"  "X95C2"  "X95C3" 
 [9] "X95T1"  "X95T2"  "X95T3" 
head(de95T_up, n=2)
                        id    logFC   logCPM       PValue          FDR X95C1
1 TRINITY_DN42864_c1_g1_i1 10.90111 6.529331 4.649629e-35 3.719401e-30 0.091
2 TRINITY_DN73954_c0_g1_i1 10.38759 5.187235 1.134433e-27 2.592778e-23 0.170
  X95C2 X95C3   X95T1  X95T2   X95T3
1 0.079     0 109.103 99.779 137.430
2 0.000     0 116.229 82.679  97.276
dim(de95T_up)
[1] 3971   11
#summary(de95T-up$????????????)

# install.packages("ggplot2")
#library(ggplot2)
#ggplot(de95C-up, aes(x=??????????, y=????????)) + geom_point()

#ggplot(de95T-up, aes(x=??????????, y=????????)) + geom_point()

# finally, apply '%in%'
CinT <- de95C_up$id %in% de95T_up$id
length(CinT)
[1] 2185
head(CinT)
# do length, head, etc. of CtoT.txt
sum(CinT)  # number of x=C-UP records in y=T-UP, expect **zero** ??????????
[1] 0
q()
exit

02/17/16:
# To Do: might compare 95C-UP.subset & 95T-UP.subset transcript column against transcript column of a file with all the transcript id's. Here %in% vs Trinity_trans.TMM.EXPR.matrix file used by 'analyze_diff_expr.pl' to produce these two 'subset' files.

ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo
cp ../Trinity_trans.TMM.EXPR.matrix .
less Trinity_trans.TMM.EXPR.matrix
        95C1    95C2    95C3    95T1    95T2    95T3
TRINITY_DN44017_c0_g1_i2        31.543  37.102  45.676  7.719   4.510   4.123
wc Trinity_trans.TMM.EXPR.matrix
  165460  1158219 10187631 Trinity_trans.TMM.EXPR.matrix
grep -c "^TRI" Trinity_trans.TMM.EXPR.matrix
165459
srun --pty --ntasks-per-node=4 --mem 4gb --qos=short $SHELL
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo

module load R/3.2  ## 3.2.1
R
# attempt analyze in R on crane ???????????
getwd()
# setwd("/work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo")  # if need to ???????????????
de95C_up <- read.delim("Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95C-UP.subset", header=TRUE)
colnames(de95C_up)
 [1] "id"     "logFC"  "logCPM" "PValue" "FDR"    "X95C1"  "X95C2"  "X95C3" 
 [9] "X95T1"  "X95T2"  "X95T3" 
dim(de95C_up)
[1] 2185   11
TMMmatrix <- read.delim("Trinity_trans.TMM.EXPR.matrix", header=TRUE)
colnames(TMMmatrix)
[1] "X"     "X95C1" "X95C2" "X95C3" "X95T1" "X95T2" "X95T3"
head(TMMmatrix, n=2)
                         X  X95C1  X95C2  X95C3 X95T1 X95T2 X95T3
1 TRINITY_DN44017_c0_g1_i2 31.543 37.102 45.676 7.719 4.510 4.123
2 TRINITY_DN48025_c0_g1_i1  3.858 10.536  3.345 1.927 6.002 4.866
dim(TMMmatrix)
[1] 165459      7
# now %in%
CinTMM <- de95C_up$id %in% TMMmatrix$X
length(CinTMM)
[1] 2185
head(CinTMM)
[1] TRUE TRUE TRUE TRUE TRUE TRUE
sum(CinTMM)
[1] 2185    ## as expected.
TMMinC <- TMMmatrix$X %in% de95C_up$id
length(TMMinC)
[1] 165459   ## as expect
head(TMMinC)
sum(TMMinC)
[1] 2185  ## so apparently not duplicate transcript id's matching a transcript id in de95C_up in TMMmatrix$X ????????
q()
exit

# now, perhaps at some point, check:
# TinC
# TinTMM


02/20/16:

# for moment, go do
#Cinxls
#Tinxls
#xlsinTMM
# finally, check if GOterm info in .xls file for transcript id's matching transcript id's in C & T.  Q: HOW TO DO ???????????

cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo
ls -al
cp /work/amundsen/pterry/Trin21test/95C1-3T1-3/trinotate/sqlitedb95C1-T3/trinotate_annotation_report.xls .
wc trinotate_annotation_report.xls
  178728  6371013 78676610 trinotate_annotation_report.xls
grep -c "^TRI" trinotate_annotation_report.xls
178727


# now, xlsinTMM
TMMmatrix <- read.delim("Trinity_trans.TMM.EXPR.matrix", header=TRUE)
colnames(TMMmatrix)
[1] "X"     "X95C1" "X95C2" "X95C3" "X95T1" "X95T2" "X95T3"
head(TMMmatrix, n=2)
                         X  X95C1  X95C2  X95C3 X95T1 X95T2 X95T3
1 TRINITY_DN44017_c0_g1_i2 31.543 37.102 45.676 7.719 4.510 4.123
2 TRINITY_DN48025_c0_g1_i1  3.858 10.536  3.345 1.927 6.002 4.866
dim(TMMmatrix)
[1] 165459      7
# fewer records than go_xls ?????????????????????

# now %in%
xlsinTMM <- go_xls$transcript_id %in% TMMmatrix$X

length(xlsinTMM)
[1] 178727

head(xlsinTMM)
[1] TRUE TRUE TRUE TRUE TRUE TRUE
sum(xlsinTMM)
[1] 178727
q()
exit

# finally, check if GOterms info in .xls file for transcript id's matching transcript id's in C & T.  Q: HOW TO DO ???????????
# try p-220-223, Vbuffalo book, 

ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo
srun --pty --ntasks-per-node=4 --mem 4gb --qos=short $SHELL
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo

module load R/3.2  ## 3.2.1
R
# attempt analyze in R on crane ???????????
getwd()
de95C_up <- read.delim("Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95C-UP.subset", header=TRUE)
colnames(de95C_up)
 [1] "id"     "logFC"  "logCPM" "PValue" "FDR"    "X95C1"  "X95C2"  "X95C3" 
 [9] "X95T1"  "X95T2"  "X95T3" 
dim(de95C_up)
[1] 2185   11
#head(de95C_up, n=3)
go_xls <- read.delim("trinotate_annotation_report.xls", header=TRUE)
colnames(go_xls)
 [1] "X.gene_id"             "transcript_id"         "sprot_Top_BLASTX_hit" 
 [4] "TrEMBL_Top_BLASTX_hit" "RNAMMER"               "prot_id"              
 [7] "prot_coords"           "sprot_Top_BLASTP_hit"  "TrEMBL_Top_BLASTP_hit"
[10] "Pfam"                  "SignalP"               "TmHMM"                
[13] "eggnog"                "gene_ontology_blast"   "gene_ontology_pfam"   
[16] "transcript"            "peptide"
dim(go_xls)
# now %in%, C_UP in go_xls
#head(go_xls, n=3)
Cinxls <- de95C_up$id %in% go_xls$transcript_id
length(Cinxls)
[1] 2185
head(Cinxls)
[1] TRUE TRUE TRUE TRUE TRUE TRUE
sum(Cinxls)
[1] 2185
dim(go_xls)
[1] 178727     17

table(Cinxls)   ## expect 'true' = 2185, 'false' = 178727 - 2185 = 176542
i <- match(de95C_up$id, go_xls$transcript_id)
table(is.na(i))   ## expect zero
FALSE 
 2185 
length(i)
table(de95C_up$id %in% go_xls$transcript_id)
table(go_xls$transcript_id %in% de95C_up$id)
 FALSE   TRUE 
176175   2552 
## perhaps some duplicatetranscript_is's in '.xls' for those in de95C_up$id ???????????
length(i)
[1] 2185
head(i, 3)
[1] 151477  79715  35124
xlsC_up_logdf <- go_xls[i,]  ## check if get 2815 records ???????
dim(xlsC_up_logdf)
[1] 2185   17
head(xlsC_up_logdf, 2)
write.table(xlsC_up_logdf, "xlsC_up_logdf.txt")
save.image(file="may17_16.RData")
q()
exit
ls -al
wc xlsT_up_logdf.txt
   3972  209173 3261778 xlsT_up_logdf.txt

head -n 2 xlsC_up_logdf.txt
less xlsT_up_logdf.txt
# looks like many of the 95C_UP matches with '.xls' files have 'GO-terms' ?????
 
02/21/16:
# but, TO DO, scp the xlsC_up_logdf.txt file to 'pro', examine in BBedit.
# perhaps save 'transcript id colm from C_UP, '.xls', so can sort, spot check compare, make sure same 2185 transcript id's in buth files.

cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing
scp pterry@crane.unl.edu:/work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo/xlsC_up_logdf.txt .
# displayed in bbedit editor, perhaps could grep 3rd field to determine percent of records with "." in "sprot_Top_BLASTX_hit" column.
cd
find . -name "*\.py" -and -type f
find . -name "xlsC_up_logdf.txt" -and -type f

cut -d ' ' -f 4 xlsC_up_logdf6rows.txt | head -n 4 > rows6col4.txt
cut -d ' ' -f 4 xlsC_up_logdf.txt > xlsC_up_logdf_col4.txt
grep -c '^\"\.' xlsC_up_logdf_col4.txt
# now output count, giving new prompt, '>' ????????????????????????
grep -c '^\.' xlsC_up_logdf_col4.txt
# gave output, but '0' ??????????????????
wc xlsC_up_logdf_col4.txt
    2186    2186   87089 xlsC_up_logdf_col4.txt
# as expected.

02/22/16:
sed 's/"."/./' xlsC_up_logdf_col4.txt > temp
# worked, so try count "." lines
grep -c '^\.' temp
978
# so 978 of 2185 records in '.xls' file common with 95C1 appear not to have any 'GO-terms' available for use by GOseq to use to annotate the DE transcripts from 95C-UP files.

02/27-8/16:
# 1st time seeing Vikas new paper, Manuscript_v17b.docx
# Following several measurements they made, I should try to make.

03/01/01:
# p-6, calc total number reads, apparently from all samples, 95C1-3,T1-3
ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3
wc output95C1_GATCAG_L006_R1_001.trimmed.fastq
  77525572   96906965 4292886820 output95C1_GATCAG_L006_R1_001.trimmed.fastq
less output95C1_GATCAG_L006_R1_001.trimmed.fastq
@HWI-ST1023:164:D1FJNACXX:6:1101:1189:2079 1:N:0:GATCAG
GGGATGGTTACTGGAAGTGGTTTGCTGGCAACCTTGCCTCCGGTGGTGCTGCCGGTGCTTCCTCCCTGTTTTTCGTGTAC
+
CCCFFFFDHHHHHJJJJEIIHHJIIGHIIJJIJJJIJJIJIJJDHI;FEGIIIII;BACECDDECDCE@CACBC@A19<A
grep -c "^@HWI" output95C1_GATCAG_L006_R1_001.trimmed.fastq
19381393
less output95C2_TAGCTT_L007_R1_001.trimmed.fastq
grep -c "^@HWI" output95C2_TAGCTT_L007_R1_001.trimmed.fastq
19517268
wc output95C2_TAGCTT_L007_R1_001.trimmed.fastq
  78069072   97586340 4323022386 output95C2_TAGCTT_L007_R1_001.trimmed.fastq
# *.readcount files seem accurate, so just use them for 4 remaining fastq Files
less output95C3_GGCTAC_L007_R1_001.trimmed.fastq.readcount
Sequences parsed: 21681817
output95C3_GGCTAC_L007_R1_001.trimmed.fastq.readcount (END) 
less output95T1_AGTCAA_L005_R1_001.trimmed.fastq.readcount
Sequences parsed: 27915998
output95T1_AGTCAA_L005_R1_001.trimmed.fastq.readcount (END) 
less output95T2_AGTTCC_L005_R1_001.trimmed.fastq.readcount
Sequences parsed: 24276992
output95T2_AGTTCC_L005_R1_001.trimmed.fastq.readcoun
less output95T3_ATGTCA_L006_R1_001.trimmed.fastq.readcount
Sequences parsed: 27406970
output95T3_ATGTCA_L006_R1_001.trimmed.fastq.readcount (END) 
# so total reads for 6 samples:
sumreads95CT <- sum(19381393 + 19517268 + 21681817 + 27915998 + 24276992 + 27406970)
sumreads95CT
[1] 140180438

# calc num. transcripts & 'components' in Trinity.fasta
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3
cd trinity_out_dir
-rw-r--r-- 1 pterry amundsen   194832811 Dec 16 13:51 Trinity.fasta
# so ~ **195 Mb**
less Trinity.fasta
>TRINITY_DN10610_c0_g1_i1 len=460 path=[946:0-169 948:170-236 943:237-459] [-1, 946, 948, 943, -2]
CGCATGCTGTTTGTGCAGTGGTGCAGTTCAGAGCGTTGGTGTTGAGCCGGGAAATGGGTA
TGCCTTATCTGACATAATTCACTGGGGGTAGCAATCCGGAATTCCACACCTACTAGCTGC
GATTCTGAATTCAGCATCCAATAGCTTGCTCCATTTCACTGCAACCCATTGAGTAAAACA
ATGAAGGAATTTTCCGGTGTGATAAGGTCTCGTAGTTGGTCTTCTATCAGTAGTCTCTTC
TGTAGGCAGCAATGACAAGCTAGCATTACTTCTATATTCAGATCATGTGTAAAATTGTTA
CTCATTCTTTTTTCCAATAAGACCCGTGTGCTATTTGCACAGCAGTGTGCTTAAGAGTCT
TGGTGTTGAGTTGAGCGGGGATGTAAGGAAATGGGAATCAATGGGGCAGCAAACCGGAAT
TTCACACTGACTAGCTGCAATTCTTAATTCGGCATCCAAG
>TRINITY_DN10610_c0_g2_i1 len=458 path=[944:0-169 949:170-234 941:235-457] [-1, 944, 949, 941, -2]
CGCATGCTGTTTGTGCAGTGGTGCAGTTCAGAGCGTTGGTGTTGAGCCGGGAAATGGGTA
TGCCTTATCTGACATAATTCACTGGGGGTAGCAATCCGGAATTCCACACCTACTAGCTGC

# looks like 1st colm transcript name (?). looks like 2nd colm has length of transcript.
# num. transcripts
grep -c '^>TRI' Trinity.fasta
165459

# how get num. components, possibly subsequent trinity step where have 1st 2 colms are transcript & 'gene' ????????????  Q: are 'genes' even listed in Trinity.fasta file ??????????????????

# calc length of transcripts range from ??? to ???
# calc average length, & N50 of transcripts ?????????????????
# try do in R

ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/trinity_out_dir
ls -al
less Trinity.fasta
# perhap grep from linux shell the '^>TRI' rows before go into R ????

grep '^>TRI' Trinity.fasta > Trinity.fasta.headers.txt
less Trinity.fasta.headers.txt
cut -f1-2 Trinity.fasta.headers.txt > Trinity.headers.col1-2.txt
# this cut failed ???????? 
cut -d' ' -f1,2 Trinity.fasta.headers.txt > Trinity.headers.col1-2.txt
less Trinity.headers.col1-2.txt
>TRINITY_DN10610_c0_g1_i1 len=460
>TRINITY_DN10610_c0_g2_i1 len=458
# 2nd cut worked!
cut -d' ' -f2 Trinity.fasta.headers.txt > Trinity.headers.col2.txt
less Trinity.headers.col2.txt
len=460
len=458
# so 3rd cut worked
wc Trinity.headers.col1-2.txt
 165459  330918 5658311 Trinity.headers.col1-2.txt
# expected num. of lines
wc Trinity.headers.col2.txt
 165459  165459 1365316 Trinity.headers.col2.txt
logout

STOPPED

srun --pty --ntasks-per-node=4 --mem 4gb --qos=short $SHELL
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/trinity_out_dir

module load R/3.2  ## 3.2.1
R
# attempt analyze in R on crane ???????????
getwd()
# setwd("/work/amundsen/pterry/Trin21test/95C1-3T1-3")  # if need to ???????????????
#genes95C1 <- read.delim("95C1.genes.results", header=TRUE)
#trinityheaders_col1_2 <- read.delim("Trinity.headers.col1-2.txt", header=FALSE)
trinityheaders_col2 <- read.delim("Trinity.headers.col2.txt", header=FALSE)
colnames(trinityheaders_col2)
[1] "V1"
head(trinityheaders_col2, n=3)
       V1
1 len=460
dim(trinityheaders_col2)
[1] 165459      1
class(trinityheaders_col2)
# a data.frame, so why 'dim' worked.
sublengthschar <- sub(pattern="len=", replacement="", x=trinityheaders_col2$V1) 
head(sublengthschar, n=3)
[1] "460" "458" "335"
# so elements are 'char'
class(sublengthschar)
[1] "character"
# so no longer a data.frame
sublengthsnum <- as.numeric(sublengthschar) 
head(sublengthsnum, n=3)
class(sublengthsnum)
# now numeric vector
length(sublengthsnum)
[1] 165459
summary(sublengthsnum)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  201.0   283.0   459.0   802.7  1005.0 18710.0 
# skewed to right, a **lot**.     
sum(sublengthsnum)
[1] 132818157
# C = N*L/G  from S. Ladunga, life891, 3/1/16 lect., slide 8,9
# 140180438 = N, L= 80, G = 132818157
C <- (140180438*80)/132818157
C
[1] 84.4345

# perhaps a bar plot of the transcript lengths, get visual idea of the distribution of the transcript lengths. Ref: p-275-7 of Vbuffalo book.# #install.packages("ggplot2")
sublengths.binned <- cut(sublengthsnum, 5)
table(sublengths.binned)
sublengths.binned
     (182,3.9e+03]  (3.9e+03,7.6e+03] (7.6e+03,1.13e+04] (1.13e+04,1.5e+04] 
            163675               1707                 63                  9 
(1.5e+04,1.87e+04] 
                 5 
# so most length values from 182 to 3900 bases. Q: 182 != 201 ??????????                 
library(ggplot2)
#sublengthsnumdf <- as.data.frame(sublengthsnum)
sublengthsnumdf <- data.frame(sublengthsnum)
class(sublengthsnumdf)
ggplot(sublengthsnumdf) + geom_bar(aes(x=sublengths.binned))
ggplot(sublengthsnumdf) + geom_bar(aes(x=sublengthsnum))
q()
exit

03/04/16:
# talked to Vikas

03/05/16:
# see what can do with 'trinotate_annotation_report.xls' file, display, view gene_ontology_blast column.


ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/trinotate/sqlitedb95C1-T3
-rw-r--r-- 1 pterry amundsen   78676610 Jan 20 11:13 trinotate_annotation_report.xls
less trinotate_annotation_report.xls
# p-196, Vbuffalo book
module load R/3.2  ## 3.2.1
R
# attempt analyze in R on crane ???????????
getwd()
go_xls <- read.delim("trinotate_annotation_report.xls", header=TRUE)
colnames(go_xls)
dim(go_xls)
[1] 178727     17
head(go_xls$gene_ontology_blast, n=3)
# apparently have gene_ontology_blast colm. So for transcript (3rd data row in file), TRINITY_DN10643_c0_g1_i1, 5 GO terms, 1 cellular, 4 biological ( 2 cellular, 1 protein, 1 resonse).
# Q: If proceed, how organize this data ??????????????????
# perhaps do %in% to get the 2185 rows of '.xls' file common with de95C_up. Then if Keenan/Vikas has **way** to display (also bring in de95T_up, i.e., the 2185 differentiated tx's for 95C)

03/06/16:
# To do:
# assume '.xls' file ok
# read thru https://github.com/trinityrnaseq/trinityrnaseq/wiki/Trinity-Differential-Expression, Differential Expression Analysis Using a Trinity Assembly, see of can clarify/what should do. Note: trying to reconcile output of
# GOseq.enriched, etc  (stat columns) with 
# '95C-UP.subset'  (tx_IDs),
# '.xls'  (**BOTH** 'gene_ID' & 'tx_ID), 
# 'go_annotations.txt'  ('gene_IDs), 
# 'gene.lengths.txt'  ('gene_IDs), 
# 'Trinity_trans.TMM.EXPR.matrix  (tx_IDs) 
# in terms of 'gene_ID' or 'tx_ID' use ????????????????????????????

# Two/three initiatives
# i) Vikas/Keenan building own display of DE tx/genes IDs with GO-terms ?????
# ii) try run __runGOseq.R script found in edgeR.115118.dir ???????(troubleshooting, learn more)
# iii) attempt go back thru Differential Expression Analysis Using a Trinity Assembly, see if can get this to display DE tx/genes IDs with GO-terms ???????

03/09/16:
# pursuant to initiatives above:
# as per Keenan, from raw counts/edgeR, plot same data each axis, Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results file

# TMM.EXPR.matrix (normalized, not raw counts), plot Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95C-UP.subset 
file (already pv <= 1e-3, logFC >= 2

# repeat 95T-UP

# compare tx_ID, gene_IDs, see what have.

# Finally, run R script from analyze_diff_expr.pl, try see why failing?
# Vikas email refs, find GO-terms sort of on own.

03/11/16:
# 1st, work with Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results file produced from 'run_DE_analysis.pl' step, using 
-rw-r--r--  1 pterry amundsen 9495163 Dec 23 22:53 Trinity_trans.counts.matrix
& edgeR 
# to do: work in .../vbufalo/countsedgeRanal


ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/DEanalysis/edgeR.115118.dir
ls -al
-rw-r--r-- 1 pterry amundsen  15079499 Dec 24 10:18 Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results
less Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results
logFC   logCPM  PValue  FDR
TRINITY_DN31372_c0_g1_i1        -13.303565262659        9.83961096097471        6.64875466320565e-40    1.06371431230228e-34
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3
cd vbufalo
mkdir countsedgeRanal
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo/countsedgeRanal
cp ../../DEanalysis/edgeR.115118.dir/Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results .

#srun --pty --ntasks-per-node=4 --mem 4gb --qos=short $SHELL
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo/countsedgeRanal

module load R/3.2  ## 3.2.1
R
# attempt analyze in R on crane ???????????
getwd()
# setwd("/work/amundsen/pterry/Trin21test/95C1-3T1-3")  # if need to ???????????????
ctsedgeRDEres <-   read.delim("Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results", header=TRUE)
colnames(ctsedgeRDEres)
[1] "logFC"  "logCPM" "PValue" "FDR"   
ctsedgeRDEresrownames <- cbind(rownamescolm = rownames(ctsedgeRDEres), ctsedgeRDEres)
rownames(ctsedgeRDEresrownames) <- NULL
colnames(ctsedgeRDEresrownames)
head(ctsedgeRDEresrownames, n=2)
              rownamescolm     logFC   logCPM       PValue          FDR
1 TRINITY_DN31372_c0_g1_i1 -13.30357 9.839611 6.648755e-40 1.063714e-34
dim(ctsedgeRDEresrownames)
[1] 159987      5

summary(ctsedgeRDEresrownames$logFC)  # ???????
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
-13.7700  -0.5443   0.8438   1.1230   2.8730  12.9700 
# need sort in here ?????????
#r <- order(-ctsedgeRDEresrownames$logFC)
#ctsedgeRDEressort <- ctsedgeRDEresrownames$logFC[r, ]
colnames(ctsedgeRDEresrownames)
[1] "rownamescolm" "logFC"        "logCPM"       "PValue"       "FDR"         
ctsedgeRDEressort <- ctsedgeRDEresrownames[order(-logFC), ]
Error in order(-logFC) : object 'logFC' not found
search()
attach(ctsedgeRDEresrownames)
ctsedgeRDEressort <- ctsedgeRDEresrownames[order(-logFC), ]
# now works ????????????????????????????????
detach(ctsedgeRDEresrownames)
search()  ## ctsedgeRDEresrownames no longer attached.
head(ctsedgeRDEressort, n=3)
tail(ctsedgeRDEressort, n=3)
dim(ctsedgeRDEressort)
[1] 159987      5
colnames(ctsedgeRDEressort)
library(ggplot2)
ggplot(ctsedgeRDEressort) + geom_point(aes(x=rownamescolm, y=logFC))
ggplot(ctsedgeRDEressort) + geom_point(aes(x=logFC, y=logFC))
# ***all*** the points along 45 deg line.

# vbufalo, dplyr, %>%, p-203
logFCgtrless2 <- ctsedgeRDEressort[ctsedgeRDEressort$logFC >= 2 | ctsedgeRDEressort$logFC <= -2, ] 
## prompt just returned, 
dim(logFCgtrless2)
[1] 69492     5
head(logFCgtrless2, n=2)
tail(logFCgtrless2, n=2)
ggplot(logFCgtrless2) + geom_point(aes(x=rownamescolm, y=logFC))

# NOTE: p-6 of 9, Trinity DE analysis, criteria pv = 1e-3, FC >= 4
# So, log2 2 = 1, log2 4 =2, already finding transcripts >= or <= 4 fold change, and still 69k of them. So do I need aonther criteria, PValue, or FDR ?????????
qq()
logout
# p-5 of 9, most sig. FDR & FCs. p-4 of 9, DE at FDR <0.05 colored red.

# Perhaps test criterion PValue <= 1e-3 (p-6 of 9), & FDR < 0.05 (p-4 of 9)

03/12/16:
ssh -Y pterry@crane.unl.edu
# Rrq096mN 
 /DEanalysis/edgeR.115118.dir
ls -al
-rw-r--r-- 1 pterry amundsen  15079499 Dec 24 10:18 Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results
less Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results
logFC   logCPM  PValue  FDR
TRINITY_DN31372_c0_g1_i1        -13.303565262659        9.83961096097471        6.64875466320565e-40    1.06371431230228e-34
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3
cd vbufalo
mkdir countsedgeRanal
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo/countsedgeRanal
cp ../../DEanalysis/edgeR.115118.dir/Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results .

#srun --pty --ntasks-per-node=4 --mem 4gb --qos=short $SHELL
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo/countsedgeRanal

module load R/3.2  ## 3.2.1
R
# attempt analyze in R on crane ???????????
getwd()
# setwd("/work/amundsen/pterry/Trin21test/95C1-3T1-3")  # if need to ???????????????
ctsedgeRDEres <-   read.delim("Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results", header=TRUE)
colnames(ctsedgeRDEres)
[1] "logFC"  "logCPM" "PValue" "FDR"   
ctsedgeRDEresrownames <- cbind(rownamescolm = rownames(ctsedgeRDEres), ctsedgeRDEres)
rownames(ctsedgeRDEresrownames) <- NULL
colnames(ctsedgeRDEresrownames)
head(ctsedgeRDEresrownames, n=2)
              rownamescolm     logFC   logCPM       PValue          FDR
1 TRINITY_DN31372_c0_g1_i1 -13.30357 9.839611 6.648755e-40 1.063714e-34
dim(ctsedgeRDEresrownames)
[1] 159987      5

summary(ctsedgeRDEresrownames$logFC)  # ???????
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
-13.7700  -0.5443   0.8438   1.1230   2.8730  12.9700 
# need sort in here ?????????
#r <- order(-ctsedgeRDEresrownames$logFC)
#ctsedgeRDEressort <- ctsedgeRDEresrownames$logFC[r, ]
colnames(ctsedgeRDEresrownames)
[1] "rownamescolm" "logFC"        "logCPM"       "PValue"       "FDR"         
search()
attach(ctsedgeRDEresrownames)
ctsedgeRDEressort <- ctsedgeRDEresrownames[order(-logFC), ]
# now works ????????????????????????????????
detach(ctsedgeRDEresrownames)
search()  ## ctsedgeRDEresrownames no longer attached.
head(ctsedgeRDEressort, n=3)
tail(ctsedgeRDEressort, n=3)
dim(ctsedgeRDEressort)
[1] 159987      5
colnames(ctsedgeRDEressort)
library(ggplot2)
ggplot(ctsedgeRDEressort) + geom_point(aes(x=rownamescolm, y=logFC))
ggplot(ctsedgeRDEressort) + geom_point(aes(x=logFC, y=logFC))
# ***all*** the points along 45 deg line.

# vbufalo, dplyr, %>%, p-203
logFCgtrless2 <- ctsedgeRDEressort[ctsedgeRDEressort$logFC >= 2 | ctsedgeRDEressort$logFC <= -2, ] 
## prompt just returned, 
dim(logFCgtrless2)
[1] 69492     5
head(logFCgtrless2, n=2)
tail(logFCgtrless2, n=2)
summary(logFCgtrless2$logFC)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
-13.770   2.199   3.234   2.405   4.457  12.970 
summary(logFCgtrless2$PValue)
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
0.000000 0.004507 0.051040 0.126600 0.165900 0.596000 
summary(logFCgtrless2$FDR)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
0.00000 0.03849 0.19880 0.25740 0.39200 0.79070 
# subset on logFC & PValue
countslogFC2PV <- logFCgtrless2[logFCgtrless2$PValue <= exp(-3), ] 
dim(countslogFC2PV)
[1] 34528     5
summary(countslogFC2PV$logFC)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
-13.770  -2.197   4.310   2.525   5.564  12.970
summary(countslogFC2PV$PValue)
     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
0.0000000 0.0002093 0.0044010 0.0112100 0.0188700 0.0497800
# subset on logFC & FDR
countslogFC2FDR <- logFCgtrless2[logFCgtrless2$FDR < 0.05, ]
dim(countslogFC2FDR)
[1] 19109     5
summary(countslogFC2FDR$logFC)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
-13.770  -2.583   4.554   2.604   6.433  12.970 
summary(countslogFC2FDR$FDR)
     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
0.0000000 0.0003155 0.0054730 0.0124700 0.0219600 0.0499700

# subset PV & FDR on logFC, probably just get to min. number above, FC2 + FDR of 19109 transcripts. 
# Compare, with ....TMM.EXPR.matrix input (rather than raw counts) file. That generated 95C-UP (2185 transcripts) & 95T-UP (~3500 transcripts) files. I note the 'TMM.EXPR.matrix' file has tx_ID names only. I note, looking in 'trinotate_annotation_report.xls' file, can **see** the relation betw. gene_id & transcript_id.

STOPPED

# Perhaps compare ('summary') the summaries on 'Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results' file (immedly above) with the 95C-UP (2185 transcripts) & 95T-UP (~3500 transcripts) files? Also, see if tx_IDs in those files are a subset of those in 'Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results' file?
# Trying to understand difference betw. 19109 & 2185 + ~ 3500 ~ 5700 tx_ids ?????????

03/16/16:
To try convert trinotate_annotation_report.xls to 3-column form that Vikas suggesting.

ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/trinotate/sqlitedb95C1-T3
# original location of 
-rw-r--r--  1 pterry amundsen 78676610 Feb 19 23:52 trinotate_annotation_report.xls
# now working with it in 
/work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo
head -n 10 trinotate_annotation_report.xls > top10xlsfile.txt
cut -f 2 top10xlsfile.txt > top10xlsfilecol2.txt
wc trinotate_annotation_report.xls
  178728  6371013 78676610 trinotate_annotation_report.xls
wc top10xlsfile.txt
wc top10xlsfilecol2.txt
less top10xlsfilecol2.txt  # dnstream manipulation, perhaps remove colm header?
cut -f 14 top10xlsfile.txt > top10xlsfilecolm14.txt
less top10xlsfilecolm14.txt

cut -f 14 trinotate_annotation_report.xls > allxlsfilecolm14.txt
wc allxlsfilecolm14.txt
  178728   798280 18458070 allxlsfilecolm14.txt
head -n 4 allxlsfilecolm14.txt
grep -c "^\." top10xlsfilecolm14.txt  ## 6 as expected
grep -c "^GO" top10xlsfilecolm14.txt  ## 3 as expected

grep -c "^\." allxlsfilecolm14.txt  ## 120723
grep -c "^GO" allxlsfilecolm14.txt  ## 58004
## so sums to total lines - colm header, as anticipated.

ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo
ls -al
module load R/3.2  ## 3.2.1
R
# attempt analyze in R on crane ???????????
 colm14_xls <- read.delim("top10xlsfilecolm14.txt", stringsAsFactors=FALSE, header=TRUE)
colnames(colm14_xls)
[1] "gene_ontology_blast"
dim(colm14_xls)
[1] 9 1
head(colm14_xls$gene_ontology_blast, n=3)
# p-249, note possible alternative ???????
#grep("^\.", colm14_xls, perl=TRUE)
#grep("^.", colm14_xls, perl=TRUE)
#colm14_xls$gene_ontology_blast[grep("^.", colm14_xls$gene_ontology_blast, perl=TRUE)]
# no discrimination ??????????
threetop10colm14GOlines <- colm14_xls$gene_ontology_blast[grep("^GO", colm14_xls$gene_ontology_blast, perl=TRUE)]
# **found** the 3 rows starting with 'GO'

03/17/16:
# ref p-253, vbuffalo bk
class(threetop10colm14GOlines)
[1] "character"
length(threetop10colm14GOlines)
head(threetop10colm14GOlines, n=2)
strsplit(threetop10colm14GOlines[1], "`")  ## worked
teststrsplit <- strsplit(threetop10colm14GOlines[1], "`")
class(teststrsplit)
length(teststrsplit)
teststrsplit
dim(teststrsplit)  ## NULL
lengths(teststrsplit)  ## 5 elt list. Apparently the 5 are in the only list elt ??????????
lengths(teststrsplit[1])
lengths(teststrsplit[[1]])

teststrsplit[[1]][1]
teststrsplit[[1]][2]

STOPPED

03/20/16:
# 1 Q: can I select out the 2185 95C_UP records in common betw. Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95C-UP.subset
and trinotate_annotation_report.xls files.
# DONE, 
# ref: p-223, vbufallo book. But need to check if can access colms 2 & 14 from output of this 'match' approach.

ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo
ls -al
module load R/3.2  ## 3.2.1
R
# attempt analyze in R on crane ???????????
xlsC_up_logdf <- read.delim("xlsC_up_logdf.txt", stringsAsFactors=FALSE, header=TRUE)
colnames(xlsC_up_logdf)
[1] "X.gene_id.transcript_id.sprot_Top_BLASTX_hit.TrEMBL_Top_BLASTX_hit.RNAMMER.prot_id.prot_coords.sprot_Top_BLASTP_hit.TrEMBL_Top_BLASTP_hit.Pfam.SignalP.TmHMM.eggnog.gene_ontology_blast.gene_ontology_pfam.transcript.peptide"
# so this output unexpected, perhaps go back, generate xlsC_up_logdf again, see if can get 'colnames()' output as expected ?????????????????
rm(xlsC_up_logdf)
ls()
xlsC_up_logdf <- read.table("xlsC_up_logdf.txt", header=T, sep=" ")
colnames(xlsC_up_logdf)  ## total 17 colms
# now colnames() output looks ok. 
dim(xlsC_up_logdf)
head(xlsC_up_logdf, n=2)
head(xlsC_up_logdf$gene_ontology_blast, n=2)
head(xlsC_up_logdf$transcript_id, n=2)
head(rownames(xlsC_up_logdf), n=3)
# if above shows can access data.frame colms ok, next to remove rows of dataframe based on colm 14 which have a "." in colm 14, i.e., no 'GOterms'.
# try 2 or 3 examples from internet on top10xlsfile.txt

top11xlsfiletest <- read.table("top11xlsfile.txt", header=T, sep=" ")
# still error, '  more columns than column names' ???????????????
head -n 3 xlsC_up_logdf.txt
head -n 10 xlsC_up_logdf.txt > top10xlsC_up_logdf.txt
top10xlsC_up_logdf <- read.table("top10xlsC_up_logdf.txt", header=T, sep=" ")
colnames(top10xlsC_up_logdf)
# now colnames() output looks ok. 

head(top10xlsC_up_logdf, n=2)
top10xlsC_up_logdfGO <-  top10xlsC_up_logdf[grep("^GO:", top10xlsC_up_logdf$gene_ontology_blast, perl=TRUE), ]
dim(top10xlsC_up_logdfGO)  ## [1]  5 17
dim(top10xlsC_up_logdf)  ## [1]  9 17
## so finds 5 of 9 records to begin with 'GO:'
##top10xlsC_up_logdfGO <- top10xlsC_up_logdf[grep1("^GO:", top10xlsC_up_logdf$gene_ontology_blast), ]
#   could not find function "grep1"
# so expect # so 978 of 2185 records not to have GO: in colm14. TO CHECK:
xlsC_up_logdf <- read.table("xlsC_up_logdf.txt", header=T, sep=" ")
colnames(xlsC_up_logdf)
dim(xlsC_up_logdf)
[1] 2185   17

xlsC_up_logdfGO <-  xlsC_up_logdf[grep("^GO:", xlsC_up_logdf$gene_ontology_blast, perl=TRUE), ]
dim(xlsC_up_logdfGO)  ## expect 1207, got [1] 1074   17 ??????????????

q()

## to do, scp 
xlsC_up_logdfGO.txt over to 'pro', so can look at in BBedit. Then for xlsC_up_logdf.txt & xlsC_up_logdfGO.txt, try 'cut' colm 14, may be easier to count number of 'GO:' rows. Try resolve diff. 1207, 1074 above ??????

cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing
scp pterry@crane.unl.edu:/work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo/xlsC_up_logdfGO.txt .

#cut -d ' ' -f 14 xlsC_up_logdf.txt | head -n 4 > rows6col4.txt
cut -d ' ' -f 14 xlsC_up_logdf.txt | head -n 4
cut -d '" "' -f 14 xlsC_up_logdf.txt | head -n 3
# cut not working ????????????????????

# so, perhaps, in R, create colm2, colm14 file (need one each for xlsC_up_logdf & xlsC_up_logdfGO. Check in R, if correct there, write.table each to file. Then scp them to 'pro' laptop. Then check for rows wi 'GO:' terms in colm14, try resolve diff. 1207, 1074 count above.

03/21/16:
# try this all this on **'pro'**, since all the files now om the 'pro'.
cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing
ls -al x*
wc xlsC_up_logdf.txt
    2186   97965 1405678 xlsC_up_logdf.txt  
## as expected length, includes header for colms
wc xlsC_up_logdfGO.txt
    1075   73608 1182169 xlsC_up_logdfGO.txt
R
getwd()
xlsC_up_logdf <- read.table("xlsC_up_logdf.txt", header=T, sep=" ")
colnames(xlsC_up_logdf)
dim(xlsC_up_logdf)
head(xlsC_up_logdf$transcript_id, n=3)
# 2185 factor levels, think should have stopped the factors ??????
rm(xlsC_up_logdf)
ls()
xlsC_up_logdf <- read.delim("xlsC_up_logdf.txt", header=T, sep=" ", stringsAsFactors=FALSE)
colnames(xlsC_up_logdf)  ## looks ok now.
dim(xlsC_up_logdf)
head(xlsC_up_logdf$transcript_id, n=3)
write.table(xlsC_up_logdf$transcript_id, "xlsC_up_logdfcolm2full.txt")
write.table(xlsC_up_logdf$gene_ontology_blast, "xlsC_up_logdfcolm14full.txt")

## Q: has numbered rows, quoted columns, perhaps can use 'sed' to remove ?????
#xlsC_up_logdfGO <- read.table("xlsC_up_logdfGO.txt", header=T, sep=" ")
xlsC_up_logdfGO <- read.delim("xlsC_up_logdfGO.txt", header=T, sep=" ", stringsAsFactors=FALSE)
colnames(xlsC_up_logdfGO)
dim(xlsC_up_logdfGO)  ## [1] 1074   17
head(xlsC_up_logdfGO$transcript_id, n=2)
head(xlsC_up_logdfGO$gene_ontology_blast, n=2)
write.table(xlsC_up_logdfGO$transcript_id, "xlsC_up_logdfcolm2fullGO.txt")
write.table(xlsC_up_logdfGO$gene_ontology_blast, "xlsC_up_logdfcolm14fullGO.txt")

## Now to check colm 14, in 'GO' output file. Do all rows befin with 'GO:' ????
## yes, so need 
i) clean up row numbers, quote marks in colm 2, colm 14 for 'GO:' files.
# p-165, vbuffalo bk, to get **'GNU'**, perhaps do on crane ??????

STOPPED

ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo
ls -al
module load R/3.2  ## 3.2.1
R
getwd()
xlsC_up_logdf <- read.delim("xlsC_up_logdf.txt", header=T, sep=" ", stringsAsFactors=FALSE)
colnames(xlsC_up_logdf)  ## looks ok now, but quotes around each name ????
dim(xlsC_up_logdf)  ## [1] 2185   17
head(xlsC_up_logdf$transcript_id, n=3)
write.table(xlsC_up_logdf$transcript_id, "xlsC_up_logdfcolm2full.txt")
write.table(xlsC_up_logdf$gene_ontology_blast, "xlsC_up_logdfcolm14full.txt")

xlsC_up_logdfGO <- read.delim("xlsC_up_logdfGO.txt", header=T, sep=" ", stringsAsFactors=FALSE)
colnames(xlsC_up_logdfGO)
dim(xlsC_up_logdfGO)  ## [1] 1074   17
head(xlsC_up_logdfGO$transcript_id, n=2)
head(xlsC_up_logdfGO$gene_ontology_blast, n=2)
write.table(xlsC_up_logdfGO$transcript_id, "xlsC_up_logdfcolm2fullGO.txt")
write.table(xlsC_up_logdfGO$gene_ontology_blast, "xlsC_up_logdfcolm14fullGO.txt")
# Q: what to do about colm names ??????
# now, to try clean, perhaps with 'sed',

xlsC_up_logdfcolm2fullGO.txt
xlsC_up_logdfcolm14fullGO.txt

## 1st step
sed -E 's/^("[^"]+)" //' xlsC_up_logdfcolm2fullGO.txt | head -n 2
# why leaving 'header' '"x"' un dealt with ????????????????????
# perhaps cause treating as a header ???????????
sed -E 's/^("[^"]+)" //' xlsC_up_logdfcolm2fullGO.txt > xlsC_up_logdfcolm2fullGOhalfsed.txt
"x"
"TRINITY_DN35725_c0_g1_i1"
## 2nd step
sed -E 's/^(")//g' xlsC_up_logdfcolm2fullGOhalfsed.txt > xlsC_up_logdfcolm2fullGO3fourthssed.txt
sed -E 's/("$)//' xlsC_up_logdfcolm2fullGO3fourthssed.txt > xlsC_up_logdfcolm2fullGOsedcomp.txt
wc xlsC_up_logdfcolm2fullGOsedcomp.txt
 1075  1075 26872 xlsC_up_logdfcolm2fullGOsedcomp.txt
## **still** have colm name 'x', otherwise, ready for step (ii). Since now just a vector, perhaps go in, remove this 'x' from 1st row of file with editor ???

03/22/16:
# ok, xlsC_up_logdfcolm14fullGO.txt file, remove '"'s and 'char row numbers, & '"x"' colm name.
ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo
head -n 2 xlsC_up_logdfcolm14fullGO.txt
sed -E 's/^("[^"]+)" //' xlsC_up_logdfcolm14fullGO.txt | head -n 2
sed -E 's/^("[^"]+)" //' xlsC_up_logdfcolm14fullGO.txt > xlsC_up_logdfcolm14fullGO.txthalfsed.txt

sed -E 's/^(")//g' xlsC_up_logdfcolm14fullGO.txthalfsed.txt > xlsC_up_logdfcolm14fullGO3fourthssed.txt
sed -E 's/("$)//' xlsC_up_logdfcolm14fullGO3fourthssed.txt > xlsC_up_logdfcolm14fullGOsedcomp.txt
# still, to remove colm header, 'x'

cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing
scp pterry@crane.unl.edu:/work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo/xlsC_up_logdfcolm14fullGOsedcomp.txt .
# removed colm header ('x') => xlsC_up_logdfcolm14fullGOsedcompminuscolhead.txt
scp xlsC_up_logdfcolm14fullGOsedcompminuscolhead.txt pterry@crane.unl.edu:/work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo/

ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo
ls -al
less xlsC_up_logdfcolm14fullGOsedcompminuscolhead.txt 
wc xlsC_up_logdfcolm14fullGOsedcompminuscolhead.txt
  1074  11865 324025 xlsC_up_logdfcolm14fullGOsedcompminuscolhead.txt
# ok, ready for 'strsplit', etc.

# then p-253, vbuffalo, *for* loop using strsplit to put colm 14 GOterms into one per row, and *ctr* wi number Goterms per row, so can expand colm 2 later.

module load R/3.2  ## 3.2.1
R
getwd()
#xlsC_up_logdfcolm14fullGOsedcompminuscolhead <- read.delim("xlsC_up_logdfcolm14fullGOsedcompminuscolhead.txt", header=FALSE, sep=" ", stringsAsFactors=FALSE)

#class(xlsC_up_logdfcolm14fullGOsedcompminuscolhead)
[1] "data.frame"
#head(xlsC_up_logdfcolm14fullGOsedcompminuscolhead, n=2)
# created 32 colms ??????????????????????????
# try
#strsplit(xlsC_up_logdfcolm14fullGOsedcompminuscolhead[1], "`")
Error in strsplit(xlsC_up_logdfcolm14fullGOsedcompminuscolhead[1], "`") : 
  non-character argumentlength(xlsC_up_logdfcolm14fullGOsedcompminuscolhead.txt)

# so go back to form with quotes, when delim, inside that command, try assign colm name 'gene_ontology_blast', 1st try wi xlsC_up_logdfcolm14fullGO.txt
xlsC_up_logdfcolm14fullGO <- read.delim("xlsC_up_logdfcolm14fullGO.txt", header=TRUE, sep=" ", stringsAsFactors=FALSE, col.names="gene_ontology_blast")
class(xlsC_up_logdfcolm14fullGO)
head(xlsC_up_logdfcolm14fullGO, n=2)
# have one colm, 'gene_ontology_blast', but no '"'s in data.frame ????????
strsplit(xlsC_up_logdfcolm14fullGO[1], "`")
Error in strsplit(xlsC_up_logdfcolm14fullGO[1], "`") : 
  non-character argument
  
# start again, try xlsC_up_logdfcolm14fullGO.txthalfsed.txt. Still has quotes arould colm 14 GOterms.
module load R/3.2  ## 3.2.1
R
getwd()
xlsC_up_logdfcolm14fullGOhalfsed <- read.delim("xlsC_up_logdfcolm14fullGO.txthalfsed.txt", header=T, sep=" ", stringsAsFactors=FALSE)
## Note 
head -n 3 xlsC_up_logdfcolm14fullGO.txthalfsed.txt
# has quotes on all the colm 14 rows ??????????????????????

03/23/16:
ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo
ls -al
less xlsC_up_logdfcolm14fullGO.txthalfsed.txt 
## has quotes on colm 14 data

head -n 2 xlsC_up_logdfcolm14fullGO.txthalfsed.txt
## still has quotes
wc xlsC_up_logdfcolm14fullGO.txthalfsed.txt
  1075  11866 326177 xlsC_up_logdfcolm14fullGO.txthalfsed.txt
module load R/3.2  ## 3.2.1
R
getwd()
## xlsC_up_logdfcolm14fullGOhalfsed <- read.delim("xlsC_up_logdfcolm14fullGO.txthalfsed.txt", header=T, sep=" ", stringsAsFactors=FALSE)
## test if don't have 'sep=" ",'
xlsC_up_logdfcolm14fullGOhalfsed <- read.delim("xlsC_up_logdfcolm14fullGO.txthalfsed.txt", header=T, stringsAsFactors=FALSE)
head(xlsC_up_logdfcolm14fullGOhalfsed, n=2)
## no quotes ?????
## rm(xlsC_up_logdfcolm14fullGOhalfsed)
## ls()
# GOterm rows now don't have quotes ???????????????

colnames(xlsC_up_logdfcolm14fullGOhalfsed)
"x"
colnames(xlsC_up_logdfcolm14fullGOhalfsed) <- "gene_ontology_blast"
colnames(xlsC_up_logdfcolm14fullGOhalfsed)
dim(xlsC_up_logdfcolm14fullGOhalfsed)  ## [1] 1074   17
class(xlsC_up_logdfcolm14fullGOhalfsed)
[1] "data.frame"
xlsC_up_logdfcolm14fullGOhalfsed[1]
## many screens ????????
head(xlsC_up_logdfcolm14fullGOhalfsed$gene_ontology_blast, n=2)
xlsC_up_logdfcolm14fullGOhalfsed[1 , 1]
## output row 1 **with** quotes ??????????????????????

## as.character(xlsC_up_logdfcolm14fullGOhalfsed[1])
#strsplit(as.character(xlsC_up_logdfcolm14fullGOhalfsed[1]), "`")
strsplit(xlsC_up_logdfcolm14fullGOhalfsed[1,1], "`")
## good output, now try capture in list, then convert to vector
templist <- strsplit(xlsC_up_logdfcolm14fullGOhalfsed[1,1], "`")
class(templist)
templist
unlist(templist)
tempvec <- unlist(templist)
class(tempvec)
[1] "character"
length(tempvec)
[1] 19
## left, demo copying tempvec into new vec to hold all 1074 GO:terms expanded.
#GOtermvec[1] <- tempvec[1]
Error in GOtermvec[1] <- tempvec[1] : object 'GOtermvec' not found
# so how to fix ????????
GOtermvecexpand <- vector(mode="character", length=25)
length(GOtermvecexpand)
GOtermvecexpand[1] <- tempvec[1]
GOtermvecexpand
## create for loop to copy the 19 elts of tempvec to GOtermvecexpand

for (i in 1:length(tempvec)) {
  GOtermvecexpand[i] <- tempvec[i]
}
GOtermvecexpand
## ok, 19 elts copied over.

# slip a save to ***github*** in here
cd ~/planets
git status
git add BdactyloidesthruGSEA081615.txt
git commit -m "update 03/23/16 BdactyloidesthruGSEA081615.txt from pro"
git status
git push origin master
# git remote -v

## before resume work on this file, need pull it down
cd ~/planets
git pull origin master
## so github pretty much up to date.

STOPPED

03/26-8/16:
## **next**, arrange 'outside for' loop to loop thru two rows in of xlsC_up_logdfcolm14fullGOhalfsed colm 14, so captured GO terms for two transcripts in vector GOtermvecexpand. Save GOterm count for each transcript in txexpandctr vector, 1704 elts needed.


# ref: 03/23/16
ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo
ls -al
less xlsC_up_logdfcolm14fullGO.txthalfsed.txt 
## has **quotes** on colm 14 data
module load R/3.2  ## 3.2.1
R
getwd()
xlsC_up_logdfcolm14fullGOhalfsed <- read.delim("xlsC_up_logdfcolm14fullGO.txthalfsed.txt", header=T, stringsAsFactors=FALSE)
head(xlsC_up_logdfcolm14fullGOhalfsed, n=2)
## **no quotes** ?????
colnames(xlsC_up_logdfcolm14fullGOhalfsed)
"x"
colnames(xlsC_up_logdfcolm14fullGOhalfsed) <- "gene_ontology_blast"
colnames(xlsC_up_logdfcolm14fullGOhalfsed)
dim(xlsC_up_logdfcolm14fullGOhalfsed)  ## [1] 1074   17
class(xlsC_up_logdfcolm14fullGOhalfsed)
[1] "data.frame"
dim(xlsC_up_logdfcolm14fullGOhalfsed)  ## [1] 1074    1
xlsC_up_logdfcolm14fullGOhalfsed[1 , 1]
## output tx row 1 **with** quotes ??????????????????????
GO1txtemplist <- strsplit(xlsC_up_logdfcolm14fullGOhalfsed[1,1], "`")
class(GO1txtemplist)
GO1txtemplist
unlist(GO1txtemplist)
GO1txtempvec <- unlist(GO1txtemplist)
class(GO1txtempvec)
[1] "character"
length(GO1txtempvec)
[1] 19

GOtermvecexpand <- vector(mode="character", length=7000)
mode(GOtermvecexpand)
GOtermvecexpandctr <- 0
##mode(GOtermvecexpandctr)
## NEED VECTOR TO HOLD COUNT OF NUMBER of tx_IDs need from colm2 ?????????
txcolm2expandvec <- numeric(length=1075)
txcolm2expandvec[1]
length(txcolm2expandvec)


##...
for (j in 1:1074) {  ## outer 'for loop', loop thru 95C-UP colm14 GOterms 
## access/copy a GOterms row
GO1txtemplist <- strsplit(xlsC_up_logdfcolm14fullGOhalfsed[j,1], "`")
## unlist to create temp vector
GO1txtempvec <- unlist(GO1txtemplist)
#print(GO1txtempvec)
## add one tx row (of 1074 rows) of GOterms to expanded list for all tx's/GOterm lines for 95C-UP DE tx's GOterms in internal for loop.

## later in here, check that won't exceed declared length of GOtermvecexpand vec before add additional GOterm character elts to it ??????

for (i in 1:length(GO1txtempvec)) {
  GOtermvecexpand[GOtermvecexpandctr + i] <- GO1txtempvec[i]
}
##stop("dummy error")
## need ctr so know where to add to GOtermvecexpand vec
GOtermvecexpandctr <- GOtermvecexpandctr + length(GO1txtempvec)
#print(GOtermvecexpandctr)
txcolm2expandvec[j] <- length(GO1txtempvec)
##stop("dummy error")
}
sum(txcolm2expandvec)
[1] 5769
print(GOtermvecexpand[5765:5775])
print(txcolm2expandvec[1:1075])
stop("dummy error")
##...

## so have the 5769 GOterms for 1074 tx IDs. Next, build expanded colm2 (tx_IDs) from txcolm2expandvec using the 1074 values in this vetor and (to be read in looks like from file xlsC_up_logdfcolm2fullGOhalfsed.txt 
) the colm 2 values (will there be trouble with 'quote' marks) ??????????????


03/30/16:
# ref: from 03/26-8/16:
ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo
ls -al
less xlsC_up_logdfcolm2fullGOhalfsed.txt 
## has **quotes** on colm 2 data
-rw-r--r--  1 pterry amundsen    29022 Mar 21 22:51 
# xlsC_up_logdfcolm2fullGOhalfsed.txt
module load R/3.2  ## 3.2.1
R
getwd()
xlsC_up_logdfcolm2fullGOhalfsed <- read.delim("xlsC_up_logdfcolm2fullGOhalfsed.txt", header=T, stringsAsFactors=FALSE)
head(xlsC_up_logdfcolm2fullGOhalfsed, n=2)
## **no quotes** ?????
colnames(xlsC_up_logdfcolm2fullGOhalfsed)
"x"
colnames(xlsC_up_logdfcolm2fullGOhalfsed) <- "transcript_id"
colnames(xlsC_up_logdfcolm2fullGOhalfsed)
class(xlsC_up_logdfcolm2fullGOhalfsed)
[1] "data.frame"
dim(xlsC_up_logdfcolm2fullGOhalfsed)  ## [1] 1074    1
xlsC_up_logdfcolm2fullGOhalfsed[1 , 1]
## output tx row 1 **with** quotes ??????????????????????
## **now** copy from line 5465 to 5524

xlsC_up_logdfcolm14fullGOhalfsed <- read.delim("xlsC_up_logdfcolm14fullGO.txthalfsed.txt", header=T, stringsAsFactors=FALSE)
head(xlsC_up_logdfcolm14fullGOhalfsed, n=2)
## **no quotes** ?????
colnames(xlsC_up_logdfcolm14fullGOhalfsed)
"x"
colnames(xlsC_up_logdfcolm14fullGOhalfsed) <- "gene_ontology_blast"
colnames(xlsC_up_logdfcolm14fullGOhalfsed)
class(xlsC_up_logdfcolm14fullGOhalfsed)
[1] "data.frame"
dim(xlsC_up_logdfcolm14fullGOhalfsed)  ## [1] 1074    1
xlsC_up_logdfcolm14fullGOhalfsed[1 , 1]
## output tx row 1 **with** quotes ??????????????????????
#GO1txtemplist <- strsplit(xlsC_up_logdfcolm14fullGOhalfsed[1,1], "`")
#class(GO1txtemplist)
#GO1txtemplist
#unlist(GO1txtemplist)
#GO1txtempvec <- unlist(GO1txtemplist)
#class(GO1txtempvec)
[1] "character"
#length(GO1txtempvec)
[1] 19

## GOtermvecexpand <- vector(mode="character", length=6000)
GOtermvecexpand <- vector(mode="character", length=5769)

#mode(GOtermvecexpand)
GOtermvecexpandctr <- 0
##mode(GOtermvecexpandctr)
## NEED VECTOR TO HOLD COUNT OF NUMBER of tx_IDs need from colm2 ?????????
txcolm2expandvec <- numeric(length=1075)
txcolm2expandvec[1]
length(txcolm2expandvec)


##...
for (j in 1:1074) {  ## outer 'for loop', loop thru 95C-UP colm14 GOterms 
## access/copy a GOterms row
  GO1txtemplist <- strsplit(xlsC_up_logdfcolm14fullGOhalfsed[j,1], "`")
## unlist to create temp vector
  GO1txtempvec <- unlist(GO1txtemplist)
#print(GO1txtempvec)
## add one tx row (of 1074 rows) of GOterms to expanded list for all tx's/GOterm lines for 95C-UP DE tx's GOterms in internal for loop.

## later in here, check that won't exceed declared length of GOtermvecexpand vec before add additional GOterm character elts to it ??????

  for (i in 1:length(GO1txtempvec)) {
    GOtermvecexpand[GOtermvecexpandctr + i] <- GO1txtempvec[i]
  }
##stop("dummy error")
## need ctr so know where to add to GOtermvecexpand vec
  GOtermvecexpandctr <- GOtermvecexpandctr + length(GO1txtempvec)
#print(GOtermvecexpandctr)
  txcolm2expandvec[j] <- length(GO1txtempvec)
##stop("dummy error")
}
sum(txcolm2expandvec)
[1] 5769
print(GOtermvecexpand[5765:5769])
print(txcolm2expandvec[1000:1075])
##stop("dummy error")

## Now, using txcolm2expandvec vector, 
print(txcolm2expandvec[1:4])
# and 
xlsC_up_logdfcolm2fullGOhalfsed[1 , 1]
dim(xlsC_up_logdfcolm2fullGOhalfsed)  ## [1] 1074    1
## create new vector with 5769 elements, use txcolm2expandvec vector to allocate appropriate number each tx_id from xlsC_up_logdfcolm2fullGOhalfsed to the new vector.

tx_idexpandedcolm2vec <- vector(mode="character", length=5769)
tx_idexpandedcolm2vec[1:2]
tx_idexpandedcolm2vecctr <- 0

##xlsC_up_logdfcolm2fullGOhalfsed$transcript_id[1]


for (k in 1:1074) {  ## k stepping thru tx_idexpandedcolm2vec elements
  indiv_tx_num_temp <- txcolm2expandvec[k]
  for (l in 1:indiv_tx_num_temp) {
    tx_idexpandedcolm2vecctr <- tx_idexpandedcolm2vecctr + 1
    tx_idexpandedcolm2vec[tx_idexpandedcolm2vecctr] <- xlsC_up_logdfcolm2fullGOhalfsed$transcript_id[k]
  }
#if (k > 2) {
#  stop("dummy error")
#}
}
tx_idexpandedcolm2vecctr
[1] 5769
tx_idexpandedcolm2vec[1:37]
tx_idexpandedcolm2vec[5759:5769]
xlsC_up_logdfcolm2fullGOhalfsed$transcript_id[1070:1074]

print(GOtermvecexpand[1:10])
print(GOtermvecexpand[5765:5769])


04/01/16:
## ok, looks like have expanded colm 2, and colm 14 expanded, one GO:term per line. So each vector 5739 elements long.
## now, try split GO: part of GO:term off from description part of GO:term. Try do 1st in R with 'strsplit'. If fails, then try do with 'sed' outside of R. Yet to decide how to format to 'write.table' from R.

colm14GOterm_numexpandvec <- vector(mode="character", length=5769)
colm14GOterm_descexpandvec <- vector(mode="character", length=5769)

#*********************skip from here down to
########colm14GOterm_expandvecctr <- 0
class(GOtermvecexpand)
[1] "character"
## if vec, change [...] in loop ???????????????
GOtermvecexpand[1]
strsplit(GOtermvecexpand[1], ":")  ## works
strsplit(GOtermvecexpand[1], "^")  ## fails ????????????????

04/02/16:
[1] "GO:0009507^cellular_component^chloroplast"

cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing
sed s/^/	/ "GO:0009507^cellular_component^chloroplast"
## fails, needs file.
cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/testing
sed 's/^/	/' test_sed040216.txt  ## no change ??????????
sed 's/\^/	/' test_sed040216.txt  
"GO:0009507cellular_component^chloroplast"
## so removed 1st '^', but left nothing in its place ?????????
sed 's/\^/\\t/' test_sed040216.txt
"GO:0009507\tcellular_component^chloroplast"
## so try just come blank spaces
sed 's/\^/ /' test_sed040216.txt
"GO:0009507 cellular_component^chloroplast"
## so at least found, replaced '^' with a spaces
sed 's/\^/`/' test_sed040216.txt
"GO:0009507`cellular_component^chloroplast"
## so try this, since know no '`' remain in these strings. Make this change outside R, then bring into R, try strsplit


## test strsplit in R
teststrsplit <- "GO:0009507`cellular_component^chloroplast"
testoutputlist <- strsplit(teststrsplit, "`")
class(testoutputlist)
testoutputvec <- unlist(testoutputlist)
class(testoutputvec)
testoutputvec
testoutputvec[1]
testoutputvec[2]
## okay, so put this together to split colm 14 as needed.
#*************************************************


class(GOtermvecexpand)
[1] "character"
## if vec (???), create df wi this as only colm.
tempcolm14expandeddf <- data.frame(colm14expd = GOtermvecexpand)
## do bit checking on df ?????
class(tempcolm14expandeddf)
dim(tempcolm14expandeddf)
head(tempcolm14expandeddf, n=2)
## ref: p-260, vbuffalo bk
# write.table(tempcolm14expandeddf, file="tempcolm14expandeddf.txt", row.names=FALSE)
q()

#ls -al temp*.txt
-rw-r--r-- 1 pterry amundsen 335576 Apr  2 22:09 tempcolm14expandeddf.txt
#less tempcolm14expandeddf.txt
# has colm header "colm14expd"
# all rows are char strings with quote marks around string 
#sed 's/\^/`/' tempcolm14expandeddf.txt > tempcolm14newsymbol.txt
#less tempcolm14newsymbol.txt
# 1st '^' each row replaced by '`'
#head -n 3 tempcolm14newsymbol.txt

# back to R, ref: p-196, vbuffalo bk
# new session, start wi 3/30/16 above, select appropriate code lines to run to get down to here.

tempcolm14newsymbol <- read.delim("tempcolm14newsymbol.txt", header=TRUE)
class (tempcolm14newsymbol)
[1] "data.frame"
print(tempcolm14newsymbol[1:3, ])
# made factors of the colm.
tempcolm14newsymbol <- read.delim("tempcolm14newsymbol.txt", header=TRUE, stringsAsFactors=FALSE)
class (tempcolm14newsymbol)
colnames(tempcolm14newsymbol)
dim(tempcolm14newsymbol)
head(tempcolm14newsymbol, n=2)
# no quotes ?????????


## if have quotes, ready for strsplit
tempoutputlist <- strsplit(tempcolm14newsymbol[1], "`")
Error in strsplit(tempcolm14newsymbol, "`") : non-character argument
tempcolm14newsymbolchar <- as.character(tempcolm14newsymbol$colm14expd)
head(tempcolm14newsymbolchar, n=2)
# has quotes, but header name not printed ???????
class(tempcolm14newsymbolchar)
[1] "character"
# no longer a dataframe ???????????????????
tempoutputlist <- strsplit(tempcolm14newsymbolchar[1], "`")
tempoutputlist
tempoutputvec <- unlist(tempoutputlist)
class(tempoutputvec)
tempoutputvec[1]
tempoutputvec[2]
## ok, so ready for loop ??????????????


for (i in 1:5769) {
#  GO1colm14templist <- strsplit(GOtermvecexpand[i], "^")
  GO1colm14templist <- strsplit(tempcolm14newsymbolchar[i], "`")
#print(GO1colm14templist)
## unlist to create temp vector
## two elts from GOtermvecexpand, 1st GO:???????, 2nd description portion of row
  GO1colm14tempvec <- unlist(GO1colm14templist)
#print(GO1colm14tempvec)
#stop("dummy error")
## place each in its own 5769 elt vec.
#######  colm14GOterm_expandvecctr <- colm14GOterm_expandvecctr + 1
  colm14GOterm_numexpandvec[i] <- GO1colm14tempvec[1]
  colm14GOterm_descexpandvec[i] <- GO1colm14tempvec[2]
#if (i > 2) {
#  stop("dummy error")
#}
}
## look at new vecs ??????
colm14GOterm_numexpandvec[1:3]
colm14GOterm_numexpandvec[5765:5769]

colm14GOterm_descexpandvec[1:3]
colm14GOterm_descexpandvec[5765:5769]
# ok, finally (i) create df with 3 colms (the 3 vecs, tx, GOnum, & GOdisc, (2) write to disk (see p-260, vbuffalo bk)

tx_idexpandedcolm2vec[1:10]

colm14expandeddf <- data.frame(tx_ids = tx_idexpandedcolm2vec, GOnums = colm14GOterm_numexpandvec, GOdisc = colm14GOterm_descexpandvec)
dim(colm14expandeddf)
[1] 5769    3
colnames(colm14expandeddf)
[1] "tx_ids" "GOnums" "GOdisc"
head(colm14expandeddf, n=2)
# looks ok, no quotes ??????????????
write.table(colm14expandeddf, file = "threecolmsexpandeddf.txt", quote=FALSE, sep="\t", row.names=FALSE, col.names=FALSE)
q()
ls -al three*
-rw-r--r-- 1 pterry amundsen 468325 Apr  3 00:21 threecolmsexpandeddf.txt
less threecolmsexpandeddf.txt
head -n 3 threecolmsexpandeddf.txt
[pterry@login.crane vbufalo]$ head -n 3 threecolmsexpandeddf.txt
TRINITY_DN35725_c0_g1_i1	GO:0009507	cellular_component^chloroplast
TRINITY_DN35725_c0_g1_i1	GO:0009534	cellular_component^chloroplast thylakoid
TRINITY_DN35725_c0_g1_i1	GO:0009535	cellular_component^chloroplast thylakoid membrane
tail -n 3 threecolmsexpandeddf.txt
TRINITY_DN46525_c0_g1_i10	GO:0008017	molecular_function^microtubule binding
TRINITY_DN46525_c0_g1_i10	GO:0003777	molecular_function^microtubule motor activity
TRINITY_DN46525_c0_g1_i10	GO:0007018	biological_process^microtubule-based movement
wc threecolmsexpandeddf.txt
  5769  28098 468325 threecolmsexpandeddf.txt

# so looks like have the 3 colm form ala vikas, next blast2go, try get hierarchical overview of the 5769 GO terms for 95C_UP DE'd transcripts.
# yet to do, 95T_UP DE''d transcripts (try with '%>% & dplyr) ???????

04/06/16:
# To do:
i) send top 27 (2 transcripts) of file threecolmsexpandeddf.txt so he can experiment with Blast2GO application. I note vikas example 3 colm files do not have '^' character that mine have ?????????????????

ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo
ls -al
head -n 27 threecolmsexpandeddf.txt | cat
## copied to bbedit, then saved as
## 95CUP_27_3colmrecs_forvikas.txt
in trintoGSEA dir in keenan2015 dir. on 'pro'.

ii) Q: for vikas: do you dnload basic version of Blast2GO, can it do what I need, that is take the 3 column file you described as input and provide summary of the 5769 GOterms in the file?

04/07/16:
## received Vikas email.
## To do, in threecolmsexpandeddf.txt file, in 3rd colm, need remove characters in front of '^' including the '^'.
## refer: p-166, vbuffalo bk

ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo
ls -al
cut -f3 threecolmsexpandeddf.txt | head -n 2
cut -f3 threecolmsexpandeddf.txt | sed -E 's/^([^\^]+)\^//' | head -n 2
## as planned.
cut -f3 threecolmsexpandeddf.txt | sed -E 's/^([^\^]+)\^//' > fixedcolm3.txt
cut -f1,2 threecolmsexpandeddf.txt | paste fixedcolm3.txt | head -n 2
## output only fixedcolm3.txt content ??????????????
cut -f1,2 threecolmsexpandeddf.txt > colms1and2.txt
paste colms1and2.txt fixedcolm3.txt | head -n 2
## looks ok.
paste colms1and2.txt fixedcolm3.txt > threecolmsexpandeddfvikasform.txt
head -n 2 threecolmsexpandeddfvikasform.txt
wc threecolmsexpandeddfvikasform.txt
  5769  28098 358714 threecolmsexpandeddfvikasform.txt

STOPPED

##********************************************************************
##********************************************************************
04/08-09/16:
## start work with 95T_UP & trinotate 'xls' with '%>%' & dplyr
## look at what did for 95CUP & '.xls' to find subset of '.xls' tx's which up regulated in 95TUP.
## p-243, vbuffalo bk, get famiiar with '%>%' & dplyr.

## from 4544, 'how many tx's from 95T_up in .xls' ???????????

04/10/16:
ssh -Y pterry@crane.unl.edu  ## line 4511
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo
ls -al *.subset
-rw-r--r-- 1 pterry amundsen 547935 Feb 15 11:24 Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95T-UP.subset
#cp Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95T-UP.subset 95TUPsubset/
#cp trinotate_annotation_report.xls 95TUPsubset/
cd 95TUPsubset/

module load R/3.2  ## 3.2.5
R
# attempt analyze in R on crane ???????????
getwd()
de95T_up <- read.delim("Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95T-UP.subset", header=TRUE)
colnames(de95T_up)
dim(de95T_up)
[1] 3971   11
head(de95T_up, n=3)
                        id    logFC   logCPM       PValue          FDR X95C1
1 TRINITY_DN42864_c1_g1_i1 10.90111 6.529331 4.649629e-35 3.719401e-30 0.091
2 TRINITY_DN73954_c0_g1_i1 10.38759 5.187235 1.134433e-27 2.592778e-23 0.170
3 TRINITY_DN47196_c1_g1_i1 12.22126 4.804913 7.542450e-27 1.206694e-22 0.000
  X95C2 X95C3   X95T1  X95T2   X95T3
1 0.079     0 109.103 99.779 137.430
2 0.000     0 116.229 82.679  97.276
3 0.011     0  40.494 37.399  41.878
go_xls <- read.delim("trinotate_annotation_report.xls", header=TRUE)
# Q: what are delimeters in this file ????????????????????????????
colnames(go_xls)
dim(go_xls)  ## [1] 178727     17
head(go_xls, n=2)
# now %in%, T_UP in go_xls
Tinxls <- de95T_up$id %in% go_xls$transcript_id
length(Tinxls)
[1] 3971
head(Tinxls)
[1] TRUE TRUE TRUE TRUE TRUE TRUE
sum(Tinxls)
[1] 3971
## so all DE tx's in de95T_up are also in go_xls (same num. records as de95T_up)



table(Tinxls)   ## TRUE 3971 
i <- match(de95T_up$id, go_xls$transcript_id)
length(i)  ## [1] 3971
table(de95T_up$id %in% go_xls$transcript_id)  ## TRUE 3971 
##************************************************************
table(go_xls$transcript_id %in% de95T_up$id)
 FALSE   TRUE 
173911   4816 
## perhaps some duplicate transcript_is's in '.xls' for those in de95T_up$id ???????????
## perhaps further ***checking*** needed, i.e., if multiple rows for de95T_up$id in go_xls$transcript_id, then perhaps miss extracting some GO terms from '.xls' file ????????????????????????????????????????????
##*************************************************************
head(i, 3)
[1] 122993  54917  42112
## Next line, pulled out the 3951 95T_up DE tx's rows from trinotate_annotation_report.xls, then written to a file.
xlsT_up_logdf <- go_xls[i,]  ## check if get 3971 records ???????
dim(xlsT_up_logdf)
[1] 3971   17
head(xlsT_up_logdf, 2)
write.table(xlsT_up_logdf, "xlsT_up_logdf.txt")  ## line 4568

## xlsT_up_logdf.txt HAS THE 3971 ROWS FROM trinotate_annotation_report.xls UP REGULATED IN THE THREE 95T_up TREATMENT SAMPLES.
save.image(file="may17_16.RData")
q()

ls -al
wc xlsT_up_logdf.txt
   3972  209173 3261778 xlsT_up_logdf.txt

ssh -Y pterry@crane.unl.edu  ## line 4511
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo
cd 95TUPsubset/

wc xlsT_up_logdf.txt
   3972  209173 3261778 xlsT_up_logdf.txt
head -n 2 xlsT_up_logdf.txt
less xlsT_up_logdf.txt
## So the 95T_up tx's from '.xls' in xlsT_up_logdf.txt


module load R/3.2  ## 3.2.5
R
# attempt analyze in R on crane ???????????
getwd()
load(file="may17_16.RData")
ls()
colnames(xlsT_up_logdf)
dim(xlsT_up_logdf)
## ref line 5141

## GET AND WRITE THE 2638 SUBSET of xlsT_up_logdf TX'S WHICH ACTUALLY HAVE GOterms IN COLM 14 OF trinotate_annotation_report.xls FILE.
xlsT_up_logdfGO <-  xlsT_up_logdf[grep("^GO:", xlsT_up_logdf$gene_ontology_blast, perl=TRUE), ]
dim(xlsT_up_logdfGO)  ## [1] 2638   17
write.table(xlsT_up_logdfGO, "xlsT_up_logdfGO.txt")
## now have subset of 95T_up which 'have' Go terms in colm 14
save.image(file="may17_16.RData")
q()
ls -al
wc xlsT_up_logdfGO.txt
   2639  176628 2918435 xlsT_up_logdfGO.txt


05/18/16:
## deleted ~ 120 lines
...
save.image(file="may19_16.RData")


#line 5422
##****************************************************************
## ACTUALLY BUILDING GOtermvecexpand AND txcolm2expandvec WI NESTED 'FOR' LOOPS.
********************************************************************
GOtermvecexpand <- vector(mode="character", length=15100)
mode(GOtermvecexpand)
GOtermvecexpandctr <- 0
##mode(GOtermvecexpandctr)
## NEED VECTOR TO HOLD COUNT OF NUMBER of tx_IDs need from colm2 ?????????
txcolm2expandvec <- numeric(length=2638)
txcolm2expandvec[1]
length(txcolm2expandvec)

## line 5433 above
for (j in 1:2638) {  ## outer 'for loop', loop thru 95T-UP colm14 GOterms 
## access/copy a GOterms row
GO1txtemplist <- strsplit(tmpcolm14charvec[j], "`")
## unlist to create temp vector
GO1txtempvec <- unlist(GO1txtemplist)
#print(GO1txtempvec)
## add one tx row (of 2638 rows) of GOterms to expanded list for all tx's/GOterm lines for 95T-UP DE tx's GOterms in internal for loop.

## later in here, check that won't exceed declared length of GOtermvecexpand vec before add additional GOterm character elts to it ??????

  for (i in 1:length(GO1txtempvec)) {
    GOtermvecexpand[GOtermvecexpandctr + i] <- GO1txtempvec[i]
  }
#if(j > 1500) {
#stop("dummy error")
#}
## need ctr so know where to add to GOtermvecexpand vec
GOtermvecexpandctr <- GOtermvecexpandctr + length(GO1txtempvec)
#print(GOtermvecexpandctr)
txcolm2expandvec[j] <- length(GO1txtempvec)
##stop("dummy error")
}
print(GOtermvecexpandctr)  ## [1] 15092
print(GOtermvecexpand[15090:15100])
sum(txcolm2expandvec)
[1] 15092

## to check, last GOterm in tmpcolm14charvec
tail(tempcolm14df$gene_ontology_blast, n=2)
## "GO:0042144^biological_process^vacuole fusion, non-autophagic"  
## last GO term in colm 14 is ***same*** as last one in GOtermvecexpand vector.
tail(txcolm2expandvec, n=4)  ## [1]  9 10  0  0
## Looks ok.
## [1] 14  4  9 10
## when txcolm2expandvec shortened by two, rerun.

length(txcolm2expandvec)  ## [1] 2638

##****************************************************************
## so have the ***15092 (but vec is 15100, will reduce to 15092 below) GOterms for 2638*** tx IDs in 'GOtermvecexpand', and the number of each tx lines for expanded colm 2 in 'txcolm2expandvec'.
##**************************************************************

## line 5460 above
## Next, build expanded colm2 (tx_IDs) from txcolm2expandvec using the 2638 values in this vector and tmpcolm2charvec, the colm 2 values.

#tempcolm14df <- data.frame(xlsT_up_logdfGO$gene_ontology_blast)
#colnames(xlsT_up_logdfGO)
tmpcolm2charvec <- as.character(xlsT_up_logdfGO$transcript_id)
class(tmpcolm2charvec)
length(tmpcolm2charvec)  ## [1] 2638
head(tmpcolm2charvec, n=3)
[1] "TRINITY_DN42864_c1_g1_i1" "TRINITY_DN47196_c1_g1_i1"
tail(tmpcolm2charvec, n=3)
[3] "TRINITY_DN237_c0_g1_i1"   

colnames(xlsT_up_logdfGO)
head(xlsT_up_logdfGO, n=2)
tail(xlsT_up_logdfGO, n=1)
## ok, 1st, last tx ID in tmpcolm2charvec vector ok.

save.image(file="may19_16.RData")
q()
 
05/20/16:

## Use txcolm2expandvec (number each tx_id needed to match up with expanded list of GOterms) & tmpcolm2charvec (the 2638 tx_id's need to 'expand').

length(txcolm2expandvec)  ## [1] 2638
head(txcolm2expandvec, n=5)  ## [1] 1 3 2 1 5

ssh -Y pterry@crane.unl.edu  ## line 4511
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo
cd 95TUPsubset/
ls -al
module load R/3.2  ## 3.2.5
R
# attempt analyze in R on crane ???????????
getwd()
load(file="may19_16.RData")
ls()



## create new vector with 15092 elements, use txcolm2expandvec vector to allocate appropriate number each tx_id from tmpcolm2charvec to a new vector.

tx_idexpandedcolm2vec <- vector(mode="character", length=15092)
tx_idexpandedcolm2vec[1:2]
tx_idexpandedcolm2vecctr <- 0

##xlsC_up_logdfcolm2fullGOhalfsed$transcript_id[1]


for (k in 1:2638) {  ## k stepping thru tx_idexpandedcolm2vec elements
  indiv_tx_num_temp <- txcolm2expandvec[k]
  for (l in 1:indiv_tx_num_temp) {
    tx_idexpandedcolm2vecctr <- tx_idexpandedcolm2vecctr + 1
    tx_idexpandedcolm2vec[tx_idexpandedcolm2vecctr] <- tmpcolm2charvec[k]
  }
#if (k > 2) {
#  stop("dummy error")
#}
}
tx_idexpandedcolm2vecctr
[1] 15092
tx_idexpandedcolm2vec[1:10]
tx_idexpandedcolm2vec[15090:15095]
[1] "TRINITY_DN237_c0_g1_i1" "TRINITY_DN237_c0_g1_i1" "TRINITY_DN237_c0_g1_i1"
[4] NA                       NA                       NA                      

##**************************************************************
## looks ok, have vec 15092 tx elts (from colm 2, tx_idexpandedcolm2vec) matching expanded (long form) GOterms from colm 14 for 95T_up trt hits in 'GOtermvecexpand'.
##****************************************************************
save.image(file="may20_16.RData")
q()


#print(GOtermvecexpand[1:10])
#print(GOtermvecexpand[5765:5769])

## next, line 5587
## ok, looks like have expanded colm 2, and colm 14 expanded, one GO:term per line. So each vector 15092 elements long.


## TO DO, CHECK THIS ????????????????????, i.e., get these vectors, check length ??????????

##******************************************************************
## now, try split GO: part of GO:term off from description part of GO:term. 1st, try with 'sed' outside of R to change "^" to "`" (so strsplit can handle). 
##********************************************************************

ssh -Y pterry@crane.unl.edu  ## line 4511
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo
cd 95TUPsubset/
ls -al
module load R/3.2  ## 3.2.5
R
# attempt analyze in R on crane ???????????
getwd()
load(file="may20_16.RData")
ls()
class(GOtermvecexpand)  ## [1] "character"
GOtermvecexpand[15090:15100]
## above had length 15100, need 15092
GOtermvecexpand15092 <- GOtermvecexpand[1:15092]
length(GOtermvecexpand15092)
head(GOtermvecexpand15092, n=3)
tail(GOtermvecexpand15092, n=3)
## looks ok.

## colm 14, GOtermvecexpand, one GOterm per line, not yet split.
##  for example, a row:  [1] "GO:0005524^molecular_function^ATP binding"                              

#write.table(GOtermvecexpand, "GOtermvecexpand95T_up.txt", row.names=FALSE, col.names=FALSE)
write.table(GOtermvecexpand15092, file="GOtermvecexpand95T_up15092.txt", row.names=FALSE, col.names=FALSE)
save.image(file="may20_16.RData")
q()
ls -al
wc GOtermvecexpand95T_up.txt
 15101  60166 998396 GOtermvecexpand95T_up.txt
## Q: why not 15092 lines ???????????????????????????????, cause defined vec as 15100
wc GOtermvecexpand95T_up15092.txt
 15092  45057 888674 GOtermvecexpand95T_up15092.txt
head -n 4 GOtermvecexpand95T_up15092.txt
tail -n 4 GOtermvecexpand95T_up15092.txt
ok, looks ready for 'sed', i.e., no colm, row names, but have quotes.

05/21/16:

## Now, for 'sed', modify line 5654

#sed 's/\^/`/' tempcolm14expandeddf.txt > tempcolm14newsymbol.txt
#less tempcolm14newsymbol.txt
# 1st '^' each row replaced by '`'
#head -n 3 tempcolm14newsymbol.txt

ssh -Y pterry@crane.unl.edu  ## line 4511
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo
cd 95TUPsubset/
ls -al


#sed 's/\^/`/' test_sed040216.txt
"GO:0009507`cellular_component^chloroplast"
## try make 'global' for "^" changes to "`"
sed 's/\^/`/g' GOtermvecexpand95T_up15092.txt > testsed.txt
## or p-166, vbuffalo, perhaps use 'E' parameter ????????
wc testsed.txt
head -n 3 testsed.txt
head -n 3 GOtermvecexpand95T_up15092.txt
## so looks like have globally replaced "^" by "`".
mv testsed.txt GOtermvec95T_up15092.txt

## Next, read in GOtermvec95T_up15092.txt to R session, so can 'strsplit' on '`'.

module load R/3.2  ## 3.2.5
R
# attempt analyze in R on crane ???????????
getwd()
load(file="may20_16.RData")
ls()

GOtermvec95T_up15092df <- read.delim("GOtermvec95T_up15092.txt", header=FALSE, 
rm(GOtermvec95T_up15092)
col.names=c("gene_ontology_blast"), stringsAsFactors=FALSE)
class (GOtermvec95T_up15092df)
colnames(GOtermvec95T_up15092df)
dim(GOtermvec95T_up15092df)
head(GOtermvec95T_up15092df, n=3)
## no quotes ?????

## to convert to char vec before for loop
GOtermvec95T_up15092 <- as.character(GOtermvec95T_up15092df$gene_ontology_blast)
class(GOtermvec95T_up15092)  ## [1] "character"
head(GOtermvec95T_up15092, n=3)
## quotes

save.image(file="may21_16.RData")

colm14GOterm_numexpandvec <- as.numeric(vector(length=15092))
class(colm14GOterm_numexpandvec)
length(colm14GOterm_numexpandvec)
colm14GOterm_descexpandvec <- as.character(vector(length=15092))
class(colm14GOterm_descexpandvec)  ## [1] "character"
colm14GOterm_descexpandvec  ## [1] "FALSE" "FALSE"
length(colm14GOterm_descexpandvec)


for (i in 1:15092) {
#  GO1colm14templist <- strsplit(GOtermvecexpand[i], "^")
  GO1colm14templist <- strsplit(GOtermvec95T_up15092[i], "`")
#print(GO1colm14templist)
## unlist to create temp vector
## three elts from GOtermvec95T_up15092, 1st GO:???????, 2nd, discard this, 3rd description portion of row
  GO3colm14tempvec <- unlist(GO1colm14templist)
#print(GO3colm14tempvec)
#stop("dummy error")
## place each in its own 15092 elt vec.
#######  colm14GOterm_expandvecctr <- colm14GOterm_expandvecctr + 1
  colm14GOterm_numexpandvec[i] <- GO3colm14tempvec[1]
  colm14GOterm_descexpandvec[i] <- GO3colm14tempvec[3]
#if (i > 2) {
#  stop("dummy error")
#}
}

#print(GO3colm14tempvec)

## look at new vecs ??????
colm14GOterm_numexpandvec[1:3]
colm14GOterm_numexpandvec[15090:15092]

colm14GOterm_descexpandvec[1:3]
colm14GOterm_descexpandvec[15090:15092]

save.image(file="may21_16.RData")
q()

##*****************************************************************
# ok, finally (i) create df with 3 colms (the 3 vecs, tx, GOnum, & GOdisc, (2) write to disk (see p-260, vbuffalo bk)
##******************************************************************
## refer line 5720
## colm2 tx's: tx_idexpandedcolm2vec[15090:15095]

05/22/16:

ssh -Y pterry@crane.unl.edu  ## line 4511
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo

## rename 95C_up vikas form file
#mv threecolmsexpandeddfvikasform.txt threecolm95Cupvikasform.txt

cd 95TUPsubset/
ls -al
module load R/3.2  ## 3.2.5
R
# attempt analyze in R on crane ???????????
getwd()
load(file="may21_16.RData")
ls()

## check that this is the expanded colm 2 tx IDs
tx_idexpandedcolm2vec[1:3]
tail(tx_idexpandedcolm2vec, n=3)
length(tx_idexpandedcolm2vec)
## colm 14 GOterm number
colm14GOterm_numexpandvec[1:3]
colm14GOterm_numexpandvec[15090:15092]
length(colm14GOterm_numexpandvec)
## colm 14 GOterm description
colm14GOterm_descexpandvec[1:3]
colm14GOterm_descexpandvec[15090:15092]
length(colm14GOterm_descexpandvec)

threecolm95Tupvikasform <- data.frame(tx_ids = tx_idexpandedcolm2vec, GOnums = colm14GOterm_numexpandvec, GOdisc = colm14GOterm_descexpandvec)
dim(threecolm95Tupvikasform)
colnames(threecolm95Tupvikasform)
head(threecolm95Tupvikasform, n=3)
tail(threecolm95Tupvikasform, n=3)

write.table(threecolm95Tupvikasform, file = "threecolm95Tupvikasform.txt", quote=FALSE, sep="\t", row.names=FALSE, col.names=FALSE)
save.image(file="may22_16.RData")

##******************************************************************
## after build & write df (3 colm 'vitas', blast2GO form), want to check that random tx's ***related*** to GOterms in xlsT_up_logdfGO ???? as they are in this new df. threecolm95Tupvikasform.
##********************************************************************

class(xlsT_up_logdfGO)  ## [1] "data.frame"
head(rownames(xlsT_up_logdfGO), n=5)
[1] "122993" "42112"  "125191" "48421"  "86418" 
## what/where from ?????????????????

dim(xlsT_up_logdf)  ## [1] 3971   17
dim(xlsT_up_logdfGO)  ## [1] 2638   17
head(xlsT_up_logdfGO, n=2)
xlsT_up_logdfGO[1319, ]
xlsT_up_logdfGO[1319, 2]
xlsT_up_logdfGO[1319, 14]
## so take a random record number, say the middle one, 1319, compare to threecolm95Tupvikasform for this tx ID and assoc'd GOterms.

load(file="may22_16.RData")
ls()


testtx_ID  <- threecolm95Tupvikasform[threecolm95Tupvikasform$tx_ids=="TRINITY_DN47208_c0_g1_i2", ]
class(testtx_ID)  ## [1] "data.frame"
dim(testtx_ID)
testtx_ID
                       tx_ids     GOnums
7437 TRINITY_DN47208_c0_g1_i2 GO:0009507
7438 TRINITY_DN47208_c0_g1_i2 GO:0005739
7439 TRINITY_DN47208_c0_g1_i2 GO:0005524
7440 TRINITY_DN47208_c0_g1_i2 GO:0009793
                                         GOdisc
7437                                chloroplast
7438                              mitochondrion
7439                                ATP binding
7440 embryo development ending in seed dormancy
## matching 
xlsT_up_logdfGO[1319, ]
xlsT_up_logdfGO[1319, 2]
xlsT_up_logdfGO[1319, 14]
## Conclusion, threecolm95Tupvikasform correctly matching up tx_IDs & GOtern 'descriptions from xlsT_up_logdfGO, the 95T_up regualted transcripts.

save.image(file="may22_16.RData")
q()

## also, ***check outside*** R, threecolm95Tupvikasform.txt
wc threecolm95Tupvikasform.txt
 15092  75241 947897 threecolm95Tupvikasform.txt
head -n 3 threecolm95Tupvikasform.txt
TRINITY_DN42864_c1_g1_i1	GO:0005524	ATP binding

tail -n 3 threecolm95Tupvikasform.txt
## So format looks fine for next step, 'blast2GO'.

05/23/16:
# slipped a save/push to ***github*** in here, then a pull down, before resume.


##****************************************************************
05/25/16:

## Now, prepare '.xls' file for 3 colm tall blast2GO form (vikas).
## ref: see lines 5790 to 6278 above.

## 9 steps to accomplish
## ref: start at line 5790

ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo/95TUPsubset
## remove 'extra'.RData files from 95TUPsubset/
ls -al
rm may17_16.RData
rm may18_16.RData
rm may19_16.RData
rm may20_16.RData
rm may21_16.RData

## create new dir, 'threecolmvikas_xls'
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo
mkdir threecolmvikas_xls
cd threecolmvikas_xls

## start new '.RData' session when save image for this '.xls' processing.

module load R/3.2  ## 3.2.5
R
# attempt analyze in R on crane ???????????
getwd()
#load(file="may21_16.RData")
#ls()
setwd("/work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo/95TUPsubset/")
## line 5823

## STEP 1
xlsdf <- read.delim("trinotate_annotation_report.xls", header=TRUE)
setwd("/work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo/threecolmvikas_xls")
ls()
## line 5891
## STEP 2
xlsdfGO <-  xlsdf[grep("^GO:", xlsdf$gene_ontology_blast, perl=TRUE), ]

dim(xlsdfGO)  ## [1] 58004    17
dim(xlsdf)  ## [1] 178727     17
58004/178727  ## [1] 0.3245397
## so, approx 1/3 of '.xls' rows have GOterms.
## What to think ????????????????????????????????????????????????

## STEP 3
write.table(xlsdfGO, file="xlsdfGO.txt", sep="\t", col.names=TRUE)
## now have subset of xlsdf which 'have' Go terms in colm 14

save.image(file="may25_16.RData")
q()
ls -al
wc xlsdfGO.txt  ##    58005  4073784 65583581 xlsdfGO.txt
wc ../95TUPsubset/trinotate_annotation_report.xls
  178728  6371013 78676610 ../95TUPsubset/trinotate_annotation_report.xls

## ref line 5910, before do following steps, , do prev steps as need some info from there.

05/26/16:

ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo/threecolmvikas_xls
ls -al
module load R/3.2  ## 3.2.5
R
# attempt analyze in R on crane ???????????
getwd()
load(file="may25_16.RData")
ls()

tmpcolm14charvec <- xlsdfGO[ , c("gene_ontology_blast")]
class(tmpcolm14charvec)  ## [1] "factor"
length(tmpcolm14charvec)  ## [1] 58004
head(tmpcolm14charvec, n=2)  ## no quotes
## **if** not quotes around field,
tmpcolm14charvec <- as.character(tmpcolm14charvec)
class(tmpcolm14charvec)  ## [1] "character"
#length(tmpcolm14charvec)
head(tmpcolm14charvec, n=2)  ## now quotes

## STEP 4


##****************************************************************
## ACTUALLY BUILDING GOtermvecexpand (long-form GOterms, colm14) AND txcolm2expandvec (needed to count number times repeat tx_IDs when build expanded colm2 tx_IDs) WI NESTED 'FOR' LOOPS.
********************************************************************
GOtermvecexpand <- vector(mode="character", length=324107)
mode(GOtermvecexpand)
GOtermvecexpandctr <- 0
##mode(GOtermvecexpandctr)
## NEED VECTOR TO HOLD COUNT OF NUMBER of tx_IDs need from colm2 ?????????
txcolm2expandvec <- numeric(length=58004)  ## expect ~58000 for '.xls' file
txcolm2expandvec[1]
length(txcolm2expandvec)

## ref: line 5921 above
for (j in 1:58004) {  ## outer 'for loop', loop thru '.xls' file colm14 GOterms 
## access/copy a GOterms row, splits on '`'
GO1txtemplist <- strsplit(tmpcolm14charvec[j], "`")
## unlist to create temp vector
GO1txtempvec <- unlist(GO1txtemplist)
#print(GO1txtempvec)
## add one tx row (of 58004 rows) of GOterms to expanded list for all tx's/GOterm lines for trinotate_annotation_report.xls in internal for loop.

## later in here, check that won't exceed declared length of GOtermvecexpand vec before add additional GOterm character elts to it ??????

  for (i in 1:length(GO1txtempvec)) {
    GOtermvecexpand[GOtermvecexpandctr + i] <- GO1txtempvec[i]
  }
#if(j > 50000) {
#stop("dummy error")
#}
## need ctr so know where to add to GOtermvecexpand vec
GOtermvecexpandctr <- GOtermvecexpandctr + length(GO1txtempvec)
#print(GOtermvecexpandctr)
txcolm2expandvec[j] <- length(GO1txtempvec)
##stop("dummy error")
}

print(GOtermvecexpandctr)  ## [1] 324107
#print(GOtermvecexpand[15090:15100])
print(GOtermvecexpand[324105:324107])
#txcolm2expandvec[5390:5400]
txcolm2expandvec[58000:58004]

sum(txcolm2expandvec)
[1] 324107

save.image(file="may25_16.RData")

## to compare, last GOterm in tmpcolm14charvec wi last in GOtermvecexpand
tail(tmpcolm14charvec, n=2)  ## matches last of GOtermvecexpand
## GO:0042744^biological_process^hydrogen peroxide catabolic process"               
## matches
## last GO term in colm 14 is ***same*** as last one in GOtermvecexpand vector.
tail(txcolm2expandvec, n=4)  ## [1] 10  6  6  5
## Looks ok.

## ref: line 5960
##****************************************************************
## so have the ***324107 GOterms in 'long' form in 'GOtermvecexpand'. GOterms for 58004*** tx IDs in 'GOtermvecexpand', and the number of each tx lines for expanded colm 2 in 'txcolm2expandvec'.
##**************************************************************

q()

ref: line 5965
## Next, build expanded colm2 (tx_IDs) from txcolm2expandvec using the 58004 values in this vector and tmpcolm2charvec, the colm 2 values.

ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo/threecolmvikas_xls
ls -al
module load R/3.2  ## 3.2.5
R
# attempt analyze in R on crane ???????????
getwd()
load(file="may25_16.RData")
ls()


tmpcolm2charvec <- as.character(xlsdfGO$transcript_id)
class(tmpcolm2charvec)  ## [1] "character"
length(tmpcolm2charvec)  ## [1] 58004
head(tmpcolm2charvec, n=3)
[1] "TRINITY_DN42864_c1_g1_i1" "TRINITY_DN47196_c1_g1_i1"
tail(tmpcolm2charvec, n=3)
[3] "TRINITY_DN237_c0_g1_i1"   

colnames(xlsdfGO)
head(xlsdfGO, n=2)
tail(xlsdfGO, n=1)
## ok, 1st, last tx ID in tmpcolm2charvec vector ok.

save.image(file="may25_16.RData")
#q()
 
 
## Use txcolm2expandvec (number each tx_id needed to match up with expanded list of GOterms) & tmpcolm2charvec (the 58004 tx_id's need to 'expand').

length(txcolm2expandvec)  ## [1] 58004
head(txcolm2expandvec, n=5)  ## [1] 5 5 2 5 5

## create new vector with 324107 elements, use txcolm2expandvec vector to allocate appropriate number each tx_id from tmpcolm2charvec to a new vector.

tx_idexpandedcolm2vec <- vector(mode="character", length=324107)
class(tx_idexpandedcolm2vec)  ## [1] "character"
tx_idexpandedcolm2vec[1:2]
tx_idexpandedcolm2vecctr <- 0


for (k in 1:58004) {  ## k stepping thru tx_idexpandedcolm2vec elements
  indiv_tx_num_temp <- txcolm2expandvec[k]
  for (l in 1:indiv_tx_num_temp) {
    tx_idexpandedcolm2vecctr <- tx_idexpandedcolm2vecctr + 1
    tx_idexpandedcolm2vec[tx_idexpandedcolm2vecctr] <- tmpcolm2charvec[k]
  }
#if (k > 50000) {
#  stop("dummy error")
#}
}
tx_idexpandedcolm2vecctr  ## [1] 324107
tx_idexpandedcolm2vec[324105:324107]
## looks like last tx_ID matches last in (xlsdfGO, n=1) and tmpcolm2charvec
[1] "TRINITY_DN38713_c0_g2_i1" "TRINITY_DN38713_c0_g2_i1"
[3] "TRINITY_DN38713_c0_g2_i1"

## ref: 6032
##**************************************************************
## looks ok, have vec 324107 tx elts (from colm 2, tx_idexpandedcolm2vec) (presumably) matching expanded (long form) GOterms from colm 14 for trinotate_annotation_report.xls in 'GOtermvecexpand'.
Perhaps DOUBLECHECK ?????????????????????????????
##****************************************************************
save.image(file="may25_16.RData")
q()

## ref: line 6042
## ok, looks like have expanded colm 2, and colm 14 expanded, one GO:term per line. So each vector 324107 elements long. Perhaps DOUBLECHECK ?????????????????????????????

05/27/16:
## ref: line 6048
##******************************************************************
## now, try split GO: part of GO:term off from description part of GO:term. 1st, try with 'sed' outside of R to change "^" to "`" globally (so strsplit can handle). 
##********************************************************************


ssh -Y pterry@crane.unl.edu  
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo/threecolmvikas_xls
ls -al
module load R/3.2  ## 3.2.5
R
# attempt analyze in R on crane ???????????
getwd()
load(file="may25_16.RData")
ls()
class(GOtermvecexpand)  ## [1] "character"
GOtermvecexpand[324105:324107]
length(GOtermvecexpand)  ## [1] 324107
head(GOtermvecexpand, n=3)
tail(GOtermvecexpand, n=3)
## looks ok.

## colm 14, GOtermvecexpand, one GOterm per line, not yet split.
##  for example, a row:  [1] "GO:0005634^cellular_component^nucleus"                               
                              
#write.table(GOtermvecexpand, "GOtermvecexpand95T_up.txt", row.names=FALSE, col.names=FALSE)
write.table(GOtermvecexpand, file="GOtermvecexpand_xls.txt", row.names=FALSE, col.names=FALSE)
save.image(file="may25_16.RData")
q()
ls -al
wc GOtermvecexpand_xls.txt
  324107   943659 18864818 GOtermvecexpand_xls.txt
head -n 4 GOtermvecexpand_xls.txt
tail -n 4 GOtermvecexpand_xls.txt
ok, looks ready for 'sed', i.e., no colm, row names, but have quotes.

## Now, for 'sed', modify line 5654

## try make 'global' for "^" changes to "`"
sed 's/\^/`/g' GOtermvecexpand_xls.txt > GOtermvecexpand_xls_sed.txt
## or p-166, vbuffalo, perhaps use 'E' parameter ????????
wc GOtermvecexpand_xls_sed.txt
head -n 3 GOtermvecexpand_xls_sed.txt
## so looks like have globally replaced "^" by "`".

## Next, read in GOtermvec95T_up15092.txt to R session, so can 'strsplit' on '`'.

module load R/3.2  ## 3.2.5
R
# attempt analyze in R on crane ???????????
getwd()
load(file="may25_16.RData")
ls()

GOtermvec_xls_seddf <- read.delim("GOtermvecexpand_xls_sed.txt", header=FALSE, col.names=c("gene_ontology_blast"), stringsAsFactors=FALSE)
class (GOtermvec_xls_seddf)
colnames(GOtermvec_xls_seddf)
dim(GOtermvec_xls_seddf)  ## [1] 324107      1
head(GOtermvec_xls_seddf, n=3)
## no quotes ?????

## to convert to char vec before for loop
GOtermvec_xls_sed <- as.character(GOtermvec_xls_seddf$gene_ontology_blast)
class(GOtermvec_xls_sed)  ## [1] "character"
head(GOtermvec_xls_sed, n=3)
## have quotes

save.image(file="may25_16.RData")

#colm14GOterm_numexpandvec <- as.numeric(vector(length=324107))

colm14GOterm_numexpandvec <- as.character(vector(length=324107))

#class(colm14GOterm_numexpandvec)  ## [1] "character"
#length(colm14GOterm_numexpandvec)  ## [1] 324107

colm14GOterm_descexpandvec <- as.character(vector(length=324107))

#class(colm14GOterm_descexpandvec)  ## [1] "character"
#head(colm14GOterm_descexpandvec, n=2)  ## [1] "FALSE" "FALSE"
#length(colm14GOterm_descexpandvec)  ## [1] 324107


for (i in 1:324107) {
  GO1colm14templist <- strsplit(GOtermvec_xls_sed[i], "`")
#print(GO1colm14templist)
## unlist to create temp vector
## three elts from GOtermvec95T_up15092, 1st GO:???????, 2nd, discard this, 3rd description portion of row
  GO3colm14tempvec <- unlist(GO1colm14templist)
#print(GO3colm14tempvec)
#stop("dummy error")
## place each in its own 324107 elt vec.
#######  colm14GOterm_expandvecctr <- colm14GOterm_expandvecctr + 1
  colm14GOterm_numexpandvec[i] <- GO3colm14tempvec[1]
  colm14GOterm_descexpandvec[i] <- GO3colm14tempvec[3]
#if (i > 500) {
#  stop("dummy error")
#}
}

#print(GO3colm14tempvec)

## look at new vecs ??????
colm14GOterm_numexpandvec[1:4]
colm14GOterm_numexpandvec[324105:324107]
[1] "GO:0016688" "GO:0046872" "GO:0042744"

colm14GOterm_descexpandvec[1:4]
colm14GOterm_descexpandvec[324105:324107]

save.image(file="may25_16.RData")
q()

## Ref: line 6181
##*****************************************************************
# ok, finally (i) create df with 3 colms (the 3 vecs, tx, GOnum, & GOdisc, (2) write to disk (see p-260, vbuffalo bk)
##******************************************************************

ssh -Y pterry@crane.unl.edu 
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo/threecolmvikas_xls
ls -al
module load R/3.2  ## 3.2.5
R
# attempt analyze in R on crane ???????????
getwd()
load(file="may25_16.RData")
ls()

## check that this is the expanded colm 2 tx IDs
tx_idexpandedcolm2vec[1:3]
tail(tx_idexpandedcolm2vec, n=3)
length(tx_idexpandedcolm2vec)  ## [1] 324107
## colm 14 GOterm number
colm14GOterm_numexpandvec[1:3]
colm14GOterm_numexpandvec[324105:324107]
length(colm14GOterm_numexpandvec)  ## [1] 324107
## colm 14 GOterm description
colm14GOterm_descexpandvec[1:3]
colm14GOterm_descexpandvec[324105:324107]
length(colm14GOterm_descexpandvec)  ## [1] 324107

threecolmxlsvikasform <- data.frame(tx_ids = tx_idexpandedcolm2vec, GOnums = colm14GOterm_numexpandvec, GOdisc = colm14GOterm_descexpandvec)
dim(threecolmxlsvikasform)  ## [1] 324107      3
colnames(threecolmxlsvikasform)
head(threecolmxlsvikasform, n=3)
tail(threecolmxlsvikasform, n=3)

write.table(threecolmxlsvikasform, file = "threecolmxlsvikasform.txt", quote=FALSE, sep="\t", row.names=FALSE, col.names=FALSE)
save.image(file="may25_16.RData")

##******************************************************************
## after build & write df (3 colm 'vitas', blast2GO form), want to check that random tx's ***related*** to GOterms in xlsdfGO ???? as they are in this new df. threecolmxlsvikasform.
##********************************************************************

class(xlsdfGO)  ## [1] "data.frame"
#head(rownames(xlsdfGO), n=5)
[1] "122993" "42112"  "125191" "48421"  "86418" 
## what/where from ?????????????????

dim(xlsdf)  ## [1] 178727     17
dim(xlsdfGO)  ## [1] 58004    17
head(xlsdfGO, n=2)
xlsdfGO[29002, ]  ## random row selected
xlsdfGO[29002, 2]  ## [1] TRINITY_DN42079_c0_g1_i2
xlsdfGO[29002, 14]
[1] GO:0016021^cellular_component^integral component of membrane`GO:0009705^cellular_component^plant-type vacuole membrane`GO:0005215^molecular_function^transporter activity`GO:0006857^biological_process^oligopeptide transport
## so take a random record number, say the middle one, 29002, compare to threecolmxlsvikasform for this tx ID and assoc'd GOterms.


testtx_ID  <- threecolmxlsvikasform[threecolmxlsvikasform$tx_ids=="TRINITY_DN42079_c0_g1_i2", ]
class(testtx_ID)  ## [1] "data.frame"
dim(testtx_ID)  ## [1] 8 3
testtx_ID
                         tx_ids     GOnums                         GOdisc
161898 TRINITY_DN42079_c0_g1_i2 GO:0016021 integral component of membrane
161899 TRINITY_DN42079_c0_g1_i2 GO:0009705    plant-type vacuole membrane
161900 TRINITY_DN42079_c0_g1_i2 GO:0005215           transporter activity
161901 TRINITY_DN42079_c0_g1_i2 GO:0006857         oligopeptide transport
161902 TRINITY_DN42079_c0_g1_i2 GO:0016021 integral component of membrane
161903 TRINITY_DN42079_c0_g1_i2 GO:0005886                plasma membrane
161904 TRINITY_DN42079_c0_g1_i2 GO:0005215           transporter activity
161905 TRINITY_DN42079_c0_g1_i2 GO:0006857         oligopeptide transport

## perhaps more than row 29002 in xlsdfGO has this tx ID ?????????????

## matching 
#xlsdfGO[1319, ]
xlsdfGO[29002, 2]  ##  [1] TRINITY_DN42079_c0_g1_i2

xlsdfGO[29002, 14]
[1] GO:0016021^cellular_component^integral component of membrane`GO:0009705^cellular_component^plant-type vacuole membrane`GO:0005215^molecular_function^transporter activity`GO:0006857^biological_process^oligopeptide transport

## Conclusion: perhaps more than row 29002 in xlsdfGO has this tx ID since this tx ID present 4 additional times in threecolmxlsvikasform  ?????????????

## check for more than 1 row with this tx ID.
xlsdfGO[xlsdfGO$transcript_id=="TRINITY_DN42079_c0_g1_i2", ]

                  X.gene_id            transcript_id
89855 TRINITY_DN42079_c0_g1 TRINITY_DN42079_c0_g1_i2
89856 TRINITY_DN42079_c0_g1 TRINITY_DN42079_c0_g1_i2
                                                 gene_ontology_blast
89855 GO:0016021^cellular_component^integral component of membrane`GO:0009705^cellular_component^plant-type vacuole membrane`GO:0005215^molecular_function^transporter activity`GO:0006857^biological_process^oligopeptide transport

89856             GO:0016021^cellular_component^integral component of membrane`GO:0005886^cellular_component^plasma membrane`GO:0005215^molecular_function^transporter activity`GO:0006857^biological_process^oligopeptide transport

## Yes, 2 rows in xlsdfGO with TRINITY_DN42079_c0_g1_i2 tx_ID, so relationship tx_IDs & explained.

save.image(file="may25_16.RData")
q()

## also, ***check outside*** R, threecolmxlsvikasform.txt
wc threecolmxlsvikasform.txt
  324107  1591873 20162525 threecolmxlsvikasform.txt
head -n 3 threecolmxlsvikasform.txt
TRINITY_DN10643_c0_g1_i1	GO:0005634	nucleus
TRINITY_DN10643_c0_g1_i1	GO:0071472	cellular response to salt stress
TRINITY_DN10643_c0_g1_i1	GO:0042631	cellular response to water deprivation

tail -n 3 threecolmxlsvikasform.txt
TRINITY_DN38713_c0_g2_i1	GO:0016688	L-ascorbate peroxidase activity
TRINITY_DN38713_c0_g2_i1	GO:0046872	metal ion binding
TRINITY_DN38713_c0_g2_i1	GO:0042744	hydrogen peroxide catabolic process

## So format looks fine for next step, 'blast2GO'.

05/29/16:
TO DO: github
# slipped a save/push to ***github*** in here, then a pull down, before resume.
## so github up to date.

## 1st, dnloaded, installed JavaForOSX.pkg.

STOPPED

05/31/16:

## Next, initially, dnload Blast2GO_macros_3_3.dmg to ****'macbook'**** (2 lbs laptop). Use **basic** 'key' for testing Blast2GO.
## NOTE: tx_IDs IN '.xls' FILE **NOT** UNIQUE ????????????????????
## **WHAT TO THINK** ??????????????????????


06/01/16:
## ***WORKING ON 'MACBOOK'***

## 1st, need scp '3-colm' files from crane to 'macbook' laptop

cd /Users/bterry/macbook2016/keenanres16/Bdac

scp pterry@crane.unl.edu:/work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo/threecolmvikas_xls/threecolmxlsvikasform.txt .

scp pterry@crane.unl.edu:/work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo/95TUPsubset/threecolm95Tupvikasform.txt .

## need colm1, uniq from threecolm95Tupvikasform.txt
## cut, sort, uniq
wc threecolm95Tupvikasform.txt
   15092   75241  947897 threecolm95Tupvikasform.txt
head -n 3 threecolm95Tupvikasform.txt
cut -f1 threecolm95Tupvikasform.txt | sort -u > colm1_95Tupvikasform_uniq.txt
ls -al
wc colm1_95Tupvikasform_uniq.txt
    2638    2638   65765 colm1_95Tupvikasform_uniq.txt
head -n 3 colm1_95Tupvikasform_uniq.txt

## from meeting wi vikas this day:
cp threecolmxlsvikasform.txt threecolmxlsvikasform.annot
cp colm1_95Tupvikasform_uniq.txt colm1_95Tupvikasform_uniq.annot

## start/load annotations, ref file, for me, the '.xls' 3 colm file (threecolmxlsvikasform.annot)
## then, colm 1, from say 3 colm for 95T_up, but run 'cut/sort/uniq' before use (colm1_95Tupvikasform_uniq.annot).
## then, 'analysis,Enrichment analysis (fishwe's exact test), 'two-sided', 'run'
## Q: should I have done 2-sided, since DE was onlt 'up' ???????????????????
## start 4:32pm => 1:20pm, next day => 20:48 hrs to run on 'macbook'.

06/02/16:
## save blast2GO result:
blast2go_fisher_20160602_2212.txt

## Make Enriched Graph, Q: how to make use of it ?????????????????
## Bar Chart, Q: looks like too much data, what to do ????????????????
## pdf only avail. in 'PRO'version ????
## tried 'reduce to most specific', down from 8693 pages to 366

## Q: HOW TO PROCEED, WHAT TO THINK ??????????????????
## user manual, p-33, fig 35 ??????????????????????

06/06-07/16:
## talked wi vikas
## Q: B. dac genome size ????????
## TRY google questions for blast2go
## in blast2go_fisher_20160602_2212.txt, wants to filter for 'OVER' from colm 10, 'Over/Under', use 'awk' ????????? or R ?????????
## then filter 'FDR', < 0.05
## then, 'new' ref file, 3 colms, 1st 1,2,3,..., 2nd 'GO_ID' from filtered output, 3rd 'fdr', colm 4 (Q: TestSeqs, RefSeqs colms ?????????????????
## next step unclear, ????????, perhaps use a item from one the drop down menus 'annot', 'charts', or 'graphs'. Problem: my basic version not even showing the 'choices' ??????????????????????????????????????

cd /Users/bterry/macbook2016/keenanres16/Bdac 
wc blast2go_fisher_20160602_2212.txt
     753 1489910 38555079 blast2go_fisher_20160602_2212.txt
R
getwd()
Bl2GO_95T_xls <- read.delim("blast2go_fisher_20160602_2212.txt", stringsAsFactors=FALSE)
dim(Bl2GO_95T_xls)  ## [1] 752  12, agrees wi 'wc'

class(Bl2GO_95T_xls)
head(Bl2GO_95T_xls, n=1)  ## TOO MANY TO DISPLAY ??????????????????
colnames(Bl2GO_95T_xls)
save.image(file="june07_16.RData")
load(file="june07_16.RData")
ls()

#c10 <- "Over/Under"
Bl2GO_95T_xls_OVER <- Bl2GO_95T_xls[grep("OVER", Bl2GO_95T_xls$Over.Under, perl=TRUE), ]
dim(Bl2GO_95T_xls_OVER)  ## [1]  0 12, NO ROWS ??????????????????????
c10 <- Bl2GO_95T_xls_OVER[[10]]
class(c10)
length(c10)  ## [1] 0, so 'grep' may not be working ????????????
orig_c10 <- Bl2GO_95T_xls$Over.Under
length(orig_c10)  ## [1] 752
orig_c10[1:3]
colnames(Bl2GO_95T_xls)
c1 <- Bl2GO_95T_xls$GO.ID
class(c1)
length(c1)
c1[1]
head(rownames(Bl2GO_95T_xls), n=3)
[1] "GO:1901566" "GO:1901564" "GO:0005737"
## Q: GO_ID is 1st colm name, but also 'colm1' ???????????????
c1_3 <- Bl2GO_95T_xls[ 1, 1:3]
c1_3
c1 <- Bl2GO_95T_xls[ 1, 1]
c1
c2 <- Bl2GO_95T_xls[ 1, 2]
c2
c3 <- Bl2GO_95T_xls[ 1, 3]
c3
## working like 'GO_ID' not 1st colm, ***THO*** listed 1st For
colnames(Bl2GO_95T_xls)
c9 <- Bl2GO_95T_xls[ 1, 9]
c9
[1] "OVER"

#Bl2GO_95T_xls_OVER <- Bl2GO_95T_xls[grep("OVER", Bl2GO_95T_xls${c10}, perl=TRUE), ]
Bl2GO_95T_xls_OVER <- Bl2GO_95T_xls[grep("OVER", Bl2GO_95T_xls[[9]], perl=TRUE), ]

dim(Bl2GO_95T_xls_OVER)  ## [1] 632  12

class(Bl2GO_95T_xls_OVER)
## next, filter for FDR < 0.05
## note: p-200, vbuffalo bk, stringsAsFactors=FALSE for data.frame creation.
## p-202, drop=FALSE.
Bl2GO_95T_xls_OVER_05 <- Bl2GO_95T_xls_OVER[Bl2GO_95T_xls_OVER[[3]] < 0.05, ]
dim(Bl2GO_95T_xls_OVER_05)  ## [1] 632  12

class(Bl2GO_95T_xls_OVER_05)
## write to Disk

#write.table(threecolmxlsvikasform, file = "threecolmxlsvikasform.txt", quote=FALSE, sep="\t", row.names=FALSE, col.names=FALSE)

write.table(Bl2GO_95T_xls_OVER_05, file = "Bl2GO_95T_xls_OVER_05.txt", quote=FALSE, sep="\t")
save.image(file="june07_16.RData")

R
getwd()
load(file="june07_16.RData")
ls()

head(rownames(Bl2GO_95T_xls_OVER_05), n=3)
testrownamesdf <- Bl2GO_95T_xls_OVER_05
head(rownames(testrownamesdf), n=3)
dim(Bl2GO_95T_xls_OVER_05)  ## [1] 632  12
testrownamesdf[ 1, 1:9]

rownames(testrownamesdf) <- NULL
testrownamesdf[ 1:2, 1:9]  ## each row now has an integer 1st, 
colnames(testrownamesdf)  ## has "GO_ID" still 1st, ?????????????????
head(rownames(testrownamesdf), n=3)  ## [1] "1" "2" "3", perhaps what want ??

## now new 3 colm df
FDRcolm <- Bl2GO_95T_xls_OVER_05[[3]]
class(FDRcolm)  ## [1] "numeric"
length(FDRcolm)  ## [1] 632
head(FDRcolm, n=3)  ## matches Bl2GO_95T_xls_OVER_05.txt
GO_ID <- rownames(Bl2GO_95T_xls_OVER_05)
class(GO_ID)  ## [1] "character"
length(GO_ID)  ## [1] 632
head(GO_ID, n=3)  ## matches 1st colm for Bl2GO_95T_xls_OVER_05.txt
intvec <- 1:632
class(intvec)
head(intvec, n=3)
tail(intvec, n=3)
## ok, now create df
Bl2GO_95T_xls_OVER_05_3col <- data.frame(intvec = intvec, GO.ID = GO_ID, FDR = FDRcolm, stringsAsFactors=FALSE)
class(Bl2GO_95T_xls_OVER_05_3col)
dim(Bl2GO_95T_xls_OVER_05_3col)  ## [1] 632   3
head(Bl2GO_95T_xls_OVER_05_3col, n=3)
tail(Bl2GO_95T_xls_OVER_05_3col, n=3)

now ## write to disk
#write.table(threecolmxlsvikasform, file = "threecolmxlsvikasform.txt", quote=FALSE, sep="\t", row.names=FALSE, col.names=FALSE)
write.table(Bl2GO_95T_xls_OVER_05_3col, file = "Bl2GO_95T_xls_OVER_05_3col.txt", quote=FALSE, sep="\t", row.names=FALSE)
save.image(file="june07_16.RData")
q()
wc Bl2GO_95T_xls_OVER_05_3col.txt
     633    1899   16983 Bl2GO_95T_xls_OVER_05_3col.txt


STOPPED
06/08-9/16:

## for 1 thing, cp this file to gethub, then pull down on 'pro' laptop. 
## Both done.
## Then what ????????????????????????????
## remake Bl2GO_95T_xls_OVER_05_3col.txt, this time with 'Term' colm taken from Bl2GO_95T_xls_OVER_05.txt
## this recreation of file step still on ***'macbook'***

cd macbook2016/keenanres16/Bdac
R
getwd()
load(file="june07_16.RData")
ls()
#FDRcolm <- Bl2GO_95T_xls_OVER_05[[3]]
Termcolm <- Bl2GO_95T_xls_OVER_05[[1]]
class(Termcolm)
length(Termcolm)
head(Termcolm, n=3)
tail(Termcolm, n=3)
# paste for colm 1
colm1 <- paste("95T", c(1:632), sep="")
class(colm1)
length(colm1)
head(colm1, n=3)
tail(colm1, n=3)
# now df
Bl2GO_95T_xls_OVER_05_3col <- data.frame(cnt95T = colm1, GO.ID = GO_ID, Term = Termcolm, stringsAsFactors=FALSE)
class(Bl2GO_95T_xls_OVER_05_3col)
dim(Bl2GO_95T_xls_OVER_05_3col)
head(Bl2GO_95T_xls_OVER_05_3col, n=3)
tail(Bl2GO_95T_xls_OVER_05_3col, n=3)
# write to disk
write.table(Bl2GO_95T_xls_OVER_05_3col, file = "Bl2GO_95T_xls_OVER_05_3col.txt", quote=FALSE, sep="\t", row.names=FALSE, col.names=FALSE)
save.image(file="june07_16.RData")
q()
wc Bl2GO_95T_xls_OVER_05_3col.txt
     632    3605   33209 Bl2GO_95T_xls_OVER_05_3col.txt
head -n 3 Bl2GO_95T_xls_OVER_05_3col.txt
95T1    GO:1901566    organonitrogen compound biosynthetic process
cp Bl2GO_95T_xls_OVER_05_3col.txt Bl2GO_95T_xls_OVER_05_3col.annot
## transfer to 'pro' laptop to use input for blast2GO annoation (1st rename 3 col file there with 'FDR' in 3rd colm. Done)

## back to ***macbook pro***

## create a dir to locate Bl2GO_95T_xls_OVER_05_3col.txt on pro laptop, name:

/Users/bterry/macbookpro2015/keenanres15/trintoGSEA/B2GOactivity

## open blast2GO on pro laptop, activate 'pro' key there (done, 11:30am, 06/08/16), 
## Now, cp Bl2GO_95T_xls_OVER_05_3col.annot (email) to 'pro' laptop, also did Bl2GO_95T_xls_OVER_05.txt (thumbdrive), the copy with all the colmns.
## file Bl2GO_95T_xls_OVER_05_3col.annot looks ok.

start blast2GO there with 'pro' key (B2G-TERRPHIL-507D9DF50B485A74E18F0969A48638BB).

STOPPED

## ***To do***: doc annotation run from pencil sheet
## looks like level2 will be one take text file data for histogram to compare 95T, 95C DE tx's

## ***meanwhile*** run fisher exact test for 95C on 'pro' laptop, pro blast2GO key.

## ***WORKING ON 'MACBOOK PRO'***

## 1st, need scp '3-colm' files from crane to 'macbook pro' laptop

#cd /Users/bterry/macbook2016/keenanres16/Bdac
cd /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/B2GOactivity/95C

scp pterry@crane.unl.edu:/work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo/threecolmvikas_xls/threecolmxlsvikasform.txt .
wc threecolmxlsvikasform.txt
  324107 1591873 20162525 threecolmxlsvikasform.txt
head -n 1 threecolmxlsvikasform.txt  

ssh -Y pterry@crane.unl.edu  ## line 4511
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo

scp pterry@crane.unl.edu:/work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo/threecolm95Cupvikasform.txt .
wc threecolm95Cupvikasform.txt
    5769   28098  358714 threecolm95Cupvikasform.txt
head -n 1 threecolm95Cupvikasform.txt
## need colm1, uniq from threecolm95Tupvikasform.txt
## cut, sort, uniq
cut -f1 threecolm95Cupvikasform.txt | sort -u > colm1_95Cupvikasform_uniq.txt
ls -al
wc colm1_95Cupvikasform_uniq.txt
    1074    1074   26870 colm1_95Cupvikasform_uniq.txt
head -n 3 colm1_95Cupvikasform_uniq.txt

cp threecolmxlsvikasform.txt threecolmxlsvikasform.annot
cp colm1_95Cupvikasform_uniq.txt colm1_95Cupvikasform_uniq.annot

## start/load annotations, ref file, for me, the '.xls' 3 colm file (threecolmxlsvikasform.annot)



## Fisher exact test ran in 20 sec ????????????????????????? for 95C on pro laptop ????????????????????????????
## refer around line 6850 for proceeding on to the 'OVER' process, but not thinking, would have done 'OVER' & '0.05' before Fisher Exact Test ????



06/12/16:

## So, TO DO: get explanation for 'Fisher Exact Test' running for only '20 seconds' for 95C DE data ?????????????????????????????????
## WHY: can't get graph mode to 'take' output from 'Fisher Exact Test' for 95C DE data ????????????????????????????????????????
## TO DO: Look into using ggplot2 to plot the two output files from 95T & 95C 'Fisher Exact Test' as suggested by Vikas.

06/15-16/16:
## do some checking on blastoGO, try 95T with basic key on 'pro' laptop.
## remove 'pro' key from pro laptop blast2GO.
## pass colm1_95Tupvikasform_uniq.txt from macbook to pro laptop.
## so work in dir: /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/B2GOactivity/95Ttesting
wc colm1_95Tupvikasform_uniq.txt
    2638    2638   65765 colm1_95Tupvikasform_uniq.txt

head -n 3 colm1_95Tupvikasform_uniq.txt
TRINITY_DN10001_c0_g2_i1
TRINITY_DN10002_c0_g2_i1
wc threecolmxlsvikasform.annot
  324107 1591873 20162525 threecolmxlsvikasform.annot

head -n 2 threecolmxlsvikasform.annot
TRINITY_DN10643_c0_g1_i1	GO:0005634	nucleus
TRINITY_DN10643_c0_g1_i1	GO:0071472	cellular response to salt stress
## ok, to run on blast2GO, basic key on pro laptop
## start/load annotations  => **46** seconds
## analysis/enrichment analysis (fishers exact test)
## select test set => colm1_95Tupvikasform_uniq.txt
## Q: 'select reference (optional)' ??????????????????????????????????
## 0.05, FDR, two-sided

## 11:33pm => 12:19am, 6/17/16, so **24:44** hr:min to run.
## try display bar graph from FETest setting ????????????????
## enriched bar chart, ***too dense to read***
## TO DO: save as text
/Users/bterry/macbookpro2015/keenanres15/trintoGSEA/B2GOactivity/95Ttesting/blast2go_statistics_20160617_0917.txt

STOPPED

## IN HERE, some comments about QUESTIONS at this point.
##
##

06/17/16:

## Can this be used for charts/make statistics/ ????????????


## reading response to my 1st submission of questions to B2GO help, ***CLEAR*** I don't understand for sure how to run FETest. Q: 'Blast2GO project', 'reference set', 'annotated project' ????????????????????????????????????????????? 
## apparently 'reference set' is ***OPTIONAL*** ??????????????????????


## When redo of 95T done, try ***redo of 95C*** on pro laptop with 'basic' b2GO key.
## dir = /Users/bterry/macbookpro2015/keenanres15/trintoGSEA/B2GOactivity/95Crerun
wc colm1_95Cupvikasform_uniq.txt
    1074    1074   26870 colm1_95Cupvikasform_uniq.txt
head -n 3 colm1_95Cupvikasform_uniq.txt
TRINITY_DN10401_c0_g1_i1
TRINITY_DN12120_c0_g2_i1
wc threecolmxlsvikasform.annot
  324107 1591873 20162525 threecolmxlsvikasform.annot
head -n 2 threecolmxlsvikasform.annot
TRINITY_DN10643_c0_g1_i1	GO:0005634	nucleus
TRINITY_DN10643_c0_g1_i1	GO:0071472	cellular response to salt stress
## ok, to run on blast2GO, basic key on pro laptop
## start/load annotations  => 46 seconds
## analysis/enrichment analysis (fishers exact test)
## select test set => colm1_95Cupvikasform_uniq.txt
## Q: 'select reference (optional)' ??????????????????????????????????
## 0.05, FDR, two-sided
## 1:02pm => !!:59pm, Sun, 06/19/16, 2 days, 10 hrs. 48min, ***58:48*** hrs:min

STOPPED

06/20/16:
## To save appropriate txt files (in 95Crerun dir), 
i) after FETest, and 
-rw-r--r--   1 bterry  staff  19731770 Jun 20 00:10 blast2go_fisher_20160620_0009.txt
## appears to have a count for tx names for each GOnumber in '#Test' set ?????
wc blast2go_fisher_20160620_0009.txt
     231  760973 19731770 blast2go_fisher_20160620_0009.txt
head -n 2 blast2go_fisher_20160620_0009.txt
philip-terry:95Crerun bterry$ head -n 2 blast2go_fisher_20160620_0009.txt
GO-ID	Term	Category	FDR	P-Value	#Test	#Ref	#notAnnotTest	#notAnnotRef	Over/Under	TestSeqs	RefSeqs
GO:0009521	photosystem	C	3.466948E-60	2.48598E-64	67	122	1007	52578	OVER	TRINITY_DN31869_c1_g1_i2, TRINITY_DN31869_c1_g1_i1, 

## do I need the output from 'chart statistics' ???????

ii) after 'show bar chart', still not the 'chart statistics', apparently need 'pro key' ????????????????

## How do these differ ????????????????????

## Talked to Vikas, TO DO: ***from*** B2GO Fisher E. Test output (saved txt files), for 95T, 95C input, proceed as follows:

06/21/16:

i) get saved FE Test txt output files for 95T, 95C. Note, will try to run 'Charts/Make Statistics, apparently requires 'B2GO pro key'. So will **try** to run on **Macbook** with 2nd 'pro key' dnloaded.

## for 95T
## copy to 
## refer line 6785, 6806, 
## 1504 is 2x of wc of blast2go_fisher_20160602_2212.txt (753) Q: why diff ?????
## perhaps blank lines betw each real line (Q: why wc would not count these ???)
## now (looks like done prevly, redo, since also doing 95C), filter for 'Over/Under' (colm 9) => did, line 6851,
...

STOPPED

## for 95T
## copy from macbook 
/Users/bterry/macbook2016/keenanres16/Bdac/blast2go_fisher_20160602_2212.txt
## copy to 
/Users/bterry/macbook2016/keenanres16/Bdac/b2go_chtmakstat/95T_frommacbook/blast2go_fisher_20160602_2212.txt

## now filter 95T b2go fisher exact test saved txt output 1st for 'Over.Under' (note prevly done, but redo, make more concise).
## refer line 6804

cd /Users/bterry/macbook2016/keenanres16/Bdac/b2go_chtmakstat/95T_frommacbook
wc blast2go_fisher_20160602_2212.txt
     753 1489910 38555079 blast2go_fisher_20160602_2212.txt
R
getwd()
Bl2GO_95T_xls <- read.delim("blast2go_fisher_20160602_2212.txt", stringsAsFactors=FALSE)
dim(Bl2GO_95T_xls)  ## [1] 752  12, agrees wi 'wc'
class(Bl2GO_95T_xls)
colnames(Bl2GO_95T_xls)  ## counting rownames as a colm ????????
 [1] "GO.ID"          "Term"           "Category"       "FDR"           
 [5] "P.Value"        "X.Test"         "X.Ref"          "X.notAnnotTest"
 [9] "X.notAnnotRef"  "Over.Under"     "TestSeqs"       "RefSeqs"    
save.image(file="dir95T_frommacbook_june21_16.RData")
ls()

Bl2GO_95T_xls_OVER <- Bl2GO_95T_xls[grep("OVER", Bl2GO_95T_xls[[9]], perl=TRUE), ]
dim(Bl2GO_95T_xls_OVER)  ## [1] 632  12

## ASIDE:
Bl2GO_95T_xls_UNDER <- Bl2GO_95T_xls[grep("UNDER", Bl2GO_95T_xls[[9]], perl=TRUE), ]
dim(Bl2GO_95T_xls_UNDER)  ## [1] 120  12
## for now, don't finish filtering 'UNDER'

## next, filter for FDR < 0.05
Bl2GO_95T_xls_OVER_05 <- Bl2GO_95T_xls_OVER[Bl2GO_95T_xls_OVER[[3]] < 0.05, ]
dim(Bl2GO_95T_xls_OVER_05)  ## [1] 632  12
class(Bl2GO_95T_xls_OVER_05)
## write to Disk
write.table(Bl2GO_95T_xls_OVER_05, file = "Bl2GO_95T_xls_OVER_05.txt", quote=FALSE, sep="\t")
save.image(file="dir95T_frommacbook_june21_16.RData")
ls()
[1] "Bl2GO_95T_xls"         "Bl2GO_95T_xls_OVER"    "Bl2GO_95T_xls_OVER_05"
[4] "Bl2GO_95T_xls_UNDER"  
getwd()

Termcolm <- Bl2GO_95T_xls_OVER_05[[1]]
class(Termcolm)  ## [1] "character"
length(Termcolm)  ## [1] 632
head(Termcolm, n=3)
[1] "organonitrogen compound biosynthetic process"
[2] "organonitrogen compound metabolic process"   
[3] "cytoplasm"
tail(Termcolm, n=3)
# paste for colm 1
colm1 <- paste("95T", c(1:632), sep="")
class(colm1)  ## [1] "character"
length(colm1)  ## [1] 632
head(colm1, n=3)  ## [1] "95T1" "95T2" "95T3"
tail(colm1, n=3)  ## [1] "95T630" "95T631" "95T632"

# now df
GO_ID <- rownames(Bl2GO_95T_xls_OVER_05)
class(GO_ID)  ## [1] "character"
length(GO_ID)  ## [1] 632
head(GO_ID, n=3)  ## matches 1st colm for Bl2GO_95T_xls_OVER_05.txt

Bl2GO_95T_xls_OVER_05_3col <- data.frame(cnt95T = colm1, GO.ID = GO_ID, Term = Termcolm, stringsAsFactors=FALSE)
class(Bl2GO_95T_xls_OVER_05_3col)
dim(Bl2GO_95T_xls_OVER_05_3col)  ## [1] 632   3

head(Bl2GO_95T_xls_OVER_05_3col, n=3)
tail(Bl2GO_95T_xls_OVER_05_3col, n=3)

# write to disk
write.table(Bl2GO_95T_xls_OVER_05_3col, file = "Bl2GO_95T_xls_OVER_05_3col.txt", quote=FALSE, sep="\t", row.names=FALSE, col.names=FALSE)
save.image(file="dir95T_frommacbook_june21_16.RData")
ls()
[1] "Bl2GO_95T_xls"              "Bl2GO_95T_xls_OVER"        
[3] "Bl2GO_95T_xls_OVER_05"      "Bl2GO_95T_xls_OVER_05_3col"
[5] "Bl2GO_95T_xls_UNDER"        "colm1"                     
[7] "GO_ID"                      "Termcolm"    
sessionInfo()
R version 3.2.4 (2016-03-10)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X 10.10.5 (Yosemite)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     
 q()

wc Bl2GO_95T_xls_OVER_05_3col.txt
     632    3605   33209 Bl2GO_95T_xls_OVER_05_3col.txt
head -n 3 Bl2GO_95T_xls_OVER_05_3col.txt
95T1	GO:1901566	organonitrogen compound biosynthetic process
cp Bl2GO_95T_xls_OVER_05_3col.txt Bl2GO_95T_xls_OVER_05_3col.annot
## Ready to run on macbook chart/make statistics with 2nd pro key.

STOPPED

## for 95C, From
/Users/bterry/macbookpro2015/keenanres15/trintoGSEA/B2GOactivity/95Crerun/blast2go_fisher_20160620_0009.txt
## to:
/Users/bterry/macbook2016/keenanres16/Bdac/b2go_chtmakstat/95T_frommacbook/blast2go_fisher_20160602_2212.txt

## now **push** BdactyloidesthruGSEA081615.txt to github, **pull** to Macbook

## on macbook, copied to:
/Users/bterry/macbook2016/keenanres16/Bdac/b2go_chtmakstat/95C_frompro/blast2go_fisher_20160620_0009.txt

## now filter 95C b2go fisher exact test saved txt output 1st for 'Over.Under'
cd /Users/bterry/macbook2016/keenanres16/Bdac/b2go_chtmakstat/95C_frompro
wc blast2go_fisher_20160620_0009.txt
     231  760973 19731770 blast2go_fisher_20160620_0009.txt

R
getwd()
Bl2GO_95C_xls <- read.delim("blast2go_fisher_20160620_0009.txt", stringsAsFactors=FALSE)
dim(Bl2GO_95C_xls)  ## [1] 230  12, agrees wi 'wc'
class(Bl2GO_95C_xls)
colnames(Bl2GO_95C_xls)  ## counting rownames as a colm ????????
 [1] "GO.ID"          "Term"           "Category"       "FDR"           
 [5] "P.Value"        "X.Test"         "X.Ref"          "X.notAnnotTest"
 [9] "X.notAnnotRef"  "Over.Under"     "TestSeqs"       "RefSeqs"
save.image(file="dir95C_frompro_june21_16.RData")
ls()

Bl2GO_95C_xls_OVER <- Bl2GO_95C_xls[grep("OVER", Bl2GO_95C_xls[[9]], perl=TRUE), ]
dim(Bl2GO_95C_xls_OVER)  ## [1] 125  12
## [1] 632  12 for 95T at this point ?????????????????????????????????

06/22/16:
## ASIDE:
Bl2GO_95C_xls_UNDER <- Bl2GO_95C_xls[grep("UNDER", Bl2GO_95C_xls[[9]], perl=TRUE), ]
dim(Bl2GO_95C_xls_UNDER)  ## [1] 105  12
## for 95T, [1] 120  12
## for now, don't finish filtering 'UNDER'

## next, filter for FDR < 0.05
Bl2GO_95C_xls_OVER_05 <- Bl2GO_95C_xls_OVER[Bl2GO_95C_xls_OVER[[3]] < 0.05, ]
dim(Bl2GO_95C_xls_OVER_05)  ## [1] 125  12
class(Bl2GO_95C_xls_OVER_05)
## write to Disk
write.table(Bl2GO_95C_xls_OVER_05, file = "Bl2GO_95C_xls_OVER_05.txt", quote=FALSE, sep="\t")
save.image(file="dir95C_frompro_june21_16.RData")
ls()
[1] "Bl2GO_95C_xls"         "Bl2GO_95C_xls_OVER"    "Bl2GO_95C_xls_OVER_05"
[4] "Bl2GO_95C_xls_UNDER"  
getwd()

Termcolm <- Bl2GO_95C_xls_OVER_05[[1]]
class(Termcolm)  ## [1] "character"
length(Termcolm)  ## [1] 125
## for 95t, was [1] 632
head(Termcolm, n=3)
[1] "photosystem"             "thylakoid membrane"     
[3] "photosynthetic membrane"
tail(Termcolm, n=3)
# paste for colm 1
colm1 <- paste("95C", c(1:125), sep="")
class(colm1)  ## [1] "character"
length(colm1)  ## [1] 125
head(colm1, n=3)  ## [1] "95C1" "95C2" "95C3"
tail(colm1, n=3)  ## [1] "95C123" "95C124" "95C125"

# now df
GO_ID <- rownames(Bl2GO_95C_xls_OVER_05)
class(GO_ID)  ## [1] "character"
length(GO_ID)  ## [1] 125
head(GO_ID, n=3)  ## matches 1st colm & row for Bl2GO_95C_xls_OVER_05.txt
[1] "GO:0009521" "GO:0042651" "GO:0034357"

Bl2GO_95C_xls_OVER_05_3col <- data.frame(cnt95C = colm1, GO.ID = GO_ID, Term = Termcolm, stringsAsFactors=FALSE)
class(Bl2GO_95C_xls_OVER_05_3col)
dim(Bl2GO_95C_xls_OVER_05_3col)  ## [1] 125   3

head(Bl2GO_95C_xls_OVER_05_3col, n=3)
  cnt95C      GO.ID                    Term
1   95C1 GO:0009521             photosystem
tail(Bl2GO_95C_xls_OVER_05_3col, n=3)
125 95C125 GO:0000271 polysaccharide biosynthetic process

# write to disk
write.table(Bl2GO_95C_xls_OVER_05_3col, file = "Bl2GO_95C_xls_OVER_05_3col.txt", quote=FALSE, sep="\t", row.names=FALSE, col.names=FALSE)
save.image(file="dir95C_frompro_june21_16.RData")
ls()
[1] "Bl2GO_95C_xls"              "Bl2GO_95C_xls_OVER"        
[3] "Bl2GO_95C_xls_OVER_05"      "Bl2GO_95C_xls_OVER_05_3col"
[5] "Bl2GO_95C_xls_UNDER"        "colm1"                     
[7] "GO_ID"                      "Termcolm" 
sessionInfo()
R version 3.2.4 (2016-03-10)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X 10.10.5 (Yosemite)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     
q()

wc Bl2GO_95C_xls_OVER_05_3col.txt
     125     661    5889 Bl2GO_95C_xls_OVER_05_3col.txt
## Note: for 95T, had
     632    3605   33209 Bl2GO_95T_xls_OVER_05_3col.txt
head -n 3 Bl2GO_95C_xls_OVER_05_3col.txt
95C1	GO:0009521	photosystem

cp Bl2GO_95C_xls_OVER_05_3col.txt Bl2GO_95C_xls_OVER_05_3col.annot
## Ready to run on macbook chart/make statistics with 2nd pro key.

## Try run b2go basic, won't, so remove, activate 2nd pro key (06/22/16)
Activation key: B2G-TERRPHIL-2ABF66376DF4FEE4CDF8E3C4CC5C9DD7
## start/load annotation/ loaded /Users/bterry/macbook2016/keenanres16/Bdac/b2go_chtmakstat/95T_frommacbook
/Bl2GO_95T_xls_OVER_05_3col.annot
## charts/make statistics/annotation/next/ ***Q:*** what should choose this window ?????/checked molr fcn, biol'l process, cellular component => for each, left default number terms = Q: **50/run**
## **Q:** how set 'level': 'GO distribution by level, ontology level 2'. 

## talked to Vikas, looks like he set me on a good path:
1. got the level 2 chart/make statistics done for both 95T & 95C. For now, saving txt, pdf files to ~/b2gWorkspace dir.

-rw-r--r--    1 bterry  staff   3386 Jun 22 13:43 Bl2GO_95C_xls_OVER_05_3col_lev2.pdf
-rw-r--r--    1 bterry  staff   3137 Jun 22 13:44 Bl2GO_95C_xls_OVER_05_3col_lev2.txt
-rw-r--r--    1 bterry  staff   4066 Jun 22 13:35 Bl2GO_95T_xls_OVER_05_3col_lev2.pdf
-rw-r--r--    1 bterry  staff  14074 Jun 22 13:34 Bl2GO_95T_xls_OVER_05_3col_lev2.txt

2. suggest do ggplot2 for muli-histogram for 95T, 95C. But consider qualitative. Look for previous doc (see Vikas paper he prevly sent me). GO categories for drought (or what trt, ctl represent for 95T, 95C. Compare 95T to these. Q: definition of 'ctl' here ?????????

## sort of, think of the biology. What did the trt do to GO terms. What are biol'l differences betw. trt & ctl ???????

06/23/16:
1st, set up a ggplot2, TO DO: figure out how to do.
So, do bit looking into 95C, 95T level 2 chart/make statistics output from 2nd pro key on macbook.

06/28-29/16:

## create df for 95T, 95C by taking 1st 3 colms from Bl2GO_95C_xls_OVER_05_3col_lev2.txt & Bl2GO_95T_xls_OVER_05_3col_lev2.txt files.

cd /Users/bterry/b2gWorkspace

R
getwd()
Bl2GO_95T_xls_OVER_05_3col_lev2 <- read.delim("Bl2GO_95T_xls_OVER_05_3col_lev2.pdf", stringsAsFactors=FALSE)
Warning messages:
1: In scan(file = file, what = what, sep = sep, quote = quote, dec = dec,  :
  EOF within quoted string
2: In scan(file = file, what = what, sep = sep, quote = quote, dec = dec,  :
  embedded nul(s) found in input
## Q: what to think, Looks like 4 lines are not 'data', so try 
i) make copy of Bl2GO_95T_xls_OVER_05_3col_lev2.txt Bl2GO_95T_xls_OVER_05_3col_lev2_cp.txt
ii) doc. where 3 groups of rows, BP, MF, CC will be after deletion
## BP = 1-19, MF = 20-27, CC = 28-36
ii) delete the 4 non table lines in the 95T copy file.
iii) try import this file into R to 'work on it'.
Bl2GO_95T_xls_OVER_05_3col_lev2_cp <- read.delim("Bl2GO_95T_xls_OVER_05_3col_lev2_cp.txt", stringsAsFactors=FALSE)
dim(Bl2GO_95T_xls_OVER_05_3col_lev2_cp)  ## [1] 35  4, should there not be 26 rows ????????????????????????????????????????????????????????
class(Bl2GO_95T_xls_OVER_05_3col_lev2_cp)
colnames(Bl2GO_95T_xls_OVER_05_3col_lev2_cp)  ## counting rownames as a colm ????????
## So there **weren't** any colm names
## TO DO: dim output above of 35 & 4 suggests may have 4 colms, so as per p-196, vbuffalo bk, create 4 headers as read in file.
Bl2GO_95T_xls_OVER_05_3col_lev2_cp <- read.delim("Bl2GO_95T_xls_OVER_05_3col_lev2_cp.txt", stringsAsFactors=FALSE)
dim(Bl2GO_95T_xls_OVER_05_3col_lev2_cp)  ## [1] 36  4, as expect
class(Bl2GO_95T_xls_OVER_05_3col_lev2_cp)
colnames(Bl2GO_95T_xls_OVER_05_3col_lev2_cp)
[1] "GO.id"   "GO.term" "X.Seqs"  "Seqs"   
head(Bl2GO_95T_xls_OVER_05_3col_lev2_cp, n=1)
ls()
save.image(file="dirb2gWorkspace_june28_16.RData")
ls()
## subset df for 1st 3 colms:
Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3 <- Bl2GO_95T_xls_OVER_05_3col_lev2_cp[ , 1:3, drop=FALSE]
dim(Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3) ## [1] 36  3
class(Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3)
colnames(Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3)
[1] "GO.id"   "GO.term" "X.Seqs" 
## need to subset the 3, BP, MF, CC.
head(Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3, n=2)
Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3[, "GO.id"]

## now create 3 df's for 95T, BP (rows 1-19), MF (rows 20-27), CC (rows 28-36)  ## [1] 19  3
Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3_BP <- Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3[1:19,, drop=FALSE]

head(Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3_BP, n=3)
tail(Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3_BP, n=3)
## now repeat for 95C
Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3_MF <- Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3[20:27,, drop=FALSE]
head(Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3_MF, n=3)
dim(Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3_MF)  ## [1] 8 3
tail(Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3_MF, n=3)

Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3_CC <- Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3[28:36,, drop=FALSE]
dim(Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3_CC)  ## [1] 9 3
head(Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3_CC, n=3)
tail(Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3_CC, n=3)

06/30/16:
## now repeat for 95C
cd /Users/bterry/b2gWorkspace

R
getwd()
i) make copy of Bl2GO_95C_xls_OVER_05_3col_lev2.txt Bl2GO_95C_xls_OVER_05_3col_lev2_cp.txt
ii) doc. where 3 groups of rows, BP, MF, CC will be after deletion
## BP = 1-12, MF = 13-14, CC = 15-22
ii) delete the 3 non table lines in the 95 copy file.
Bl2GO_95C_xls_OVER_05_3col_lev2_cp <- read.delim("Bl2GO_95C_xls_OVER_05_3col_lev2_cp.txt", stringsAsFactors=FALSE)
dim(Bl2GO_95C_xls_OVER_05_3col_lev2_cp)  ## [1] 22  4, as expect
class(Bl2GO_95C_xls_OVER_05_3col_lev2_cp)
colnames(Bl2GO_95C_xls_OVER_05_3col_lev2_cp)
[1] "GO.id"   "GO.term" "X.Seqs"  "Seqs"   
head(Bl2GO_95C_xls_OVER_05_3col_lev2_cp, n=1)
ls()
save.image(file="dirb2gWorkspace_june28_16.RData")
ls()

## subset df for 1st 3 colms:
Bl2GO_95C_xls_OVER_05_3col_lev2_cp_3 <- Bl2GO_95C_xls_OVER_05_3col_lev2_cp[ , 1:3, drop=FALSE]
class(Bl2GO_95C_xls_OVER_05_3col_lev2_cp_3)
dim(Bl2GO_95C_xls_OVER_05_3col_lev2_cp_3)  ## [1] 22  3
head(Bl2GO_95C_xls_OVER_05_3col_lev2_cp_3, n=3)
## now repeat for 95C
Bl2GO_95C_xls_OVER_05_3col_lev2_cp_3_BP <- Bl2GO_95C_xls_OVER_05_3col_lev2_cp_3[1:12,, drop=FALSE]
head(Bl2GO_95C_xls_OVER_05_3col_lev2_cp_3_BP, n=3)
tail(Bl2GO_95C_xls_OVER_05_3col_lev2_cp_3_BP, n=3)
dim(Bl2GO_95C_xls_OVER_05_3col_lev2_cp_3_BP)  ## [1] 12  3

Bl2GO_95C_xls_OVER_05_3col_lev2_cp_3_MF <- Bl2GO_95C_xls_OVER_05_3col_lev2_cp_3[13:14,, drop=FALSE]
head(Bl2GO_95C_xls_OVER_05_3col_lev2_cp_3_MF, n=2)
dim(Bl2GO_95C_xls_OVER_05_3col_lev2_cp_3_MF)  ## [1] 2 3
tail(Bl2GO_95C_xls_OVER_05_3col_lev2_cp_3_MF, n=2)

Bl2GO_95C_xls_OVER_05_3col_lev2_cp_3_CC <- Bl2GO_95C_xls_OVER_05_3col_lev2_cp_3[15:22,, drop=FALSE]
dim(Bl2GO_95C_xls_OVER_05_3col_lev2_cp_3_CC)  ## [1] 8 3
head(Bl2GO_95C_xls_OVER_05_3col_lev2_cp_3_CC, n=3)
tail(Bl2GO_95C_xls_OVER_05_3col_lev2_cp_3_CC, n=3)
save.image(file="dirb2gWorkspace_june28_16.RData")
ls()


STOPPED


cd /Users/bterry/b2gWorkspace
## initially check for duplication of GOnumbers. Note, MF, CC, BF sections of these outputs from b2go/charts/make stat. Perhaps treat these sections separately as b2go/charts/mak stats does. So need separate the 3 sections before start checking for uniqueness of GOnumbers. HOW? Looks like good solns in R (including plyr) for uniqueness if 1st separate the 3 sections.

Perhaps try in R, could just manually count lines in each of the 3 sections, select from the df the row one wants for each of the 3 sections, for 95T, 95C.

07/03/16:
## compare the GO#s betw 95T & 95C for BP, MF, CC
dim(Bl2GO_95C_xls_OVER_05_3col_lev2_cp_3_BP)  ## [1] 12  3
dim(Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3_BP)  ## [1] 19  3
colnames(Bl2GO_95C_xls_OVER_05_3col_lev2_cp_3_BP)
colnames(Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3_BP)

## p-222, vbuffalo
table(Bl2GO_95C_xls_OVER_05_3col_lev2_cp_3_BP$GO.id %in% Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3_BP$GO.id)
TRUE 
  12 
## so, all GO#s in 95C also in 95T 'BP'.
## Q: perhaps try bar grph all 19 GO#s in combined graph, just put zero in for number of seqs for the 7 extra GO#s in 95T.
## perhaps here, try produce 1st 'grouped bar plot' wi ggplot' for 'BP' GO terms (Q: probably 'character' data type issues ???????)
## rerun 'untitled text 15' to refamiliarize with how create this grouped bar graph.
save.image(file="dirb2gWorkspace_june28_16.RData")
ls()

07/04/16:
## p-195, matloff
load(file="dirb2gWorkspace_june28_16.RData")
ls()
colnames(Bl2GO_95C_xls_OVER_05_3col_lev2_cp_3_BP)
Bl2GO_95C_xls_OVER_05_3col_lev2_cp_3_BP_GOsort <- Bl2GO_95C_xls_OVER_05_3col_lev2_cp_3_BP[order(Bl2GO_95C_xls_OVER_05_3col_lev2_cp_3_BP$GO.id),] 
Bl2GO_95C_xls_OVER_05_3col_lev2_cp_3_BP_GOsort

Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3_BP_GOsort <- Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3_BP[order(Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3_BP$GO.id),]
Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3_BP_GOsort

## p-26, matloff, create C95 vector from GO.id colm of Bl2GO_95C_xls_OVER_05_3col_lev2_cp_3_BP_GOsort df
## then insert 7 GO.id colm elts found only in T95.

Bl2GO_95C_xls_OVER_05_3col_lev2_cp_3_BP_GOsort_wi7 <- Bl2GO_95C_xls_OVER_05_3col_lev2_cp_3_BP_GOsort$GO.id
class(Bl2GO_95C_xls_OVER_05_3col_lev2_cp_3_BP_GOsort_wi7)
[1] "character"
Cvec <- Bl2GO_95C_xls_OVER_05_3col_lev2_cp_3_BP_GOsort_wi7
length(Cvec)
Cvec

## finish creating Cvec19

Cvec19 <- c("GO:0000003", Cvec[1:2], "GO:0022414", Cvec[3:5], "GO:0040007",  Cvec[6], "GO:0048511", "GO:0048518", Cvec[7:10], "GO:0051704", Cvec[11:12], "GO:0098754")
class(Cvec19)
length(Cvec19)
Cvec19
Cvec19GOnum <- Cvec19
## looks like Cvec19GOnum has 95T order, 19 long. Next, grab #seqs from 95C df, then substitute in CvecSeqs the 7 locations using 'c' vector construction placing zero for those new 7 #Seqs values.

07/05/16:
colnames(Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3_BP_GOsort)
Cvec19seqs  <- Bl2GO_95C_xls_OVER_05_3col_lev2_cp_3_BP_GOsort$X.Seqs
Cvec19seqs  ##  [1] 43 44  2  2  2 30  2  8 14  1  9  4
class(Cvec19seqs)  ## [1] "integer"
## now add the 7 addl elements, all zeros imitating prev code for GOnums colm.
Cvec19seqs <- c(0, Cvec19seqs[1:2], 0, Cvec19seqs[3:5], 0, Cvec19seqs[6], 0, 0, Cvec19seqs[7:10], 0, Cvec19seqs[11:12], 0)
Cvec19seqs
save.image(file="dirb2gWorkspace_june28_16.RData")
ls()

## now, have GOnums & #Seqs vecs expanded to 19 elts for 95C data. Next, try construct df like 'Food, Music, People' (GOnums, 'Names') internet example, and 'bad, good, etc' are #Seqs for C95, T95.
## see untitled text 10.

07/07/16:
class(Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3_BP_GOsort)
dim(Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3_BP_GOsort)
head(head(Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3_BP_GOsort, n=3)
Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3_BP_GOsort

Names <- Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3_BP_GOsort$GO.id
C95 <- Cvec19seqs
T95 <- Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3_BP_GOsort$X.Seqs

grpdbargraphdf = data.frame(Names, C95, T95, stringsAsFactors=FALSE)
grpdbargraphdf

library(reshape)
data.m <- melt(grpdbargraphdf, id.vars='Names')
data.m

install.packages("ggplot2")
library("ggplot2")
pdf("testgroupedbargraph.pdf")
ggplot(data.m, aes(Names, value)) +   
  geom_bar(aes(fill = variable), position = "dodge", stat="identity")
dev.off()



pdf("flipgroupedbargraph.pdf")
ggplot(data.m, aes(Names, value)) +   
  geom_bar(aes(fill = variable), position = "dodge", stat="identity") + coord_flip()
dev.off()
## worked, 

## next task, go back replace GOnum with GOterm, try add main graph message ????

Names <- Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3_BP_GOsort$GO.term
grpdbargraphGOtermdf = data.frame(Names, C95, T95, stringsAsFactors=FALSE)
grpdbargraphGOtermdf
data.m <- melt(grpdbargraphGOtermdf, id.vars='Names')
data.m
pdf("flipgroupedbargraphGOterm.pdf")
ggplot(data.m, aes(Names, value)) +   
  geom_bar(aes(fill = variable), position = "dodge", stat="identity") + coord_flip() + labs(title = "Grouped Bar graph 95T vs 95C, B2G lev 2 ????")
dev.off()

## note: order of GO#s, GOterms in plots **different** betw two graphs ????????
## To test: remove title from latter plot, see if any affect ????????
pdf("flipgroupedbargraphGOterm_notitle.pdf")
ggplot(data.m, aes(Names, value)) +   
  geom_bar(aes(fill = variable), position = "dodge", stat="identity") + coord_flip()
dev.off()
## no help, same order as try 'with title' ????????????????????????
## But each GO#, GOterm **found** on each graph

## Q: trt = leaf spot ... ??????????????????, go ck vikas paper, try compare other reported GO terms for this trtmnt ???????????????
## So next, do this graph for 'MF', 'CC'.

Bl2GO_95C_xls_OVER_05_3col_lev2_cp_3_MF
## p-222, vbuffalo
table(Bl2GO_95C_xls_OVER_05_3col_lev2_cp_3_MF$GO.id %in% Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3_MF$GO.id)
TRUE 
   2 
## so, all GO#s in 95C also in 95T 'MF'.

Bl2GO_95C_xls_OVER_05_3col_lev2_cp_3_MF$GO.id
Bl2GO_95C_xls_OVER_05_3col_lev2_cp_3_MF
Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3_MF
dim(Bl2GO_95C_xls_OVER_05_3col_lev2_cp_3_MF)  ## [1] 2 3
dim(Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3_MF)  ## [1] 8 3
## 5 of these 'extra' rows have very low number of sequences.
## Q: perhaps try bar grph all 8 GO#s in combined graph, just put zero in for number of seqs for the 6 extra GO#s in 95T.
save.image(file="dirb2gWorkspace_june28_16.RData")
ls()

## Q: MEANING OF MY 95C, 95T COMPARISON (THINKING OF KEENAN FIPS 2016 paper ???????????????????????????
## Q: consider doing some of the meta data presented in this paper on 95C, 95T data set  ????????

STOPPED

07/18/16:
## talked to Vikas, opinion: next, take 'grouped bar chart' data, the GOterms there with bit ratio for treated, try see if can relate leaf-spot affected genes in lit. to the genes in GO consortium for the GOterms wi big ratio in my for ex., BP 'grouped bar chart'.

## Q: where find genes associated with GOterms? 

07/20/16:
## Goal: identify genes in diff'ly expressed tx's in 95T?

## Plan:
## After looking around Gene Ontology Consortium a bit, looks like searching starting from GOterm to genes say not practical. Looks like **lots** of genes for each GOterm. For example, 'single-organism process' is a term enriched for 95T vs 95C. Looks like no practical way to search for what genes included in this term? Perhaps possibly, take tx's in 95T 'diff'ly expressed' set compared to 95C, blast, subset the tx's assoc'd with GO# associated wi GOterm 'single-organism process'. Then if want to find an associated gene with tx's in this subset, perhaps blast vs nr nucleotide db (Q: make sure RNA, cDNA, relationship correct?). Finally, compare these genes with 'leaf spot' genes cited in Keenan FIPS paper, cited lit?

## WAIT?
## already have GO#s for each of 2638 DE 95T tx's. 'single-organism process' has GO# = 44699.
## go back vitas 3-colm file, have GO# for each of 2638 unique DE tx's. So search file wi tx's wi this GO#. Then, blast seqs of such tx's to see what genes they 'hit'. Q: What if 'lev2' output from blast2go is 'parent of' some of these GO#s, thus, could not find subset of DE tx's which are 'single-organism process'? Q: what is a 'single-organism process'? Perhaps way relate GO# = 44699 to the GO#s assocd wi the DE tx's, i.e., perhaps blast2go, some other s/w ????????????????

___________________________________________________________________________
07/28/16:

## SUMMARY, DOCUMENTATION, & ***WHAT TO DO NEXT***
## talked Keenan today, 
i) do get genes behind lev2 GO#s in grouped bar Chart
ii) but redo plot after 1st normalizing 95T, 95C graphed values (calc median, then divide each value by median, values > median, their values  >1, values < median, their new values now  <1. Should at a glance see relative sizes each pair, 95T, 95C plotted together. 
iii) then try relate pfam families with genes, and couple diseases, wi HMM alg (?) to find relationships. Q: exactly what is idea ?????????????????
## for example, NB ARC (possible gene resisting leaf spot disease), search pfam for, then clustal, MSA, then HMM Build, then HMM search trinity.fasta for B. dactyloides version of NB ARC, then check if such seqs in DE tx's for 95T. ?????????????????????

iv) vikas, TF db, motif, KEGG

input for b2go, fisher ex. test (2 files)

line 6651, 6657
--threecolmxlsvikasform.txt

line 7034
--(wc threecolmxlsvikasform.annot
  324107 1591873 20162525 threecolmxlsvikasform.annot)
  
line 7043
--## select test set => colm1_95Tupvikasform_uniq.txt

line 7047
--## 11:33pm => 12:19am, 6/17/16, so **24:44** hr:min to run.

line 7051 (blast2go_statistics_20160617_0917.txt => not fisher ??????????


line 7128
output b2go, fisher ex. test
/Users/bterry/macbook2016/keenanres16/Bdac/b2go_chtmakstat/95T_frommacbook/blast2go_fisher_20160602_2212.txt

line 7130
## now filter 95T b2go fisher exact test saved txt output 1st for 'Over.Under' 

line 7133
cd /Users/bterry/macbook2016/keenanres16/Bdac/b2go_chtmakstat/95T_frommacbook
wc blast2go_fisher_20160602_2212.txt
     753 1489910 38555079 blast2go_fisher_20160602_2212.txt

line 7138
Bl2GO_95T_xls <- read.delim("blast2go_fisher_20160602_2212.txt", stringsAsFactors=FALSE)

line 7148
Bl2GO_95T_xls_OVER <- Bl2GO_95T_xls[grep("OVER", Bl2GO_95T_xls[[9]], perl=TRUE), ]
dim(Bl2GO_95T_xls_OVER)  ## [1] 632  12

line 7156
## next, filter for FDR < 0.05
Bl2GO_95T_xls_OVER_05 <- Bl2GO_95T_xls_OVER[Bl2GO_95T_xls_OVER[[3]] < 0.05, ]
dim(Bl2GO_95T_xls_OVER_05)  ## [1] 632  12

line 7161
write.table(Bl2GO_95T_xls_OVER_05, file = "Bl2GO_95T_xls_OVER_05.txt", quote=FALSE, sep="\t")

line 7176
# ***paste*** for colm 1
colm1 <- paste("95T", c(1:632), sep="")

line 7189
Bl2GO_95T_xls_OVER_05_3col <- data.frame(cnt95T = colm1, GO.ID = GO_ID, Term = Termcolm, stringsAsFactors=FALSE)
dim(Bl2GO_95T_xls_OVER_05_3col)  ## [1] 632   3

line 7197
write.table(Bl2GO_95T_xls_OVER_05_3col, file = "Bl2GO_95T_xls_OVER_05_3col.txt", quote=FALSE, sep="\t", row.names=FALSE, col.names=FALSE)
## has *************95T??******* number in 1st colm 

line 7225
## for 95C, From
...

line 7226-8 (confusion ?????????????????????????????????)
...

line 7308
write.table(Bl2GO_95C_xls_OVER_05_3col, file = "Bl2GO_95C_xls_OVER_05_3col.txt", quote=FALSE, sep="\t", row.names=FALSE, col.names=FALSE)

line 7334 (95C)
cp Bl2GO_95C_xls_OVER_05_3col.txt Bl2GO_95C_xls_OVER_05_3col.annot
## Ready to run on macbook chart/make statistics with 2nd pro key.

line 7345
1. got the level 2 chart/make statistics done for both 95T & 95C. For now, saving txt, pdf files to ~/b2gWorkspace dir.

Bl2GO_95T_xls_OVER_05_3col_lev2.txt


line 7352
2. suggest do ggplot2 for muli-histogram for 95T, 95C.
## me, perhaps normalize 95T, 95C 1st, i.e., say take median each data set,
calc. ratio each value compared to median\, then do grouped bar plot ????????


STOPPED

To finish: thru grouped bar graph

...

## mapping grouped bar graph GOterms back to specific set tx's from which they were built. Idea (?) Blast these tx seqs vs NR nucleotide db, find genes behind/underlying for example, 44699, 'single-organism process'. Is this a GOAL?

95T...lev2 (44699, single-organism process)

=> map 95T##'s to ...3col.txt file, colm1, (the subset under 44699, single-organism process)

=> map assoc'd GO#s to tx's in threecolmxlsvikasform.annot

=> map tx's to trinity.fasta, tx's & assocd seq.

=> blast these seqs vs NR nucleotide db

=> list top hit genes as those responsible for GO# = 44699, 'single-organism process' from grouped bar graph.


_____________________________________________________________________________

## do a push to github/planets, done.


08/01/16:
## several tasks above incomplete, but here, try do 'median' normalization before grouped bar graph plot for 'BP' GO#s, then GOterms.

cd b2gWorkspace
r
load(file="dirb2gWorkspace_june28_16.RData")
ls()
class(Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3_BP_GOsort)
dim(Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3_BP_GOsort)
head(Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3_BP_GOsort, n=3)
Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3_BP_GOsort

grpdbargraphdf

NamesGOid <- Bl2GO_95T_xls_OVER_05_3col_lev2_cp_3_BP_GOsort$GO.id
NamesGOid
## need median normalize C95, T95 before make df, grpdbargraphGOiddf
C95
medC95 <- median(C95)
medC95
vnormC95 <- C95/medC95
vnormC95

T95
medT95 <- median(T95)
medT95
vnormT95 <- T95/medT95
vnormT95
## Q: this should work even if medians are 2 & 15. Since each value is relative to each median (like in 'median units', should give relatable size bars, can compare ???????????????????????

grpdbargraphGOidmeddf = data.frame(NamesGOid, vnormC95, vnormT95, stringsAsFactors=FALSE)
grpdbargraphGOidmeddf

## next, lines 7541 - 43, create median normaln for C95, T95, then grpdbargraphGOidmeddf, then melt, & ggplot.

## now do the 'melt' preceding the ggplot.

library(reshape)
dataGOidmed.m <- melt(grpdbargraphGOidmeddf, id.vars='NamesGOid')
dataGOidmed.m

install.packages("ggplot2")
library("ggplot2")
pdf("xaxisgroupedbargraphGOidmed.pdf")
ggplot(dataGOidmed.m, aes(NamesGOid, value)) +   
  geom_bar(aes(fill = variable), position = "dodge", stat="identity")
dev.off()
## working fine, now flip it

pdf("flipgroupedbargraphGOidmed.pdf")
ggplot(dataGOidmed.m, aes(NamesGOid, value)) +   
  geom_bar(aes(fill = variable), position = "dodge", stat="identity") + coord_flip()
dev.off()


## refer 07/28/16, talk wi Keenan (notes above)

## mapping grouped bar graph GOterms back to specific set tx's from which they were built. Idea (?) Blast these tx seqs vs NR nucleotide db, find genes behind/underlying for example, 44699, 'single-organism process'. Is this a GOAL?

95T...lev2 (44699, single-organism process)

=> map 95T##'s to ...3col.txt file, colm1, (the subset under 44699, single-organism process)

=> map assoc'd GO#s to tx's in threecolmxlsvikasform.annot

=> map tx's to trinity.fasta, tx's & assocd seq.

=> blast these seqs vs NR nucleotide db

=> list top hit genes as those responsible for GO# = 44699, 'single-organism process' from grouped bar graph.


08/08/16:
pushed this file to github

08/09/16:
## in Bl2GO_95T_xls_OVER_05_3col_lev2_cp.txt, for row 'GO:0044699' get colm 4, 'seqs', 235 of them ??????
sort
uniq
select matching records from colm 1 of Bl2GO_95T_xls_OVER_05_3col.txt

select matching GO#s records from colm 2 of threecolmxlsvikasform.txt

select matching tx's from trinity.fasta (Q: location, is there one on macbook ??)

## ref: line 4679
ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/trinity_out_dir
ls -al
less Trinity.fasta
>TRINITY_DN10610_c0_g1_i1 len=460 path=[946:0-169 948:170-236 943:237-459] [-1, 946, 948, 943, -2]
CGCATGCTGTTTGTGCAGTGGTGCAGTTCAGAGCGTTGGTGTTGAGCCGGGAAATGGGTA
TGCCTTATCTGACATAATTCACTGGGGGTAGCAATCCGGAATTCCACACCTACTAGCTGC

## so looks like can match tx's in Trinity.fasta with colm 1 of threecolmxlsvikasform.txt

## should now have the records in Trinity.fasta which produced specific GO#/GOterm in lev2 file above.

# perhap grep from linux shell the '^>TRI' rows before go into R ????

08/16/16:
Talked to keenan,
NB ARC domain, a family of proteins. Search pfam for this name, get seqs, then these vs trinotate db (or trinity if no seqs in trinotate db ???), try find B. dactyloides wi HMMER, perhaps creates MSA like output (??) Perhaps search vs tx's from say a GOterm from lev2 b2GO ????????


08/28/16:
## reading thru tab.0124.pdf (read 1st 8 pages) at /Users/bterry/macbook2016/keenanres16/Bdac/pfam/tab.0124.pdf

## find lot of work has been done on disease resistance in plants. Also, note, at http://www.ncbi.nlm.nih.gov/books/NBK7286/ at ncbi, article: Overview of Intracellular Compartments and Trafficking Pathways, helpful, since, intracellular compartments impt in disease resistance in plants.

## so back to plan of 08/16/16 above.

## need get list of protein families Keenan says has (i.e., in addition to NB ARC domain. **TO DO.**


STOPPED

09/12/16:
## Can't get globus going, so try scp -r for copying $WORK home dir from crane to new 3 Tb extl hdrive connected to 'pro' laptop.

cd /Volumes
cd Volumes
cd /Volumes/My Passport for Mac


scp -r pterry@crane.unl.edu:/work/amundsen/pterry/ .
## start 12:28pm.
## progress showing on screen.
> 429*8
[1] 3432
> (429*8)
[1] 3432
> (429*8)/60
[1] 57.2
> 
## so ~ 2 and 1/2 days to complete.
## connection closed after only ~ 6 GB copied.
## that is, stopped this, succeeded with globus, before 10/31/16. e.g., copied to 'pro' keenan's office, then to 3Tb extl hdrive, then time capsule backed up pro. 
TO DO: bit of checking to see if can find, recover couple files from these 'attic' copies.


10/20/16:
## **upgraded** to bioconductor 3.4 today
source("https://bioconductor.org/biocLite.R")
    biocLite("BiocUpgrade")
## written for r 3.3.1 which i have on macbook.

10/31/16:
## do a push to github... from ~/planets from 'macbook'

11/03/16:
## Try do on macbook. Create a dir., /Users/bterry/macbook2016/keenanres16/Bdac/pca

Try to do pca analysis on file Trinity used for their pca
attempt. See above, 12/21/15, slurm_comp_reps_for_each_sample_PCA.sh. So file to do pca on is Trinity_trans.counts.matrix. So, copy file from 'attic' archive from 3T extl hdrive.
/Volumes/My Passport for Mac/attic/Trin21test/95C1-3T1-3/qc_comp_reps/Trinity_trans.counts.matrix
## to 
/Users/bterry/macbook2016/keenanres16/Bdac/pca
ls -al
-rw-r--r--   1 bterry  staff  9495163 Oct 25 22:09 Trinity_trans.counts.matrix
## Now, code similar to stat873, fall, 2016, for lab3prob3a &/or 3b.

philip-terry-2:pca bterry$ wc Trinity_trans.counts.matrix
  165460 1158219 9495163 Trinity_trans.counts.matrix
  
## see r code script, Trtrctspca.R  

## Note: perhaps check 3Tb external drive /Volumes/My Passport for Mac/attic/Trin21test/95C1-3T1-3/qc_comp_reps dir for output from running Trinity_trans.counts.matrix.R output.
## I note there using 'log2', why here ???????????????????????
## writes the 'loadings', and 'scores' to a file (**NOT** finding these two files in qc_comp_reps dir ??????????)
## note, I generated DE output ('up' from 95T & 95C). Perhaps could run printcomp on an input file containing these ?????????????????
pca$loadings  ## so almost no difference in components
## of eigenvectors, PC1, or PC2. Would this be expected ??????????????
> dim(scoresm)  ## = pca$scores
[1] 165459      6
## Q: if try make vikas ggplot, do I 1st try reduce number records in pca$scores file to plot ???????????????

11/04/16:
Talked to Vikas about use pca on Trinity_trans.counts.matrix file. Questions to be answered:
i) clarify how analyze variance loadings (eigenvector 'components'). How use the sign on the components?
ii) do split, Q: how would work, since each tx counts listed for all 6 samples ????????? Perhaps use my DE up regulated list of tx's for 'C', 'T' samples? 
iii) vikas, R script in methods section, take say top 1000 tx's, perhaps log2 ???, with highest variance, run princomp on. Q: similar to DE objective ???? See his paper 'Nature scientific Reports, 6:34908, 2016' supplementary methods section, p-2 for R script to do.
iv) > pca$loadings, Cumulative Var    0.2    0.4    0.6    0.8    1.0, Eskridge ????????
v) biplot, scale on top, RHS of plot ???????
## on a biplot, what are the lines, eigenvectors ???????????????
vi) email vikas, internet address to access his paper ??????
vii) scree plot

## Q: what was trinity s/w trying to achieve with a pca plot ??????????????

11/05/16:
## ok, work on HMMER and Bdac trinity data.
## info from Keenan, steps
## 1. pfam, dnload gene family (NB ARC)
## 2. pfam google search ?????
## 3. coronation (??) & model, LHS of web page => **how** keenan get to this page ?????????????
## b. then dnload raw HMMER ???, NB ARC
## 4. HMMER search trinity.fa
## ?. HMMBUILD

## Proceed wi vikas idea, run pca top 1000 tx's with highest variation.
11/07/16:
## Wait, talked to K. Eskridge, 1st need to check quality of data in Trinity_trans.counts.matrix file. If ok, perhaps go for most variable 1000 tx's, but not as Vikas did.

11/08/16:
## Apply **Chebyshev's theorem**: the proportion of any distribution that lies within k std devs of the mean is at least: 1 - 1/k^2, where k is a +ve number greater than 1. This theorem applies to all distributions of data.

For Trinity_trans.counts.matrix file, calc.

(|xbar_1 - xbar_2|)/sqrt(V(xbar_1 - xbar_2)

for each row in the file. I note the std dev in denominator is additional, perhaps to allow comparison betw. the various rows ???????????????????

try v buffalo & add new colm ???????
data$size      <- 0   # Use the same value (0) for all rows

## bar plot of the std devs,  see http://stats.libretexts.org/Textbook_Maps/General_Statistics/Map%3A_Introductory_Statistics_(Shafer_and_Zhang)/02%3A_Descriptive_Statistics/2.5%3A_The_Empirical_Rule_and_Chebyshev's_Theorem
for Example
## or v buffalo, p-217
## or think recall one in an R club presentation ????????

11/14/16:
## .R file working on last few days, rename from TRtxctspca.R to TRtxctspca_testing.R. Then, copy to TRtxctspca.R, focus this toward direction now want to go.

11/16/16:
## Try use Chebychev theorem to find DE tx's (> 6 stdevs in either direction)
## Mlog2_52C1dfmin6sdev has 13 records, T > C DExpression.
## Mlog2_52C1dfplus6sdev has 28 records, C > T DExpression.
## I note for this 28, several of the '95T' records have all zeros? Q: should one next compare these subsets to Trinity DE files? Perhaps especially test these sequences with HMMER & pfam database? 
## Q: failed for p-216, v. buffalo, to plot ggplot2 combined with 'cut' fcn ?????????????????

11/18/16:
## Before do stuff of 11/16/16, try do 
## Q: test calc meandif row, since values large compared to log2 input data ??
## Try princomp, biplot on 13+28 = 41 rows mentioned in 11/16/16 above.
## 1st, perhaps create df wi row names, & 1-char symbol for the 41 rows
## 2nd, need matrix with 6 colms, here, total 41 rows, include colm names, 
## 3rd, princomp (lab3probb3.R,and8.pdf, hand8.pdf, stat 873)
## list scores, loadings, sqrt(sdev), the eigenvalues
## and heatmap
## df like vikas,
data <- data.frame(Symb,PC1,PC2)
...
p+geom_text_repel(size=7)
ggsave(...

biplot(...

11/20/16:
## in Trtxctspca.R, results & plans:

## 13 'T' < 6 stdevs grouped in one cluster as expected (A-M)
## 28 'C' > 6 stdevs grouped in one cluster as expected (N-9)
## Will need REDO not excluding '95C1' < mean rows, since some
## of 'DE' tx's have zeros in all 3 'T' repeats.
## TODO: compare 'DE' expressed tx's here with those from 
## Trinity s/w.
## Agreenent with 'biplot' plot, eigenvalue 'components'
## grouped same place as their variables on ggplot plot.
## still 'cut' in vbuffalo, p-216 ?????????????????
## Sc2, St2, Sp2, use ???????????????????? *****??????******

## **TO DO**: doc eskridge comments of 11/21/16
## ...

1123/16:
## perhaps find 'DE' by Trinity, see if any overlap with the 28 or 13 found > 6 stdev with Chebychev approach (Q: where documented ????????????)
## the files to be compared are:
cd /Users/bterry/macbook2016/keenanres16/Bdac/pca

-rw-r--r--   1 bterry  staff   308395 Oct 25 23:18 Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95C-UP.subset

-rw-r--r--   1 bterry  staff   547935 Oct 25 23:18 Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95T-UP.subset

## so run Trtxctspca.R down thru producing 28, 13 tx's < or > than 6 stdev's (Chebychev).
## read in these two Trinity DE files wi 'read.delim', and compare them to the '28 & 13' wi %in%

# xlsC_up_logdf <- read.delim("xlsC_up_logdf.txt", header=T, sep=" ", stringsAsFactors=FALSE)
C-UP <- read.delim("Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95C-UP.subset", header=T, sep=" ", stringsAsFactors=FALSE)
colnames(de95C-UP)
dim(C-UP)
Chebminus_C-UP <- rownames(Mlog2_52C1dfmin6sdev) %in% C-UP$id
Chebplus_C-UP <- rownames(Mlog2_52C1dfplus6sdev) %in% C-UP$id


## TO DOC: & rerun Chebychev wi all input, OR **minus** rowsums < 10 ??????? Trtxctspca_rsums.R
## to accomplish: try subset, characterize with rowSums fcn. 
## i) test doing a rowSums with multiple row dataframe. Ref: http://stackoverflow.com/questions/23568142/row-and-column-sums-in-r

## ii) then do for 165k dataset. do 'summary' of vector (see what have), then add this vector as a colm to the data set, do before 'for' loop. Then 
## iii) subset the 165k df for rows >= 10
## iv) dim
## v) run for loop. Careful, wi new 'rsums' colm, to correctly handle new colms while running for loop.

## 11/28/16:
## issue with 'Inf's & 'NA's in Mlog2_rsums
## so, actually a record where variance for both 'C' & 'T' samples is ZERO!!
## So, TO DO, remove the **61** records with Inf in colm 8, 'meandif'. Found with search inside BBEdit.
## summary(Mlog2_thenotInf[,8])
##Min.   1st Qu.    Median      Mean   3rd Qu.      Max.      NA's 
##-629.6000   -3.9870   -1.7750   -2.9200   -0.1007  215.2000         2 
## so, remove the 'Inf's.
## so, still two rows of NA's, not in original input file, 
## TO DO, remove, then proceed to comparison with Trinity's C_UP, T_Up sets

## vi) compare '>' and '<' tx sets with Trinity's C_UP, T_Up sets.

11/30/16:

STOPPED

DOC stuff this day ...
## table of overlap betw. C_UP (2185), T_UP (3971), and BBEDitNAmin6sdev (292) & BBEDitNAplus6sdev (49).

               C_UP(2185)         T_UP(3971)

minus(292)        0                193(66%)

plus(49)       44(90%)                0

## So, get NO overlap betw. DE for 'C', 'T'
## But, only subset of Chebychev > or < 6 stdev's vs Trinity DE's ?????????
## explanation: ?????????????????????????????
## Note: rwoSums >= 10, 61 rows wi 'Inf' (discarded), two rows 'NA's, discarded.

## next princomp, 
See Trtxctspca_rsums.R, 
## one thing left, ck **Vikas**, remove rownames (here numbers) from plot ?????

12/04/16:
Try barplot (p-216, vbuffalo) using vbuffalo code, & input data file
## Result: **FAILS** also for **PREspecified** cut data ????????????????????

## so found sdvec with the sd values to use with 'cut' (ref p-216, Vbuffalo)
## ## ok, have 49 rows > 6 stdevs as previously found for DE '95C' rows.

## Now, try find out if can ggplot as p-216
## success!

## For now, move on from this Chebychev plot, left, **TO DO**, as per Vikas, try doc this plot a bit more.

12/08/16:
## try heatmap(of what?, perhaps BBEDitNArbind data ???????), as per R club, #4 meeting. Here, not using heatmap pgm, but looks like should work find when no need to cluster, but note, some comments in Galili user2016 video ( transformation, etc. considerations?)

## 1st need rbind long form for 292 ('T') + 49 ('C') gtr 6 stdev count rows. Start from BBEDitNA dataframe.

12/12/16:
## Plotted Chevychev 6 sample colms several ways, don't know what to make of the data? Using Trtxctspca_rsums.R
## Perhaps for the 341 rows, can look into bit more by scatter plot for the data input to the ggplot system. Plot input data pre-log2 (sorted by meandif), pre & after scale, post log2, before and after scale, sorted & not sorted.
## learn how use heatmap.2 without clustering. Do pca for C_UP, T_UP. Vikas for pca plot, problem with not seeing rownames in plot ????????????


12/13/16:
## Talked to Keenan, now Hmmer, 
## dnloaded NB-ARC.hmm, placed in dir Bdac/pfam on macbook.
## 1st, on crane, to run hmmsearch wih this .hmm family with my Trinity.fasta file, expect blast type output, get best ones, p-value, ...
## Note: looks like I need nhmmer (for DNA), not hmmsearch (for protein)


12/14-15/16:
12/18/16:
## off working wi ggplot of pca, will return to Hmmer tomorrow when expect get 3.1b2 installed on crane cluster.

12/19/16:
## Comments,
## crane has HMMER ver 3.1b2, the latest. Note: **need learn where** hmmer files installed, want to see if can open dna_target.fa ('exec' file type in mac dnload, see p-31) Upshot: someone gave wrong permissions on /util/src/BCRF/hmmer/3.1b2/tutorial/dna_target.fa file (but in 'terminal', can do head(dna_target.fa), displays as fasta file.
## Note: 'module show hummer/3.1' not helping, refers me to 'module spider hummer/3.1' which not helping either ???????????????????

## UserGuide.pdf, looks like ok try p-31, for 1st step described by Keenan.
## create new dir inside $WORK, for 'Hmmer work' initially try run with 'srun' 

ssh -Y pterry@crane.unl.edu 
# Rrq096mN 
#cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo/95TUPsubset
cd /work/amundsen/pterry/
ls -al
cd ... **same level** as Trin21test
mkdir hmm_pfam
## see p-31, Userguide.pdf
## > nhmmer MADE1.hmm tutorial/dna target.fa > MADE1.out
## ck location most recent Trinity.fasta  ## created 9/14/16, location:
#cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/trinity_out_dir
cd hmm_pfam/
grep -c "^>" Trinity.fasta  ## 165459, why working on crane ?????

#scp NB-ARC.hmm to hmm_pfam dir ????????? or 'globus' ????????, or dnload direct to crane ?????????????
cd /Users/bterry/macbook2016/keenanres16/Bdac/pfam
scp NB-ARC.hmm pterry@crane.unl.edu:/work/amundsen/pterry/hmm_pfam

ssh -Y pterry@crane.unl.edu 
# Rrq096mN 
srun --pty --ntasks-per-node=4 --mem 4gb --qos=short $SHELL
## Q: setting parameters for srun ??????????????
cd /work/amundsen/pterry/hmm_pfam
module load compiler/gcc/4.8 openmpi/1.8 hmmer

nhmmer NB-ARC.hmm /work/amundsen/pterry/Trin21test/95C1-3T1-3/trinity_out_dir/Trinity.fasta > Trinity_nhmmer.out
Error: Invalid alphabet type in hmm for nhmmer. Expect DNA or RNA
cp /work/amundsen/pterry/Trin21test/95C1-3T1-3/trinity_out_dir/Trinity.fasta .
mv Trinity.fasta Trinity.fa
nhmmer NB-ARC.hmm /work/amundsen/pterry/Trin21test/95C1-3T1-3/trinity_out_dir/Trinity.fasta > Trinity_nhmmer.out
Error: Invalid alphabet type in hmm for nhmmer. Expect DNA or RNA
## Q: perhaps I have a protein .hmm, need a DNA/RNA one ?????????

## extract best ones from out file, (pvalue)
## make MSA (clustalw ??), perhaps, p-26, try 'hmmalign' ???
## hmmBuild ??, new .hmm, p-30 ????, starting wi an .hmm ??????????
## hmmSearch (??), of Trinity.fasta, new seqs, (or use nhmmer ??)
## now compare with DE tx's, C_UP, T_UP, or the 341 from Chebychev analysis ??

STOPPED

12/22/16:
## talked to Keenan, Vikas, Upshot: 
i) Will need to revisit what did with Trinity analysis, for example, 
ii) 'trimmed' files, were they 80 nucleotides (??), if so, short of 100 aa long TransDecoder.LongOrfs. ??????????????????
## but wait, if Trinity.fasta.transdecorder.pep concatenates tx's > 100 aa's, what to think ?????????????
iii) try hmmsearch, so see if can run on crane using Trinity.fasta.transdecoder.pep ???????????????????????????????

## det. number '>' in two pep files, trinity.fasta ??
grep -c "^TRI" Trinity_trans.counts.matrix
165459
grep -c "^>" Trinity.fasta
165459
ssh -Y pterry@crane.unl.edu 
# Rrq096mN 
## from /work/amundsen/pterry/Trin21test/95C1-3T1-3/ dir,
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3
cd transdecoder/
ls -altop
## find Trinity.fasta.transdecoder.pep ??
grep -c "^>" Trinity.fasta.transdecoder.pep  ## ***74489***
## find longest_orfs.pep ??
cd Trinity.fasta.transdecoder_dir/
grep -c "^>" longest_orfs.pep  ## 158367
## my two 'pep' files are fasta, not MSA ????
## so 1st, try as per Keenan, hmmsearch one at a time, the two .pep files above.
cd ..
pwd
srun --pty --ntasks-per-node=4 --mem 4gb --qos=short $SHELL
module load compiler/gcc/4.8 openmpi/1.8 hmmer
hmmsearch NB-ARC.hmm Trinity.fasta.transdecoder.pep > hmmsrchshortpep.out
less hmmsrchshortpep.out
wc hmmsrchshortpep.out
##   20512  119872 1735266 hmmsrchshortpep.out
## now what to do with this output ????????
## initially, perhaps scp it to macbook, examine what have. Think need create a fasta file of top hits (how decide) ???????????
## from /work/amundsen/pterry/hmm_pfam/hmmsrchshortpep.out file

12/23/16:
cd /Users/bterry/macbook2016/keenanres16/Bdac/pfam
scp pterry@crane.unl.edu:/work/amundsen/pterry/hmm_pfam/hmmsrchshortpep.out .
ls -al
## Hmmer User's Guide, p-21-27, discussing 'hmmsearch' output
## 1st sec, 'header', 2nd, 'sequence top hits', list of ranked top hits (sorted by E-value, most significant hit first), formatted in a BLAST-like style.
## last 2 colms, Q: will there be an issue relation names in these colms back to 
Trinity.fasta.transdecoder.pep file when try subset that file by lowest E-value rows from hmmsrchshortpep.out ?????????????????????????? Perhaps not, if when subset on a tx name, take all domains for that tx when subset ???????????
## E-value is based on the sequence bit score, which is the second number. ... log-odds score ... ???????????????????
## 3rd colm, 'bias'. The only time you really need to pay attention to the bias value is when it’s **large**, on the same order of magnitude as the sequence bit score.
## ... turn the biased-composition score correction off ?????????????
## The next three colms are again an E-value, score, and bias, but only for the **single** best-scoring domain in the sequence, rather than the sum of all its identified domains.
## The **idea** is that we might be able to detect that a sequence is a member of a multidomain family because it contains multiple weakly-scoring domains, even if no single domain is solidly significant on its own.
## p-23
## So ***operationally***, 
if both E-values are significant (<< 1), the sequence is likely to be homologous to your query.
 if the full sequence E-value is significant but the single best domain E-value is not, the target sequence is **probably** a multidomain remote homolog; but be wary, and watch out for the case where it’s just a repetitive sequence.
## ... 'envelope' ...  ????????????????????
## The two columns headed #doms are two different estimates of the number of distinct domains that the target sequence contains. ... These two numbers should be about the **same**.
## ***3rd*** output section: 
## Domain annotation for each sequence (and alignments):
## p-24
## The ! or ? symbol indicates whether this domain does or does not satisfy **both** per-sequence and per-domain inclusion thresholds.
## 'conditional E-value  ?????????????????????
## 'independent E-value' 
## p-25
## ??????????????????????
## Operationally:
## If the independent E-value is significant (<< 1), that means that even this single domain by itself is such a strong hit that it suffices to identify the sequence as a **significant** homolog with respect to the size of the entire original database search. You can be confident that this is a homologous domain.
## The next **four** columns give the endpoints of the reported local alignment with respect to both the query model (“hmm from” and “hmm to”) and the target sequence (“ali from” and “ali to”).
## ... symbology ...
## ... envelope ...
## Operationally, ...
## ... last colm ...
## p-26
## p-27
## summary Statistics

12/24/16:
## ok, try take highest scoring hit in hmmsrchshortpep.out, relate back to Trinity.fasta.transdecoder.pep.
## so need to scp over (Trinity.fasta.transdecoder.pep from crane (/work/amundsen/pterry/hmm_pfam)
cd /Users/bterry/macbook2016/keenanres16/Bdac/pfam
scp pterry@crane.unl.edu:/work/amundsen/pterry/hmm_pfam/Trinity.fasta.transdecoder.pep .
ls -al
## Q: what are m & g in 'm.106285' & 'g.106285'. Apparently **1st** appeared in Trinity.fasta.transdecoder.pep file ??????????????????????????????
## For highest scoring E-value in hmmsrchshortpep.out file, TRINITY_DN48137_c0_g1_i3|m.50031, can relate 1st domain in 3rd section alignment 181 to 463 to line 385075, 
>TRINITY_DN48137_c0_g1_i3|m.50031 TRINITY_DN48137_c0_g1_i3|g.50031  ORF TRINITY_DN48137_c0_g1_i3|g.50031 TRINITY_DN48137_c0_g1_i3|m.50031 type:3prime_partial len:810 (+) TRINITY_DN48137_c0_g1_i3:99-2525(+)
## Q: don't understand all in the prev. line ????????????????????
## Q: i3, i6, i2, i9, are these domains ???????? each domain from 181 to 462 or 3.  Appear to only be small differences between them ??????????????????
## found TRINITY_DN48137_c0_g1_i3|m.50031 on just one line in Trinity.fasta.transdecoder.pep file. 
## SO WHAT TO DO ?????????
## Should be able to take 'Sequence' colm from sec 2 of hmmsearch, do %in% to find the sec 2 hits from hmmsrchshortpep.out in Trinity.fasta.transdecoder.pep file, the rows want to build Stockholm MSA file with hmmalign.
## Q: or do I want to get just the 'domains' specified in the 3rd sec of hmmsrchshortpep.out for each of the 'hits' ??????????????
## a Q for Keenan ????????????????????????????????????
********TO DO*******
## Note: **still** need analyze scores in 'full', 'best 1 domain' as discussed p-21 to 27 of HMMER User's Guide.

12/24/16:
## TRY EXAMPLE AT:
http://stackoverflow.com/questions/21263636/how-to-read-fasta-into-dataframe-and-extract-subsequences-of-fasta-file-in-r

# created an rstudio project, 'pfam'
#fatodftest.R

fatodf_input.fasta
>NM_000016 700 200 234
ACATATTGGAGGCCGAAACAATGAGGCGTGATCAACTCAGTATATCAC
>NM_000775 700 124 236
CTAACCTCTCCCAGTGTGGAACCTCTATCTCATGAGAAAGCTGGGATGAG
>NM_003820 700 111 222
ATTTCCTCCTGCTGCCCGGGAGGTAACACCCTGGACCCCTGGAGTCTGCA


getwd()  ## /Users/bterry/macbook2016/keenanres16/Bdac/pfam dir
library("Biostrings")
#fastaFile <- readDNAStringSet("my.fasta")
fastaFile <- readDNAStringSet("fatodf_input.fasta")
seq_name = names(fastaFile)
class(seq_name)
seq_name
sequence = paste(fastaFile)
sequence
class(sequence)
df <- data.frame(seq_name, sequence)
df
# successful creating desired df

12/26/16:
## **Try** subset sequence colm of df using values in new colms 'start', 'end', and create new colm for these seqs.


12/27/16:
## next task, subset Trinity.fasta.transdecoder.pep file by the 908 tx hits in section 2 of hmmsrchshortpep.out. Get subset, of Trinity.fasta.transdecoder.pep, the 908 rows, and domain subsets if possible (Ck: Keenan, if what want ?????)
## 1st, need to convert fasta to df.
## 2nd task, shorten Trinity.fasta.transdecoder.pep fasta names to part before 1st space char.
## write.table ...
## work in fatodftest.R file
## So will create new file in this process, Trinity.fasta.transdecoder.pep.txt
## Sequences in colm 2 ***not*** accurate. Got ERROR from readDNAStringSet fcn, perhaps nonstandard sequence codes (~ 7 million of them) ????????

12/28/16:
Try use BBEdit, &/or pcfb book, see if can 'see' such characters in Trinity.fasta.transdecoder.pep file.
## created first5.pep
## next, p-21, pcfb book, 
## Find box, (>.*)
## replace box, 'a .'
## then, replace all
## Now, try read into R in RStudio, use fatodftest.R code file.
d <- read.delim("first5.pep", header=FALSE, col.names="seqs")
class(d)  ## a df
dim(d)
head(d)  ## each sequence not on same line ????????

12/29/16:
## try BBedit first5.pep so each seq on a single line, worked. 
## First box has \w(\r)\w. Replace box has 'nothing'. 
## To test with 1st 6 ref/seqs, first7.pep, in case '*' at end of seq works diff. There, no '*' at end. When do on real data file, will need be **spot** checking several seqs, make sure they same as in Trinity.fasta.transdecoder.pep file.
## first6.pep file, with '>' line to '.', and each seq on 1 line. 
## now, using fatodftest.R
## first6.pep placed in 6 elt char vector, good, 
## next, get the refs for these 6 into a character vector in R, and subset the references to the part before the 1st 'space' char.

12/29/16:

## skip trying to select out '>' lines in BBedit, by removing sequence lines, since don't know what to do with '*' in only some sequence lines ??????????
## instead, try grep from linux command line
#grep -c "^>" Trinity.fasta.transdecoder.pep  ## ***74489***
grep "^>" first6ref.pep > first6ref.out
cat first6ref.out  ## ok, what Expect
## next, read into R, remove all after 1st space, create character vector with the refs.
## done.
## finally create df, refSeqID_seq, looks ok.
## next, create 'real' df from Trinity.fasta.transdecoder.pep, expect 74489 rows. 

12/30/16:
## create vector of seqs in Trinity.fasta.transdecoder.pep, prepping for dataframe.
## starting wi Trinity.fasta.transdecoder.pep, copy to Trinity.fasta.transdecoder.copyseq.pep
## next convert '>' lines to '.'
## need check 'grep' & 'case sensitive'
## 'find' box: (>.*)
## 'replaceall' box: '.'  ## 74489 replacements
## then to put each serquence on 1 line
## 'find' box: \w(\r)\w
## 'replaceall' box: 'nothing'  ## 309012 replacements
grep -c "\." Trinity.fasta.transdecoder.copyseq.pep  ## 74489 as expect
wc Trinity.fasta.transdecoder.copyseq.pep
  **149924**  149924 20567382 Trinity.fasta.transdecoder.copyseq.pep
## Q: why not = 2*74489 = [1] **148978** lines ??????
## Q: TOO MANY LINES ?????????????????????????????????
## 854 **extra** seq lines ?????????????????
## Q: might some of seq lines be still on multiple lines ?????????????
## Q: need to ***CHECK*** ???????????????????
## Q: **Note**, in BBEdit, findall for ^\. gave 74489, & ^\w gave 74489
## Q: why 'wc' not getting 2*74489 ?????????????????????? 
## Q: to CHECK, try perhaps in for loop in R ?????????????????????????
## see if when get vecFullSeq from for loop, if have all seqs, & they agree with Trinity.fasta.transdecoder.copyseq.pep

## now, to R session, fatodftest.R, to create char vector of the seqs from Trinity.fasta.transdecoder.pep (after '>' to '.' & each seq on one line (tho with 'wc' result, unexplained, compared to '^\w' search ??????).

dseq <- read.delim("Trinity.fasta.transdecoder.copyseq.pep", header=FALSE, col.names="seqs", stringsAsFactors=FALSE)
class(dseq)  ## dataframe
dim(dseq)  ## ## [1] 149924      1  ## why not 2*74489 = [1] 148978 ??????????
head(dseq, n=6)  ## output looking as anticipated
tail(dseq)

12/31/16:
## **stop** this approach for moment since can't think of way it will find why 
> ctdot
[1] 74489
> ctword
[1] 75435
## **discrepancy** betw ctdot, ctword ?????????????????????
## see if python script, seqread.py, p-212, cpfb book can help ?????????????
## creatred python dir at /Users/bterry/macbook2016/keenanres16/Bdac/pfam/python
on Macbook
cp first6ref.pep to python dir, change name to first6ref.fta.
cd python
python seqread.py first6ref.fta

01/01/17:
##Try see ':'s in first6ref.fta in BBEdit.
## see 3 per reference name, so ':' put in by seqread.py wiii be 4th in a ref.  ## But check outpiut of seqread.py to verify.
## so test run seqread.py with first6ref.fta to see if can output to file.
python seqread_pmt.py first6ref.fta > first6ref.out
## first6ref.out has 4 ':'s per ref name, total 24 in 6 ref file, first6ref.fta.
## Test linux command line 'cut' command on first6ref.out,
cut -d: -f1,2,3,4 first6ref.out > first6ref.f1234.out
cut -d: -f5 first6ref.out > first6ref.f5.out
## note, a **space** at end each ref & a 'space' berfore each sequence in the outputs of 'cut'. Test eliminating using BBedit. **Worked** with 'space' in find window, 'nothing in 'replaceall' window.

## Now ready try seqread_pmt.py with input Trinity.fasta.transdecoder.pep
## cp Trinity.fasta.transdecoder.pep to python dir, change extension to '.fta', then run with seqread_pmt.py
python seqread_pmt.py Trinity.fasta.transdecoder.fta > Trinity.fasta.transdecoder.out
## now do cut on Trinity.fasta.transdecoder.out
cut -d: -f1,2,3,4 Trinity.fasta.transdecoder.out > Trinity.fasta.transdecoder.f1234.out
wc Trinity.fasta.transdecoder.f1234.out
   74489  670401 15166530 Trinity.fasta.transdecoder.f1234.out
cut -d: -f5 Trinity.fasta.transdecoder.out > Trinity.fasta.transdecoder.f5.out
wc Trinity.fasta.transdecoder.f5.out
   74489   74489 21109971 Trinity.fasta.transdecoder.f5.out

## then check in BBedit, for 'space' char in front of 'f5' seq file, to remove it (done), and examine if what expect is in row 1 & row 74489. Looks like seqs at line 1 & 74489 match, but careful, if try compare a seq which **crosses** 2 lines in fta (pep), BBedid search function does **not** report a match.

## ok, next task read in f1234, f5 files to R, convert to vectors, Need shorten refs to characters before 1st, create df with these two columns. Need shorten refs to characters before 1st 'space'. ... 908, then domains, need alifrom, ali to colms from hmmsrchshortpep.out

## for f5, used for loop to get seqs vector from dataframe read in (Q: is there a recommended way ??)
## for f1234, do a for loop, etc.
## check from linux command line, BBedit this written df file, Trinity.fasta.transdecoder.pep.df.txt.
wc Trinity.fasta.transdecoder.pep.df.txt
   74490  148980 16496269 Trinity.fasta.transdecoder.pep.df.txt
head -n 3 Trinity.fasta.transdecoder.pep.df.txt  ## 
**no** '*' end of seqs colm ???????
## but ***present*** in refSeqID_seq before it written to file Trinity.fasta.transdecoder.pep.df.txt **********************************
tail -n 3 Trinity.fasta.transdecoder.pep.df.txt
## Q: comparing refSeqID_seq inside R, 1st, 744789th (last) row, with Trinity.fasta.transdecoder.pep.df.txt 1st & last row, DISCREPANCIES ????

## TO DO, compare with Trinity.fasta.transdecoder.pep, see if at least the refSeqID_seq version is accurate ????????????????

01/02/16:

## write this df to file, a stopping point.
write.table(RefSeqID_seq, file="Trinity.fasta.transdecoder.pep.df.txt", quote=FALSE, sep="\t", row.names=FALSE, col.names=TRUE) 

philip-terry-2:pfam bterry$ head -n 3 Trinity.fasta.transdecoder.pep.df.txt
RefSeqID	seq
TRINITY_DN10001_c0_g1_i1|m.106285	MYRRSSHRKTSSDVDASAAANNASDNNNTNTTSHTMKRTSTAYVSDMKDTNMDAVNATMAADGSAHHTSSSRAGAVAGSTRKTRRRMSSVSSARRRGSHSSSSTSSSKAADRMHDSGVMSSSSNSKTSRRSSMRRRNTSTSSTDMTKVTATYNAGTAARAAAAANDRNRRHTRSDGSSRDDDKDNSGVDMTCASVRADSVTKKMDRAATTVSNDAASVRARVSRSWHHAASHVWRNVRKHVHVSAMGGGTGKMSGGNAADWKRMARATDARWKAGTAAYNGHTDSVYCCDNKATGSRDRTRVWDTYKCKVYGGNHRTANTMRRVSHASMNGTKVGNDYTVADYHDASCYDSMVTGSSDYTCVWDTGDYVMYRRGHAGVDVCDDKYSCSKDAMKVWDRKTGNCRTKGHRGVNAVRGNVSASGDGVAKWNTGVSKDSDRGAAVSDDAKYVAGGNDHVVYKDASTGVHSRVKHDGVRSDANGRVSGSYDSVSDYTGTYAVYKNWTTSWSAKSDYRRVVATSDGRTDGHNVGAVGK

philip-terry-2:pfam bterry$ tail -n 3 Trinity.fasta.transdecoder.pep.df.txt
TRINITY_DN9999_c0_g1_i1|m.75417	VNRAWAKHRSVNTGVVCGHAVWACVDTNRYNRRKSKDAKAAGVKMGNGAVGAYMGAGGMYYVGYSMMYMAGMHMGYMMMYMGGAVGAAGSNGKAARYA
TRINITY_DN9999_c0_g2_i1|m.75420	VNRAWAKHRSVNTGVVCGHAVWACVDTHRYNSSKSKDAKAAGVKMGNGAVGAYMGAGGMYYVGYSMMYMAGMHMGYMMMYMGGAVGAAGSNGKAARYA
TRINITY_DN99_c0_g2_i1|m.125359	MASASSSSVDGYRRTDAGTGSTSSHAWWRACAVAAAHGAKHVAWSSSTSATVSSDGRSSARHRRDGG

## Compare to Trinity.fasta.transdecoder.pep
1st ref, Seq

>TRINITY_DN10001_c0_g1_i1|m.106285 TRINITY_DN10001_c0_g1_i1|g.106285  ORF TRINITY_DN10001_c0_g1_i1|g.106285 TRINITY_DN10001_c0_g1_i1|m.106285 type:complete len:728 (+) TRINITY_DN10001_c0_g1_i1:361-2544(+)
MYRRQSILSHRPKTSSDVDAESAAAQNNAFSDNNNTNTTPIQPSPPHTMKRTISQTFPAP
YVSDMKDTNMLDAVNEATMAADGSAHHQQTSSFSRAFGAVAGSFTRQKTRRRMSSVSSPI
PAQRRRGSIHSLFESLPSSTSSQSKPAADQRMPLQHQDSGIPVFQMQQSQPSSSNSKTFS
PFRRLSSMRRRPNTSTSSTDMTKPVFTAPTYPNQALPGTAARQAAAAANQDRQNQLRREQ
EHTRSFLDGLIPSSRDDDLKDNESGVDMTCASPIVRADSVTEKKMIDPFQRLPAELATTV
LSNLDAASLVRAERVSRSWHEHAASPHVWRNVFLRKHEPEVHVSPAPIQMGGLGTGKMSG
GNPAPAQDWKRMFQARATIDARWKAGTPAAIYLNGHTDSVYCCQFDENKAITGSRDRTIR
VWDLQTYKCIKVYGGPNHRPTANTPPPMEERPERVISHASMNGTKVGNDIYTVPADYHDA
SILCLQYDSEIMVTGSSDYTCIVWDITGDEYVPMYRLRGHEAGVLDVCLDDKYIISCSKD
AMIKVWDRKTGNCLRTLKGHRGPVNAVQLRGNFLVSASGDGVAKLWNLETGVSIKDFPSE
DRGLAAVEFSDDAKYVLAGGNDHVVYKFDASTGELVHSRVKHDGLVRSLFLDAFNGRIVS
GSYDQSIQVSDYETGQTYAVYKNWTTSWILSAKSDYRRVVATSQDGRTLILDFGHNVPGA
ELLVGFK*

last ref/Seq (line 458936)
>TRINITY_DN99_c0_g2_i1|m.125359 TRINITY_DN99_c0_g2_i1|g.125359  ORF TRINITY_DN99_c0_g2_i1|g.125359 TRINITY_DN99_c0_g2_i1|m.125359 type:3prime_partial len:100 (+) TRINITY_DN99_c0_g2_i1:68-364(+)
MASPASSPSSVDGYRERTDLAGTLGSTSSHAPWWRQACAVAAAPPLPHPGAKEQQHPEPQ
VQAWSSPSPTSAPITVSSFDGRPSSAELRHPRRDQGGPP


## From refSeqID_seq dataframe in R
> head(refSeqID_seq, n=3)
                           refSeqID
1 TRINITY_DN10001_c0_g1_i1|m.106285
2 TRINITY_DN10001_c0_g2_i1|m.106290
3 TRINITY_DN10002_c0_g1_i1|m.106280
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       v_s
1 MYRRQSILSHRPKTSSDVDAESAAAQNNAFSDNNNTNTTPIQPSPPHTMKRTISQTFPAPYVSDMKDTNMLDAVNEATMAADGSAHHQQTSSFSRAFGAVAGSFTRQKTRRRMSSVSSPIPAQRRRGSIHSLFESLPSSTSSQSKPAADQRMPLQHQDSGIPVFQMQQSQPSSSNSKTFSPFRRLSSMRRRPNTSTSSTDMTKPVFTAPTYPNQALPGTAARQAAAAANQDRQNQLRREQEHTRSFLDGLIPSSRDDDLKDNESGVDMTCASPIVRADSVTEKKMIDPFQRLPAELATTVLSNLDAASLVRAERVSRSWHEHAASPHVWRNVFLRKHEPEVHVSPAPIQMGGLGTGKMSGGNPAPAQDWKRMFQARATIDARWKAGTPAAIYLNGHTDSVYCCQFDENKAITGSRDRTIRVWDLQTYKCIKVYGGPNHRPTANTPPPMEERPERVISHASMNGTKVGNDIYTVPADYHDASILCLQYDSEIMVTGSSDYTCIVWDITGDEYVPMYRLRGHEAGVLDVCLDDKYIISCSKDAMIKVWDRKTGNCLRTLKGHRGPVNAVQLRGNFLVSASGDGVAKLWNLETGVSIKDFPSEDRGLAAVEFSDDAKYVLAGGNDHVVYKFDASTGELVHSRVKHDGLVRSLFLDAFNGRIVSGSYDQSIQVSDYETGQTYAVYKNWTTSWILSAKSDYRRVVATSQDGRTLILDFGHNVPGAELLVGFK*

> tail(refSeqID_seq, n=3)
                             refSeqID
74487 TRINITY_DN9999_c0_g1_i1|m.75417
74488 TRINITY_DN9999_c0_g2_i1|m.75420
74489  TRINITY_DN99_c0_g2_i1|m.125359
                                                                                                                                                            v_s
74487 VNRAWAEKPHRISVNLTGVVCQFFGLFLHFALFVWACVDTNRYNRRKISKDAEKLAAGIVEKMIGNGAIVPPPGQAYMQPGAGQGMYYQVPPQGYSMQPMYMQPAPGQQQQFMHPQQMGQQQYMMPMQYPMGQQGPAVGAAGPSNGKAARYA*
74488 VNRAWAEKPHRISVNLTGVVCQFFGLFLHFALFVWACVDTHRYNSSKISKDAEKLAAGIVEKMIGNGAIVPPPGQAYMQPGAGQGMYYQVPPQGYSMQPMYMQPAPGQQQQFMHPQQMGQQQYMMPMQYPMGQQGPAVGAAGPSNGKAARYA*
74489                                                       MASPASSPSSVDGYRERTDLAGTLGSTSSHAPWWRQACAVAAAPPLPHPGAKEQQHPEPQVQAWSSPSPTSAPITVSSFDGRPSSAELRHPRRDQGGPP

## LOOKS like the refSeqID_seq version in R is ***accurate***, so WHAT TO THINK OF THE STEP OF ***WRITING*** refSeqID_seq to Trinity.fasta.transdecoder.pep.df.txt file, i.e., not accurate in this file ???????????????????????

## Q: can I do next step to subset from Trinity.fasta.transdecoder.pep the 908 hits from hmmsearch output (hmmsrchshortpep.out), then subset those 908 to domains, from fields 'alifrom, ali to' colms from hmmsrchshortpep.out. Without being able to reliably save the dataframe to a file? Note: saved python results, not much to regenerate dataframe from them.

STOPPED

## next, try subset the 908 hmmsearch hits reported in hmmsrchshortpep.out.
## Perhaps, make copy of hmmsrchshortpep.out, 
hmmsrchshortpepcopy.out

## then in BBEdit, in sec 2, select lines 15 thru 924 (total 908 lines, remove dashed line (16), save as hmmsrchshortpepsec2.out
## ***Still*** need check what doc. indicated needed to check for the 'scores' betw. 'full seq' & 'best 1 domain' ???????
## refer 12/23/16 above, following 5 (last 5) have 'bias' same order of magnitude as the sequence bit score. Thus need remove these from sec2

TRINITY_DN45340_c0_g1_i1|m.120072   TRINITY_DN45340_c0_g1_i1|g.12007
TRINITY_DN47593_c0_g1_i2|m.54878    TRINITY_DN47593_c0_g1_i2|g.54878
TRINITY_DN47466_c0_g1_i1|m.146536   TRINITY_DN47466_c0_g1_i1|g.14653
TRINITY_DN45259_c1_g1_i1|m.66031    TRINITY_DN45259_c1_g1_i1|g.66031
TRINITY_DN45259_c1_g1_i2|m.66034    TRINITY_DN45259_c1_g1_i2|g.66034

## **YET TO DO**

## 702-4 rows, possible multidomain remote homolog (Q: what to do with these ????????????????????????????)

## Q: defn (<< 1) => ***where*** to stop including rows ??????????????
## Q: hmmsearch keeping all 'full' E-score rows < 10, but this criterion throwing many before that.

## #doms, should be about the **same** (Q: is 2 vs 1 similar enough ???????
## down to row 791, 'about same'

## Note row 791, --- inclusion threshold ------, Q: is ***this*** where should not include any more rows ?????????????????????????????????

## ***3rd*** output section: 
## The ! or ? symbol indicates whether this domain does or does not satisfy **both** per-sequence and per-domain inclusion thresholds.

## If the independent E-value is significant (<< 1), that means that even this single domain by itself is such a strong hit that it suffices to identify the sequence as a **significant** homolog with respect to the size of the entire original database search. You can be confident that this is a homologous domain.

## perhaps grep all the '  1  !' lines as ones 'to include' ???????????? But since tx name not in the line, may neet grep all the '>>' lines in sec3 also. Will need connect these names wi the '  1  !' lines to include. May have to connect with section 2 rows plan to 'include' ??????????????????

## The next **four** columns give the endpoints of the reported local alignment with respect to both the query model (“hmm from” and “hmm to”) and the target sequence (“ali from” and “ali to”).
## if plan to select 'domain', then will need associate (“ali from” and “ali to”) with 'hit' name ??????????????????

## summary Statistics
## Q: 907, 'over threshold', ***different*** from preceding criteria ???????????

01/03/17:
*****************************************
# slip a save to ***github*** in here
cd ~/planets
git status
git add BdactyloidesthruGSEA081615.txt
git commit -m "update 01/03/17 BdactyloidesthruGSEA081615.txt from macbook"
git status
git push origin master
# git remote -v
## so updated BdactyloidesthruGSEA081615.txt to github, planets repo.
******************************************

## next task, check all **indept** E-valuesin sec3, decide his criterion which hits to retain. Looks like grep of '  1  ! rows would make easier.
## perhaps try in BBEdit with hmmsrchshortpepcopy.out file. Found 770. Go ahead, do linux command line grep, place in file hmmsrchshortpepcopy.1!.out
cd /Users/bterry/macbook2016/keenanres16/Bdac/pfam

grep "^   1 \!.*" hmmsrchshortpepcopy.out > hmmsrchshortpepcopy.1bang.out
## 770 records

## but wait, want to relate "^   1 \!.*" rows to tx  names, so perhaps grep "   1", get all these lines, then gep all the ">>" lines, associate these in dataframe, then subset the "^   1 \!.*" rows.

grep "^   1.*" hmmsrchshortpepcopy.out > hmmsrchshortpepcopy.1.all.out
     907   14512   92514 hmmsrchshortpepcopy.1.all.out

grep "^>>.*" hmmsrchshortpepcopy.out > hmmsrchshortpepcopy.sec3names.out
     907    5442  109747 hmmsrchshortpepcopy.sec3names.out

## now need decide on a subset of these rows from sec3. create a df of just these tx names. Then subset prev df refSeqID_seq from Trinity.fasta.transdecoder.pep produced thru python using this sec 3 subset.
## SO next, NEED DECIDE ON A CRITERIA TO SELECT THIS SUBSET ????????

## so go thru the various criteria, come up with a way to decide on the subset of hits want to apply to df refSeqID_seq ????????

01/08/16:
## list of criteria

STOPPED

## **sec2** of hmmsearch Output
## note, 908 records in sec2

## Hmmer User's Guide, p-21-27, discussing 'hmmsearch' output
## refer line 8203 above, from 12/23/16:

##(1)
## 3rd colm, 'bias'. The only time you really need to pay attention to the bias value is when it’s **large**, on the same order of magnitude as the sequence bit score.
## so, read into R, hmmsrchshortpepsec2.out,  but remove line ------ inclusion threshold ------, line 791, so ****790**** hits above this line remain, this file a new  name, hmmsrchshortpepsec2minusinclline.out. So, 907 hits plus header.

01/09-10/16:
## Then, read into R, use fatoftest.R to code.
sec2df <- read.delim("hmmsrchshortpepsec2minusinclline.out", header=TRUE, sep="", stringsAsFactors=FALSE)

## then compare 'full' score, 'full' bias colms ('assume' don't need do for 'best 1 domain' ?????????????)
## would like an appropriate output to quickly see if bias is **large**.
sec2df["biasprob"] <- integer(length(sec2df$score))
dim(sec2df)
head(sec2df)
diffvec <- sec2df$score - sec2df$bias
head(diffvec)
length(diffvec)
for(i in 1:length(diffvec) {
  if(diffvec(i) < 10) {
    sec2df(i)$biasprob <- 1
  }
}


01/11/17:
## and 398, 399 may not be correct, so go ***spot check*** some
## diffvec values, say 100, 200, ... 900, see if their difference
## is correct. ????????????????????????????????
## also, for NA in row 400, check if can find that row in Trinity.fasta.transdecoder.pep file, correct its name in hmmsrchshortpepsec2minusinclline.out ('sequence' name probably ok, 'description' name has 2 spaces then a zero after name) ??????????????

## so, some ambiguity after row 401 in file 
## hmmsrchshortpepsec2minusinclline.out
## it the row with extra zero in DESCRIPTION
## column, TRINITY_DN916_c0_g2_i1|g.5414  O

01/12-13/17:
## WHAT TO DO ????????
## perhaps, edit line 400 in his file
## last zero & preceding two 'spaces' ??????)
## do from copy of hmmsrchshortpepsec2minusinclline.out
## hmmsrchshortpepsec2minusinclline.fix.out (fixed line 400)

## perhaps read.delim this file, process so can do diffvec.
## then redo diffvec <- sec2df$score - sec2df$bias
## & see if diffvec now correct, no row 400 'NA'
## now, 907 elements as expected, no NA's
## now can proceed with determination of rows with bias
## near 'score' (see 01/09-10/17 above)
## put into fatodftest.R, date 01/12/17
## count rows with 1's, 0's
## count the '1's, the rows with bias too close to the score.
## subset all rows wi biasprob == 1
## result:  gave ***6*** rows, row 898 being the 1st, 907 the last
## with 'bias' too close to 'score'.

##(2)
## So ***operationally***, 
if both E-values are significant (<< 1), the sequence is likely to be homologous to your query.

## So, use file hmmsrchshortpepsec2minusinclline.fix.out, find rows where both colms 'full' or 'best 1 domain' E-vaues are say less than .0001 ***???????***
sec2dffix_crit2 <- sec2dffix[sec2dffix$E.value < 0.0001 & sec2dffix$E.value.1 < 0.0001, ]
dim(sec2dffix_crit2)  ## [1] 711  11
## ok, 711 rows by criterion (2)

##01/14/17:
##(3), exp & N
## The two columns headed #doms are two different estimates of the number of distinct domains that the target sequence contains. ... These two numbers should be about the **same** (***how*** close ??????)
sec2dffix_crit3 <- sec2dffix[sec2dffix$exp <= 1.5*sec2dffix$N, ]
dim(sec2dffix_crit3)  ## [1] 763  11
## Q: choice of '1.5 ???
## will want to ***check*** if final set of hits after all the criteria is a subset of these 763 domains ????????????????????????

## ***sec 3*** of hmmsearch Output
## see line 8218 above

##(4)
## The ! or ? symbol indicates whether this domain does or does not satisfy **both** per-sequence and per-domain inclusion thresholds.
## all domains
hmmsrchshortpepcopy.1.all.out  ## 907 'domains', as sec2

01/15/17:
##(5)
## Operationally:
## If the **independent** E-value is significant (<< 1), that means that even this single domain by itself is such a strong hit that it suffices to identify the sequence as a **significant** homolog with respect to the size of the entire original database search. You can be confident that this is a homologous domain.

## so, see how many of the 5 criteria, can do by computer ????
## looks like need read into R the ....1.all.out file to calc how many rows have 'independent E-value' less than say 0.0001 ??????????????

## perhaps read this file into R, do 
## NOTE: addl random spurious characters in file ??????????????????

sec3df1.all <- read.delim("hmmsrchshortpepcopysec3.1.all.out", header=FALSE, sep="",  stringsAsFactors=FALSE)
dim(sec3df1.all) ## [1] 907  16

sec3df1.all.4col <- sec3df1.all[, -c(1, 3:5, 7:9, 12:16)]
dim(sec3df1.all.4col)  ## [1] 907   4
head(sec3df1.all.4col, n=3)
#data_frame <- setNames(data_frame, c("premium","change","newprice"))
sec3df1.all.4col <- setNames(sec3df1.all.4col, c("bang", "i-Evalue", "alifrom", "alito"))
head(sec3df1.all.4col, n=3)

## looks ready to subset rows by values less than 0.0001 in i-Evalue colm.

# for completeness, see if subset by '!' matches # rows found by grep at linux command line.
sec3df1.all.4col_critbang <- sec3df1.all.4col[sec3df1.all.4col$bang == "!", ]
dim(sec3df1.all.4col_critbang)  ## [1] 770   4, agrees wi linux command grep 

01/16/17:
***********************************************************
**TO DO**, (see pencil version)
Summary table for the 5 criteria (hmmsrchshortpepsec2minusinclline.fix.out);
## note, transferred pencil notes on 02/19/17, so other possible file (forget which ??)
1) 898 of 907 'pass bias score'
2) both E-values (E.value, E.value.1) < .0001, 711 rows pass, see line 8617)
3) exp & N, 763 rows pass, see p-86239 
4) sec 3, '|  !', hmmsrchshortpepcopy.1bang.out, 770 rows, see p-8536
5) i-Evalue criterion, test result later, see line 9011, 769 rows pass.
**************************************************

## ok, prepare df & fasta file of 706 hits for hmmalign step.

## have refSeqID_seq df from Trinity.fasta.transdecoder.pep file, 74489 rows, has shortened names field, just part before 1st 'space'.
## have sec3df1.all.4col df, 907 rows
## To Do: get sec3df1.all.names df from hmmsrchshortpepcopy.sec3names.out file.
## in BBedit, remove '>> ' from LHS of file, rename file to hmmsrchshortpepcopy.sec3names.LHS.out
## Search/Find box = (>> ), replace box is empty, click 'replace all'

## Read into R

d_r_sec3 <- read.delim("hmmsrchshortpepcopy.sec3names.LHS.out", header=FALSE, col.names="refs", stringsAsFactors=FALSE)   
class(d_r_sec3)  ## dataframe
dim(d_r_sec3)  ## [1] 907     1
head(d_r_sec3, n=3)  ## output looking as anticipated
tail(d_r_sec3, n=3)
v_r_sec3 <- vector(mode="character", length=907)
class(v_r_sec3)
head(v_r_sec3, n=3)
for(i in 1:907) { 
  v_r_sec3[i] <- d_r_sec3[i,1]
}
class(v_r_sec3)
head(v_r_sec3, n=3)
tail(v_r_sec3, n=3)
length(v_r_sec3)  ## [1] 907

## remove part of name past 1st 'space'. (see line 211, fatodfest.R file)
#here try remove all after 1st space for RefS
refSeqID_sec3 <- sub(" .*", "", v_r_sec3)
head(refSeqID_sec3)
## ok

## create df of sec3df1.all.4col plus refSeqID_sec3, total 907 rows.
##my.dataframe["new.col"] <- a.vector
sec3df1.all.5col <- sec3df1.all.4col
sec3df1.all.5col["refs"] <- refSeqID_sec3
dim(sec3df1.all.5col)  ## ## [1] 907   5
head(sec3df1.all.5col, n=3)
## looks ok

01/17/17:
## subset this dataframe to the 706 rows meeting crit 5. Call it sec3df1.all.5col.names.crit5 (see line 373, fatodftest.R)
sec3df1.all.5col.names.crit5 <- sec3df1.all.5col[sec3df1.all.5col$i_Evalue < 0.0001, ]
dim(sec3df1.all.5col.names.crit5)  ## [1] 706   4

## now subset refSeqID_seq df to these 706 rows wi innerjoin to sec3df1.all.5col.names.crit5
## see http://stackoverflow.com/questions/1299871/how-to-join-merge-data-frames-inner-outer-left-right
## Q: does join field need to be numeric? p-222, vbuffalo, apparently not?
## merge(df1, df2, by = "CustomerId") 
## 1st, need change colm name refs to refSeqID in sec3df1.all.5col.names.crit5
#colnames(X)[2] <- "superduper"
colnames(sec3df1.all.5col.names.crit5)[5] <- "refSeqID"
head(sec3df1.all.5col.names.crit5)
## ok
merged706hits <- merge(sec3df1.all.5col.names.crit5, refSeqID_seq, by = "refSeqID")
class(merged706hits)
dim(merged706hits)
head(merged706hits, n=3)
## ok
## next, create a colm with the 'domain' for this hit, specified by colms alifrom & alito.

## substr(x,start,stop)
merged706hits$domain <- substr(merged706hits$v_s, merged706hits$alifrom, merged706hits$alito)
dim(merged706hits)
head(merged706hits)
tail(merged706hits)

## ***Q:*** in v_s colm, some sequences only start after bunch of 'space' characters ??????????????????????????

## Q: after create fasta file, will need to check how seqs displayed ?????????????????????????
## prepare fasta file from a dataframe file, for hmmalign, using seqRFLP package. See http://stackoverflow.com/questions/23374100/convert-table-into-fasta-in-r

## convert df to fasta file, WORK OUT HOW ?????????????
install.packages("seqRFLP")
library("seqRFLP")
names <- c("seq1","seq2","seq3","seq4")
sequences<-c("EPTFYQNPQFSVTLDKR","SLLEDPCYIGLR","YEVLESVQNYDTGVAK","VLGALDLGDNYR")
df <- data.frame(names,sequences)
df
df.fasta = dataframe2fas(df, file="df.fasta")
## Q: NOT on separate lines ????????????????? Can I use this output ????????????

######## fataframe2fas() example
dd <- dataframe2fas(paste("AAACCCTTAAAAAAATTA
TTTTCTATTGGTTTCTTGGGGGGGTT", 1:10, sep = ""))
dd
## Q: would have to set up input data to use ???????????
## 

## Another website, http://stackoverflow.com/questions/23374100/convert-table-into-fasta-in-r
col1 <- c("seq1", "seq2")
col2 <- c("ATCGATCGATCG", "GCCATGCCATTG")
dftest <- data.frame(col1, col2)
dftest
X <- dftest
Xfasta <- character(nrow(X) * 2)
Xfasta
Xfasta[c(TRUE, FALSE)] <- paste0(">", X$col1)
Xfasta
Xfasta[c(FALSE, TRUE)] <- as.character(X$col2)
## Q: NOW putting in sequences as example expect ???????????????
writeLines(Xfasta, "filename.fasta")  ## looks ok.

01/18/17:
## so, ready, try create fasta from refSeqID & domain columns of merged706hits df **after** remove all columns but these two.
colnames(merged706hits)
## to do, remove columns 2 thru 6
#sec3df1.all.4col <- sec3df1.all[, -c(1, 3:5, 7:9, 12:16)]
merged706hits2col <- merged706hits[, -c(2:6)]
dim(merged706hits2col)
head(merged706hits2col)
## ok
merged706hits2colfasta <- character(nrow(merged706hits2col) * 2)
head(merged706hits2colfasta, n=3)
merged706hits2colfasta[c(TRUE, FALSE)] <- paste0(">", merged706hits2col$refSeqID)
head(merged706hits2colfasta, n=3)
merged706hits2colfasta[c(FALSE, TRUE)] <- as.character(merged706hits2col$domain)
head(merged706hits2colfasta, n=3)
writeLines(merged706hits2colfasta, "merged706hits2col.fasta")  ## looks ok.

01/19/17:
## **TO DO**: some checking on content of merged706hits2col.fasta file, **then** on to 'hmmalign'
## to do: scp merged706hits2col.fasta to crane
cd /Users/bterry/macbook2016/keenanres16/Bdac/pfam
## note, ran hmmsearch on crane in /work/amundsen/pterry/hmm_pfam
## so, 
scp merged706hits2col.fasta pterry@crane.unl.edu:/work/amundsen/pterry/hmm_pfam/

## see line 8174
ssh -Y pterry@crane.unl.edu 
# Rrq096mN 
cd /work/amundsen/pterry/hmm_pfam
srun --pty --ntasks-per-node=4 --mem 4gb --qos=short $SHELL
module load compiler/gcc/4.8 openmpi/1.8 hmmer

##hmmsearch NB-ARC.hmm Trinity.fasta.transdecoder.pep > hmmsrchshortpep.out
##less hmmsrchshortpep.out
##wc hmmsrchshortpep.out
##   20512  119872 1735266 hmmsrchshortpep.out

cd /work/amundsen/pterry/hmm_pfam
hmmalign NB-ARC.hmm merged706hits2col.fasta > hmmalignmerged706.out
exit
-rw-r--r--  1 pterry amundsen   1233031 Jan 19 11:04 hmmalignmerged706.out

wc hmmalignmerged706.out  ##    5662   16972 1233031 hmmalignmerged706.out
less hmmalignmerged706.out
## now what to do with this output ????????, run hmmBuild
## perhaps scp back to macbook so can 'examine' the file a bit.
logout
cd /Users/bterry/macbook2016/keenanres16/Bdac/pfam
scp pterry@crane.unl.edu:/work/amundsen/pterry/hmm_pfam/hmmalignmerged706.out .
ls -al
-rw-r--r--   1 bterry  staff   1233031 Jan 19 11:23 hmmalignmerged706.out

ssh -Y pterry@crane.unl.edu 
# Rrq096mN 
cd /work/amundsen/pterry/hmm_pfam
mv hmmalignmerged706.out hmmalignmerged706.sto

## refer: p-20, HMMER User's Guide
## may need change extension to 'hmmalignmerged706.sto'???? Done. 

srun --pty --ntasks-per-node=4 --mem 4gb --qos=short $SHELL
module load compiler/gcc/4.8 openmpi/1.8 hmmer
cd /work/amundsen/pterry/hmm_pfam

hmmbuild NB-ARC.hmm hmmalignmerged706.sto > NB-ARC_TrinityBdac.hmm
ls -al
-rw-r--r--  1 pterry amundsen       763 Jan 19 21:55 NB-ARC_TrinityBdac.hmm
## much smaller than 
## is this output file name ok ???????????
much less NB-ARC_TrinityBdac.hmm than NB-ARC.hmm ?????????????????
-rw-r--r--  1 pterry amundsen    110770 Jan 19 21:55 NB-ARC.hmm
exit
less NB-ARC_TrinityBdac.hmm
## NOTE: this file 'sort of some summary file' (????????????), see p-20, HMMER User's Guide. Q: anything to note in this 'summary' ??????????????
## *****NOTE*****: new hmm saved **as** NB-ARC.hmm.
-rw-r--r--  1 pterry amundsen    110770 Jan 19 21:55 NB-ARC.hmm
## see p-21, HMMER User's Guide !!!!!!!!!!!!!!!!!!!!!!!!!!
less NB-ARC.hmm

STOPPED
01/20/17:
## now, new hmmsearch of Trinity.fasta.transdecoder.pep (from Trunity.fasta ??) file with 'new' NB-ARC.hmm
## ***Ask*** about new hmmsearch ??????????????????????????

ssh -Y pterry@crane.unl.edu 
# Rrq096mN 
cd /work/amundsen/pterry/hmm_pfam
srun --pty --ntasks-per-node=4 --mem 4gb --qos=short $SHELL
module load compiler/gcc/4.8 openmpi/1.8 hmmer
cd /work/amundsen/pterry/hmm_pfam

hmmsearch NB-ARC.hmm Trinity.fasta.transdecoder.pep > hmmsrchshortpeprefined2ndtry.out
ls -al
exit
less hmmsrchshortpeprefined2ndtry.out
wc hmmsrchshortpeprefined2ndtry.out
  20654  111756 1719995 hmmsrchshortpeprefined2ndtry.out
## next, refer when ran hmmsearch above for how the work with hmmsrchshortpeprefined2ndtry.out (line 8191 above)
scp to macbook, BBedit, etc.

cd /Users/bterry/macbook2016/keenanres16/Bdac/pfam
scp pterry@crane.unl.edu:/work/amundsen/pterry/hmm_pfam/hmmsrchshortpeprefined2ndtry.out .
ls -al

01/23/17:
## github saved (see 01/03/17) BdactyloidesthruGSEA081615.txt

## Then what, search output file hits wi **blastp** ????????????
## identify/relate the tx names of hits ???????????????

01/25/17:
## ala Bryant et al., 2017, Cell RFeports 18, 762 (new Trinotate paper), p-773, '... comprehensive protein database formed by **merging** (HOW??) Swiss-
Prot (Boeckmann et al., 2005) with UniRef90 (UniProt Consortium, 2015) protein
databases downloaded from UniProt ...'.
## TO test, dnload (www.uniprot.org/), UniProkKB, (unprot-all.fasta.gz, 553,474, dnloads ~ 4 min, 113.9MB) & UniRef (uniref-all.fasta.gz, 49,122,202. Q: after ~25 min, *only* **.gz.part** file in 'download' dir, 158.9MB ????????), to pfam/uniprot dir., examine? 
## Q: ***what to do*** ??????????????????????
gunzip uniprot-all.fasta.gz
-rw-r--r--   1 bterry  staff   255M Jan 25 22:59 uniprot-all.fasta
wc -l uniprot-all.fasta 
 4131225 uniprot-all.fasta
## Note: sequence this fasta file, seq split into 60 char lines ????????

01/26/17:
## Talked to Adam on getting uniref90.fasta.gz file downloaded.

philip-terry-2:uniprot bterry$ curl -O -C - ftp://ftp.uniprot.org/pub/databases/uniprot/current_release/uniref/uniref90/uniref90.fasta.gz
** Resuming transfer from byte position 345661440
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
 65 10.3G   65 6934M    0     0   447k      0  6:44:42  4:24:16  2:20:26     0curl: (56) Recv failure: Network is down
## looks like when restarted this 'curl' session at house, unable to finish?
## TO DO: Go check with him tomorrow, try get it to 'crane' where plan to use anyway. Q: still quetion, whether to upload hmmsearch hits to www.uniprot.org, blast them on that site?

01/27/17:
Completed dnload of 
-rw-r--r--  1 bterry  staff    11G Jan 27 13:14 uniref90.fasta.gz
Expanded it
-rw-r--r--  1 bterry  staff    21G Jan 27 13:14 uniref90.fasta

## So like to get uniref90.fasta and 
-rw-r--r--  1 bterry  staff   255M Jan 25 22:59 uniprot-all.fasta
on Crane, so can do blastp.
Waiting till Mon, see if Adam, JJ want to put one or both of these there? Else I will wget, or curl them to crane?

## mean time, I need to prepare the query fasta file from the 2nd hnnsearch output, hmmsrchshortpeprefined2ndtry.out, **crit 5** in sec 3.


## So, TO DO:

*****************************************
ref, line 8644 above, 01/03/17:

01/29/17:
## preparing 'query' for blastp vs uniprotKB, uniRef90 (refer Bryant et al., Cell Reports 18, 762 2017), p-773.

## need create two files from sec 3 of hmmsrchshortpeprefined2ndtry.out

grep "^   1.*" hmmsrchshortpeprefined2ndtry.out > hmmsrchshortpeprefined2ndtry.1.all.out
-rw-r--r--   1 bterry  staff    91K Jan 29 10:58 hmmsrchshortpeprefined2ndtry.1.all.out
wc hmmsrchshortpeprefined2ndtry.1.all.out
     913   14608   93126 hmmsrchshortpeprefined2ndtry.1.all.out

grep "^>>.*" hmmsrchshortpeprefined2ndtry.out > hmmsrchshortpeprefined2ndtry.sec3names.out
-rw-r--r--   1 bterry  staff   108K Jan 29 11:18 hmmsrchshortpeprefined2ndtry.sec3names.out
wc hmmsrchshortpeprefined2ndtry.sec3names.out
     913    5478  110473 hmmsrchshortpeprefined2ndtry.sec3names.out

## upgrade rstudio to 
RStudio 1.0.136 - Mac OS X 10.6+ (64-bit) 	71.2 MB 	2016-12-21 	12d6d6ade0203a2fcef6fe3dea65c1ae
## 12d6d6ade0203a2fcef6fe3dea65c1ae, so matches

## read in hmmsrchshortpeprefined2ndtry.1.all.out

## see line 8653 (361, crit 5)
sec3df.2ndtry1.all <- read.delim("hmmsrchshortpeprefined2ndtry.1.all.out", header=FALSE, sep="",  stringsAsFactors=FALSE)
dim(sec3df.2ndtry1.all) ## [1] 913  16, as expect.
head(sec3df.2ndtry1.all, n=3)

## ref: line 8656 (366, fatodftest.R)
sec3df.2ndtry.1.all.4col <- sec3df.2ndtry1.all[, -c(1, 3:5, 7:9, 12:16)]
dim(sec3df.2ndtry.1.all.4col)  ## [1] 913   4
head(sec3df.2ndtry.1.all.4col, n=3)
#data_frame <- setNames(data_frame, c("premium","change","newprice"))
sec3df.2ndtry.1.all.4col <- setNames(sec3df.2ndtry.1.all.4col, c("bang", "i-Evalue", "alifrom", "alito"))
head(sec3df.2ndtry.1.all.4col, n=3)

## ref, line 8680
## To Do: get sec3df.2ndtry.1.all.names df from hmmsrchshortpeprefined2ndtry.sec3names.out file.
## in BBedit, remove '>> ' from LHS of file, rename file to hmmsrchshortpeprefined2ndtry.sec3names.LHS.out
## Search/Find box = (>> ), replace box is empty, click 'replace all'

## from line 8686 (from line 381-400 -> line 472)
d_r_sec3 <- read.delim("hmmsrchshortpeprefined2ndtry.sec3names.LHS.out", header=FALSE, col.names="refs", stringsAsFactors=FALSE)   
class(d_r_sec3)  ## dataframe
dim(d_r_sec3)  ## [1] 913     1
head(d_r_sec3, n=3)  ## output looking as anticipated
tail(d_r_sec3, n=3)
v_r_sec3 <- vector(mode="character", length=907)
class(v_r_sec3)
head(v_r_sec3, n=3)
for(i in 1:913) { 
  v_r_sec3[i] <- d_r_sec3[i,1]
}
class(v_r_sec3)
head(v_r_sec3, n=3)
tail(v_r_sec3, n=3)
length(v_r_sec3)  ## [1] 913

## remove part of name past 1st 'space'. (see line 211, fatodfest.R file)
#here try remove all after 1st space for RefS
refSeqID_sec3 <- sub(" .*", "", v_r_sec3)
head(refSeqID_sec3)
## ok

## see line 8708
## create df of sec3df.2ndtry.1.all.4col plus refSeqID_sec3, total 913 rows.
## create df of sec3df.2ndtry.1.all.4col plus refSeqID_sec3, total 913 rows.
##my.dataframe["new.col"] <- a.vector
sec3df.2ndtry.1.all.5col <- sec3df.2ndtry.1.all.4col
sec3df.2ndtry.1.all.5col["refs"] <- refSeqID_sec3
dim(sec3df.2ndtry.1.all.5col)  ## ## [1] 913   5
head(sec3df.2ndtry.1.all.5col, n=3)
## looks ok

## refer line 410-417, fatodftest.R, subset df on crit 5
##01/17/17:
## subset this dataframe to the 706 rows meeting crit 5.
sec3df1.2ndtry.all.5col.names.crit5 <- sec3df.2ndtry.1.all.5col[sec3df.2ndtry.1.all.5col$i_Evalue < 0.0001, ]
dim(sec3df1.2ndtry.all.5col.names.crit5)  ## [1] 769   5
head(sec3df1.2ndtry.all.5col.names.crit5, n=3)
## need change colm name refs to refSeqID in sec3df1.all.5col.names.crit5
colnames(sec3df1.2ndtry.all.5col.names.crit5)[5] <- "refSeqID"
head(sec3df1.2ndtry.all.5col.names.crit5)
## ok

## now subset refSeqID_seq df to these 769 rows wi innerjoin to sec3df1.all.5col.names.crit5

## 1st, need regenerate refSeqID_seq df (lines 174-214, fatodftest.R)

01/30/17:
## to accomplish, copy lines 175 thru 219 from fatodftest.R to 01/30/17 in fatodftest.R.
## done, (lines 516 561, fatodftest.R)

## refer line 8730 (or lines 419-429, 442-456, fatodftest.R)
merged706hits <- merge(sec3df1.all.5col.names.crit5, refSeqID_seq, by = "refSeqID")
class(merged706hits)
dim(merged706hits)
head(merged706hits, n=3)
## ok
## next, create a colm with the 'domain' for this hit, specified by colms alifrom & alito.

## substr(x,start,stop)
merged706hits$domain <- substr(merged706hits$v_s, merged706hits$alifrom, merged706hits$alito)
dim(merged706hits)
head(merged706hits)
tail(merged706hits)

## then see lines 442-456, fatodftest.R for rest.

##  'query' file, merged769hits2col.fasta, for blastp vs uniprotKB, uniRef90 (refer Bryant et al., Cell Reports 18, 762 2017), p-773.

01/31/17:
## prepare to blastp (E <= 1e-5) NB-ARC derived hits originally from Trinity.fasta, in merged769hits2col.fasta file against uniprotKB, & uniRef90.
## get the two files to crane (HCC).
#philip-terry-2:uniprot bterry$ curl -O -C - ftp://ftp.uniprot.org/pub/databases/uniprot/current_release/uniref/uniref90/uniref90.fasta.gz
## Think Adam wget this file to my crane work dir. To check,
ssh -Y pterry@crane.unl.edu 
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo/95TUPsubset
cd /work/amundsen/pterry
ls -lh  ## ok, uniref90 file there.
-rw-r--r--  1 pterry amundsen  11G Jan 27 13:39 uniref90.fasta.gz
## tried to dnload from ftp site the uniprotKB. When dnloaded what thought might be the site, 1st ref. line in fasta file did **not** match 1st ref line in what downloaded from website gui (553474 whatever, reviewed version ????, http://www.uniprot.org/uniprot/?query=*&fil=reviewed%3Ayes)
## Ck keena, JJ, why no match ??????????????????????????
## so just scp the uniprot-all.fasta over to crane from macbook.

cd /Users/bterry/macbook2016/keenanres16/Bdac/pfam/uniprot
ls -lh
scp uniprot-all.fasta pterry@crane.unl.edu:/work/amundsen/pterry/hmm_pfam/
uniprot-all.fasta                                   51%  133MB   0.0KB/s - stalled -Write failed: Broken pipe
lost connection
## Now what, perhaps try from on campus ?????????????

## 02/01/17:, tried on campus, **completed** in 1:31 min. **To do**, check same number bytes on macbook, crane for this file.

ssh -Y pterry@crane.unl.edu 
# Rrq096mN 
cd /work/amundsen/pterry
ls -lh
mv uniref90.fasta.gz hmm_pfam

02/01/17:
ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry/hmm_pfam/
ls -al  ## uniprot-all.fasta number bytes *match* that on macbook from which scp came.
mkdir blastpuniprotKB
mv uniprot-all.fasta blastpuniprotKB
cd blastpuniprotKB
ls -lh
## now, ready run blastp from *slurm*, so create a slurm file.
need scp merged769hits2col.fasta to /work/amundsen/pterry/hmm_pfam/
cd /Users/bterry/macbook2016/keenanres16/Bdac/pfam
ls -lh
scp merged769hits2col.fasta pterry@crane.unl.edu:/work/amundsen/pterry/hmm_pfam/
## scp slurm script to /home/amundsen/pterry/scripts

02/02/17:

cd /Users/bterry/macbook2016/keenanres16/Bdac/pfam/uniprot
scp slurm_blastp_uniprotKB.sh pterry@crane.unl.edu:/home/amundsen/pterry/scripts/
ssh -Y pterry@crane.unl.edu
# Rrq096mN
cd /home/amundsen/pterry/scripts
ls -lh
sbatch slurm_blastp_uniprotKB.sh 6571798 10:38am => ??:??am, 
squeue -u pterry  ## R
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
## Q: ???????????????????????????
cd /work/amundsen/pterry/hmm_pfam/blastpuniprotKB
less job.6571798.err

BLAST Database error: No alias or index file found for protein database [uniprot-all.fasta] in search path [/lustre/work/amundsen/pterry/hmm_pfam/blastpuniprotKB::]
job.6571798.err (END) 

more job.6571798.err
more job.3128028.out
# no error messages apparent in .err or .out Files
# Q: how to examine directory, determine what have ??????????????
# Note: 4 GOseq.depleted or GOseq.enriched files have only headers, no data in rows below ???????????????????????
# To do, check out the 4 pdf files ????????????

sacct -j  3128028 -o start,end
              Start                 End 
------------------- ------------------- 
2016-01-25T15:38:52 2016-01-25T15:40:59 
2016-01-25T15:38:52 2016-01-25T15:40:59 
# 2 min 7 sec


02/07/17:
## ok, JJ setting up crane to blastp, uniprotKB, uniref90.
## talked to Adam, some of doc on HCC for biodata module needs updating ????
## will need check wi JJ on how use uniprotKB ??????????????????? 
## need to create slurm_blastp_uniref90.sh file, to use module biodata.

cd /Users/bterry/macbook2016/keenanres16/Bdac/pfam/uniprot
scp slurm_blastp_uniref90.sh pterry@crane.unl.edu:/home/amundsen/pterry/scripts/

ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry/hmm_pfam
mkdir blastpuniref90
cd /home/amundsen/pterry/scripts
ls -lh
sbatch slurm_blastp_uniref90.sh 6644714  2:19pm => ??:??am, 
squeue -u pterry  ## ????

cd /work/amundsen/pterry/hmm_pfam/blastpuniref90
ls -lh
less job.6644714.err
Static data resources for bioinformatics 1.0.
     Contact the Bioinformatics Core Research Facility (bcrf-support@unl.edu) for questions/support.
/var/spool/slurmd/job6644714/slurm_script: line 14: blastp: command not found
job.6644714.err (END) 

## talked to JJ, indicated how deal with blastp error. So fix in slurm_blastp_uniref90.sh, try run again.

## tomorrow, uniprotKB 'db' file should be ready ($BLAST/uniprot_sprot). Check in dir. for these db files, dir. is 
ls $UNIPROT_KB  ## failed on tusker ??????????????

cd /Users/bterry/macbook2016/keenanres16/Bdac/pfam/uniprot
scp slurm_blastp_uniref90.sh pterry@crane.unl.edu:/home/amundsen/pterry/scripts/

ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /home/amundsen/pterry/scripts
ls -lh
sbatch slurm_blastp_uniref90.sh 6645338  4:52pm => ??:??am, 
squeue -u pterry  ## a PD
           6645338     batch TJob_bla   pterry PD       0:00      1 (Resources)

cd /work/amundsen/pterry/hmm_pfam/blastpuniref90
ls -lh
less job.6645338.err
Static data resources for bioinformatics 1.0.
     Contact the Bioinformatics Core Research Facility (bcrf-support@unl.edu) for questions/support.
job.6645338.err (END) 
## Now job has R status, so apparently working ????????????????????
           6645338     batch TJob_bla   pterry  R       3:09      1 c1315
squeue -u pterry  ## 10:00pm,
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
## So, no longer running ????
ls -lh
less job.6645338.err  ## same info message as earlier.

sacct -j  6645338 -o start,end
              Start                 End 
------------------- ------------------- 
2017-02-07T16:52:56 2017-02-07T19:40:41 
2017-02-07T16:52:56 2017-02-07T19:40:41 
## so ran ~ 2hr & 49 min.

less blastpuniref90.outfmt6
TRINITY_DN1004_c0_g1_i1|m.81778 UniRef90_A0A0A9INA7     68.889  180     55      1
       1       180     197     375     2.65e-75        251
TRINITY_DN11662_c0_g1_i1|m.153215       UniRef90_A0A1D5WZU6     84.615  26      4
       0       1       26      441     466     2.16e-08        55.1
## looks like 12 columns, need go find defs for the colmns (done). And then the annotation of the uniref90 seqs hit ??????????????

cd /work/amundsen/pterry/hmm_pfam/blastpuniref90
ls -lh
wc -l blastpuniref90.outfmt6
799 blastpuniref90.outfmt6
head -n 3 blastpuniref90.outfmt6
tail -n 3 blastpuniref90.outfmt6


02/09/17:
## fix/finish slurm_blastp_uniprotKB.sh

cd /Users/bterry/macbook2016/keenanres16/Bdac/pfam/uniprot
scp slurm_blastp_uniprotKB.sh pterry@crane.unl.edu:/home/amundsen/pterry/scripts/

ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry/hmm_pfam/
ls -lh  ## ck if blastpuniprotKB dir exists?
cd /home/amundsen/pterry/scripts
ls -lh
sbatch slurm_blastp_uniprotKB.sh 6670504 10:37am => ??:??am, 
squeue -u pterry  ## a R
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           6670504     batch TJob_bla   pterry  R       1:41      1 c1903

cd /work/amundsen/pterry/hmm_pfam/blastpuniprotKB
ls -lh
less job.6670504.err  ## just JJ's contact info if problem.

sacct -j  6670504 -o start,end
              Start                 End 
------------------- ------------------- 
2017-02-09T10:36:14 2017-02-09T10:38:34 
2017-02-09T10:36:14 2017-02-09T10:38:34 
## 2 min, 20 sec., so much **faster**, uniprotKB db than uniref90 db.

wc -l blastpuniprotKB.outfmt6
771 blastpuniprotKB.outfmt6, nearly same as uniref90 ??????

head -n 3 blastpuniprotKB.outfmt6
tail -n 3 blastpuniprotKB.outfmt6
## Q: **what** next ???????

## names hits **different** vs uniprotKB & uniref90 db's.
## So, **how** compare hits between them ???????????????????????

## definitely need select hits E <= 10^-5. Can this be done from unix command line ??????????????
## TO try: awk, ref:
http://unix.stackexchange.com/questions/188095/remove-lines-where-a-fields-value-is-less-than-or-equal-to-3-sed-or-awk

cd /Users/bterry/macbook2016/keenanres16/Bdac/pfam/uniprot
scp pterry@crane.unl.edu:/work/amundsen/pterry/hmm_pfam/blastpuniprotKB/blastpuniprotKB.outfmt6 .
cp blastpuniprotKB.outfmt6 copyblastpuniprotKB.outfmt6
wc -l blastpuniprotKB.outfmt6
     771 blastpuniprotKB.outfmt6
awk '($11 < 0.00001) ' copyblastpuniprotKB.outfmt6 > copyblastpuniprotKB00001.txt
wc -l copyblastpuniprotKB00001.txt
     655 copyblastpuniprotKB00001.txt
head -n 3 copyblastpuniprotKB00001.txt

STOPPED

02/10/17:
## Next, compare trinity DE'd lists with rows in blastp output (colm 1). Matches would be DE'd tx's for NB-ARC proteins. Will  need to **reduce** colm 1 of copyblastpuniprotKB00001.txt to just the tx id to compare with DE'd files for trt, ctl.
## Q: are NB-ARC proteins/genes available other than as hmm ??????????

## **JJ** info:
[pterry@login.crane pterry]$ module load biodata
Static data resources for bioinformatics 1.0.
     Contact the Bioinformatics Core Research Facility (bcrf-support@unl.edu) for questions/support.
[pterry@login.crane pterry]$ ls $UNIPROT_KB
complete                  idmapping      proteomics_mapping   taxonomic_divisions genome_annotation_tracks  pan_proteomes  reference_proteomes  variants
[pterry@login.crane pterry]$ echo $UNIPROT
/work/HCC/BCRF/uniprot/2017_1
[pterry@login.crane pterry]$ Write failed: Broken pipe
philip-terry-2:uniprot bterry$ 
## so, apparently uniprot files were versions for **Jan, 2017**
## Q: is there a **directory** where the uniprotKB & uniref90 dnloads are, tho apparently compressed ????????????????????

ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry
## DE'd trinity files 'scp'd from 'pro' to crane, num. of bytes agree on 'pro', crane. 
Better doc. where I put on crane (/work/amundsen/pterry)

02/11/17:
scp two DE'd files over to 
cd /Users/bterry/macbook2016/keenanres16/Bdac/pfam/uniprot

-rw-r--r--  1 pterry amundsen 302K Feb 10 09:40 Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95C-UP.subset
-rw-r--r--  1 pterry amundsen 536K Feb 10 09:42 Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95T-UP.subset

scp pterry@crane.unl.edu:/work/amundsen/pterry/Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95C-UP.subset .

scp pterry@crane.unl.edu:/work/amundsen/pterry/Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95T-UP.subset .

-rw-r--r--   1 bterry  staff       308395 Feb 11 20:46 Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95C-UP.subset
-rw-r--r--   1 bterry  staff       547935 Feb 11 20:50 Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95T-UP.subset
## size matches size on crane.
wc -l copyblastpuniprotKB00001.txt  ##      655 copyblastpuniprotKB00001.txt
wc -l Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95C-UP.subset
    2186 Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95C-UP.subset
wc -l Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95T-UP.subset
    3972 Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95T-UP.subset

## ok, now working on colm 1 of copyblastpuniprotKB00001.txt
cut -f 1 copyblastpuniprotKB00001.txt > copyblastpuniprotKB00001.col1.txt
head -n 3 copyblastpuniprotKB00001.col1.txt
wc -l copyblastpuniprotKB00001.col1.txt

## trying sed to remove '|...' for each line, 
sed -n "_|.*$__p" sedtest.txt
sed: 1: "_|.*": invalid command code _
sed -n "/|.*$//p" sedtest.txt
sed: 1: "/|.*$//p": invalid command code /
sed -n "_|.*$_s__p" sedtest.txt
sed: 1: "_|.*": invalid command code _
sed -n "/|.*$/s//p" sedtest.txt
sed -n "/m\..*$/s//p" sedtest.txt
sed: 1: "/m\..*$/s//p": unterminated substitute in regular expression

## **for moment**, give up on sed for this task, looks like bbedit can do.

02/12/17:
## ref: p-28, haddock & dunn book
copy copyblastpuniprotKB00001.col1.txt to get copyblastpuniprotKB00001.col1.bbedit.txt
## Open copyblastpuniprotKB00001.col1.bbedit.txt in BBedit, then search/find, then, of course 'grep' & 'case sensitive' checked, in 'find' box, '\w+)\|.+', and in replace box, '\1'. 655 rows replaced as expect.

sort copyblastpuniprotKB00001.col1.bbedit.txt | uniq | wc -l  ##      634
sort copyblastpuniprotKB00001.col1.bbedit.txt | uniq -c | wc -l  ## 634 ?????
sort copyblastpuniprotKB00001.col1.bbedit.txt | uniq -c > testuniq
## not working as p-243, shotts bk ???????????????
sort copyblastpuniprotKB00001.col1.bbedit.txt | uniq > uniprotKBcol1uniq.txt
wc -l uniprotKBcol1uniq.txt  ##      634 uniprotKBcol1uniq.txt

## working on Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95C-UP.subset

cut -f 1 Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95C-UP.subset > C_UPcol1.txt
head -n 3 C_UPcol1.txt  ## need remove colm 1 label, 'id', *done*.
wc -l C_UPcol1.txt  ##     2185 C_UPcol1.txt

STOPPED

sort C_UPcol1.txt | uniq > C_UPcol1.uniq.txt
head -n 3 C_UPcol1.uniq.txt
wc -l C_UPcol1.uniq.txt  ##  2185 C_UPcol1.uniq.txt

#comm -12 file1 file2
comm -12 uniprotKBcol1uniq.txt C_UPcol1.uniq.txt > comm_uniprotKBcol1vsC_UPcol1
wc -l comm_uniprotKBcol1vsC_UPcol1  ##        6 comm_uniprotKBcol1vsC_UPcol1
head comm_uniprotKBcol1vsC_UPcol1

## working on 
Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95T-UP.subset
cut -f 1 Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95T-UP.subset > T_UPcol1.txt
head -n 3 T_UPcol1.txt  ## ## need remove colm 1 label, 'id', *done*.
wc -l T_UPcol1.txt  ##     3971 T_UPcol1.txt

sort T_UPcol1.txt | uniq > T_UPcol1.uniq.txt
head -n 3 T_UPcol1.uniq.txt
wc -l T_UPcol1.uniq.txt  ##      3971 T_UPcol1.uniq.txt

comm -12 uniprotKBcol1uniq.txt T_UPcol1.uniq.txt > comm_uniprotKBcol1vsT_UPcol1

wc -l comm_uniprotKBcol1vsT_UPcol1  ##        18 comm_uniprotKBcol1vsT_UPcol1
cat comm_uniprotKBcol1vsT_UPcol1

philip-terry-2:uniprot bterry$ cat comm_uniprotKBcol1vsC_UPcol1

TRINITY_DN42138_c0_g1_i6
TRINITY_DN43935_c0_g1_i1
TRINITY_DN43935_c0_g1_i4
TRINITY_DN44006_c0_g1_i2
TRINITY_DN45879_c0_g1_i1
TRINITY_DN47540_c0_g2_i3

philip-terry-2:uniprot bterry$ cat comm_uniprotKBcol1vsT_UPcol1
TRINITY_DN14867_c0_g1_i1
TRINITY_DN14867_c0_g2_i1
TRINITY_DN33129_c0_g1_i1
TRINITY_DN42138_c0_g1_i3
TRINITY_DN43726_c0_g1_i1
TRINITY_DN47538_c0_g1_i6
TRINITY_DN47735_c2_g1_i1
TRINITY_DN48027_c1_g1_i10
TRINITY_DN48035_c1_g2_i2
TRINITY_DN48048_c1_g2_i1
TRINITY_DN48048_c1_g2_i10
TRINITY_DN48048_c1_g2_i16
TRINITY_DN48048_c1_g2_i2
TRINITY_DN48048_c1_g2_i4
TRINITY_DN48248_c0_g2_i8
TRINITY_DN48341_c1_g1_i4
TRINITY_DN48414_c4_g2_i1
TRINITY_DN8064_c0_g1_i1

## Now, identify uniprotKB hits (their annotation) by trinity 'transdecoder' proteins, run thru NB-ARC hmm, & matching names in common with DE'd tx's, (Q: how, perhaps just enter their names at uniprotKB web site) ??????

## Start with copyblastpuniprotKB00001.txt coming from outfmt6 output from blastp run. 655 records Evalue <= 0.00001
## Take tx names from comm_uniprotKBcol1vsC_UPcol1,comm_uniprotKBcol1vsT_UPcol1 files, search copyblastpuniprotKB00001.txt for matching records, record matching uniprotKB hit names.
## 1st, T_UPcol1
wc -l copyblastpuniprotKB00001.txt  ##      655 copyblastpuniprotKB00001.txt
## Note, apparently only 634 unique records.
## 1st, the 6 hits from comm_uniprotKBcol1vsC_UPcol1

TRINITY_DN42138_c0_g1_i6|m.29512	sp|Q9M667|RPP13_ARATH	line 211
TRINITY_DN43935_c0_g1_i1|m.113624	sp|Q9SX38|DRL4_ARATH	line 241
TRINITY_DN43935_c0_g1_i4|m.113631	sp|Q9SX38|DRL4_ARATH	line 243
TRINITY_DN44006_c0_g1_i2|m.127971	sp|Q39214|RPM1_ARATH	line 251
TRINITY_DN45879_c0_g1_i1|m.19009	sp|Q6L438|R1A6_SOLDE	line 306
TRINITY_DN47540_c0_g2_i3|m.55414	sp|Q39214|RPM1_ARATH	line 400

## then, the 18 hits from comm_uniprotKBcol1vsT_UPcol1

TRINITY_DN14867_c0_g1_i1|m.150615	sp|Q9M667|RPP13_ARATH	line 13
TRINITY_DN14867_c0_g2_i1|m.150617	sp|Q9M667|RPP13_ARATH	line 14
TRINITY_DN33129_c0_g1_i1|m.8542	sp|Q7XA39|RGA4_SOLBU	line 95
TRINITY_DN42138_c0_g1_i3|m.29503	sp|Q9M667|RPP13_ARATH	line 208
TRINITY_DN43726_c0_g1_i1|m.91712	sp|Q9FG90|DRL33_ARATH	line 238

02/13/17:
TRINITY_DN47538_c0_g1_i6|m.54233	sp|Q7XA42|RGA1_SOLBU	line 388
TRINITY_DN47735_c2_g1_i1|m.123183	sp|Q7XA40|RGA3_SOLBU	line 422
TRINITY_DN48027_c1_g1_i10|m.143658	sp|Q7XA40|RGA3_SOLBU	line 440
TRINITY_DN48035_c1_g2_i2|m.144326	sp|Q39214|RPM1_ARATH	line 454 note: dupl, hits same sp number, '|m....' different ???????????????????
TRINITY_DN48048_c1_g2_i1|m.144363	sp|Q39214|RPM1_ARATH	line 459
TRINITY_DN48048_c1_g2_i10|m.144401	sp|Q39214|RPM1_ARATH	line 460
TRINITY_DN48048_c1_g2_i16|m.144423	sp|Q39214|RPM1_ARATH	line 465
TRINITY_DN48048_c1_g2_i2|m.144366	sp|Q39214|RPM1_ARATH	line 468
TRINITY_DN48048_c1_g2_i14|m.144411	sp|Q39214|RPM1_ARATH	line 463
TRINITY_DN48248_c0_g2_i8|m.69449	sp|Q39214|RPM1_ARATH	line 506
TRINITY_DN48341_c1_g1_i4|m.46848	sp|Q39214|RPM1_ARATH	line 518
TRINITY_DN48414_c4_g2_i1|m.136104	sp|Q7XA40|RGA3_SOLBU	line 535
TRINITY_DN8064_c0_g1_i1|m.148651	sp|Q38834|R13L4_ARATH	line 625

## so only 9 *different* uniprotKB hits out of 24 hits.
## dnloaded basket of 9, just a fasta file. So how best to access annotation for these 9 ???????????????????
## Dnloaded brief annatation. Q: can I see more detailed annotation other than one hit at a time in a dnload ????????????

02/14/17:
## comments, considerations
i) understanding the system in plants for defending against disease (is there a review, etc found at least 2, 1-s2.0-S0168952512001709-main.pdf, 1-s2.0-S0885576512000033-main.pdf) in /Users/bterry/macbook2016/keenanres16/Bdac/pfam/uniprot dir. 
ii) uniref90 blastp results (note number hits almost same as vs uniprotKB)
iii) access long form of annotation for hits from uniprotKB site, annotation score. Look thru, decide which to select for dnload.
iv) Evalue for blastp, p-value for trinity/trinotate DE'd genes, should I go, document ????
## Vikas, do p-value for DE'd tx's. (me, benefit ??????????????)
v) looking forward, direction of research **TO dO**, make a plan!!!!

# slipped a save to ***github*** in here for this file,  BdactyloidesthruGSEA081615.txt.

02/19/17:

STOPPED
## Q: can I use a linux command line join to find uniprotKB hits for tx names in  Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95T-UP.subset
 file ?????????
## which file to 'join' with  '95T-UP', 95C-UP files ????????
95C-UP 'join' comm_uniprotKBcol1vsC_UPcol1
95T-UP 'join' comm_uniprotKBcol1vsT_UPcol1
## 'join' colm name? 
## Q: p-249, shotts book, looks like need sort each file *&* each input file needs to be the same length ***?????????????????????????***
## *rather* than pursue 'join' further for this task, perhaps go to ...
but 1st, create unique files for all files not unique ???????
## *OR*, given there are only 9 different uniprotKB names, or 6 + 18 tx names (run uniq on comm_uniprotKBcol1vsC_UPcol1, comm_uniprotKBcol1vsT_UPcol1 to determine number unique number tx names), 

cd /Users/bterry/macbook2016/keenanres16/Bdac/pfam/uniprot
sort comm_uniprotKBcol1vsC_UPcol1 | uniq | wc -l  ##      6
sort comm_uniprotKBcol1vsT_UPcol1 | uniq | wc -l  ##      18

## To determine if any tx names in common between the lists, tho may be none technically in common, but some **just** difference at end of tx name.
cat comm_uniprotKBcol1vsC_UPcol1 comm_uniprotKBcol1vsT_UPcol1 > CandTuniqtest
sort CandTuniqtest | uniq | wc -l  24

## ok, for C_UP, & T_UP, separately in BBedit, manually select the 6 or 18 records so have the logFC values for these 6 + 18 tx names.

## bkmark: 
uniprotKB, my 9 hits
http://www.uniprot.org/uniprot/?query=job:M20170214F725F458AC8690F874DD868E4ED79B88A2CA71D


03/05/17:
Recheck Keenan,
--logFC, base important ??????
--plan do blastp for transdecoder output from trinity tx's, but just for the tx names in C_UP, T_UP ??????
--how do The blast, say only top hit, can one pick a 'outfmt' format to give some of the graphical, etc. output can get by say blastp online? An other kind of blast for nucleotides (tx's directly ???????).
--try do blat (or Magic-BLAST, BLAST RNA-seq mapping tool ????) on a related seqd genome (brachypodium, model for grasses, Nature 463, 763-768 (11 February 2010), Genome sequencing and analysis of the model grass Brachypodium distachyon)
 (mower, phylogenetic paper for Bdac) ?????????????? Might provide addl insight ????????
--Rouxel review, table 2, fungal avirulence genes, perhaps could identify addl (R) genes for these avirulence genes ?????????????????
--addl domains, NB-LRR ????????????

03/07/17:
## ok, set up following project: start with the transdecoder amino acid seq output from Trinity.fasta, Trinity.fasta.transdecorder.pep. Separately merge (Subset) C_UP (2185) & T_UP (3971) tx's with these 74489 rows. ***To check*** '.py' code, think used to convert fasta to df format, so should already exist the df form file produced from Trinity.fasta.transdecorder.pep (Trinity.fasta.transdecorder.out, line 8389 above).

Blastp each merged subset in turn vs uniprotKB db. In resulting 'outfmt6' outout format, colm2 will be the uniprotKB target for a particular original tx. Submit each target hit (its name) to uniprotKB online db, to get annotation for the hit, and thus annotation for that Trinity.fasta tx. Try catalogue, make sense of the resulting body annotations for C_UP, T_UP tx's.

Initially get 'head' for the three files (Trinity.fasta.transdecorder.pep df form, & C_UP, T_UP), so can figure how to subset from the 74489, for C_UP, T_UP. Perhaps, 1st, find Trinity.fasta.transdecorder.pep file after conversion to dataframe format. Then merge in turn, C_UP with Trinity.fasta.transdecorder.pep df form, and then T_UP with Trinity.fasta.transdecorder.pep df form.

03/15/17:
## use C_UPT_UPforblastp.R file to prepare (see p-8390, Bdac... file) Trinity.fasta.transdecoder.f1234.out output dataframe for merging with C_UP & T_UP, and blastp vs uniprotKB. The ...f1234.out file from run of seqread_pmt.py to convert transdecoder ....pep fasta file to dataframe.
## 1st need remove everything past 1st '|' for each row of Trinity.fasta.transdecoder.f1234.out. To accomplish, test with 1st three rows with reg expn '(\w+)\|.+' in find box, '\1' in 'replace all' box . Worked, 'case sensitive' & 'grep' selected.
So, repeat on Trinity.fasta.transdecoder.f1234.copy.out. 74489 modified, so success.
## Next, read in Trinity.fasta.transdecoder.f1234.copy.out & Trinity.fasta.transdecoder.f5.copy.out into R with C_UPT_UPforblastp.R code.

03/17/17:
ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry
find . -name 'Trinity.fasta' -print

[pterry@login.crane trinity_out_dir]$ pwd
/work/amundsen/pterry/Trin21test/95C1-3T1-3/trinity_out_dir

-rw-r--r-- 1 pterry amundsen 194832811 Dec 16  2015 Trinity.fasta

cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/trinity_out_dir

cp /work/amundsen/pterry/Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95C-UP.subset .
## **note**: Trinity.fasta is fasta file, so to test (p-222, vbuffalo) to see if all of Trinity_trans.counts.matrix.95C_vs_95T.edgeR.DE_results.P1e-3_C2.95C-UP.subset
rows are in Trinity.fasta, would 1st need convert Trinity.fasta to dataframe.

## table(merge...  ## p-222, vbuffalo, [1] 854  1331
## merged C_UP with refSeqID_seq dataframes, [1] 1698    2
## to *check* number unique rows in colm 1 of mergedC_UP df.
length(unique(mergedC_UP$refSeqID))  ## [1] 1331, so looks like duplicates explains difference.

## left, convert mergedC_UP df to fasta file, write to file.

writeLines(mergedC_UP2colfasta, "mergedC_UP2col.fasta")  ## looks ok.
## ready for blastp vs uniprotKB

STOPPED
wc -l mergedC_UP2col.fasta
    3396 mergedC_UP2col.fasta
 ##grep -c "^>" Trinity.fasta  ## 165459, why working on crane ?????
grep -c "^>" mergedC_UP2col.fasta  ## 1698, consistent with 'wc -l'

03/17/17:
## prepare a mergedT_UP2col.fasta for treatment DE'd tx's.
wc -l mergedT_UP2col.fasta
    8336 mergedT_UP2col.fasta  ## [1] 4168, double of as expect.
grep -c "^>" mergedT_UP2col.fasta  ## 4168 as expect.
*****************************************************
## **to try** spot check ref, seq in mergedC_UP2col.fasta, mergedT_UP2col.fasta files with refSeqID_seq.txt file or the prev 'Trinity.fasta.transdecorder.pep'file ?????????????????????

## spot these two from mergedT_UP2col.fasta
>TRINITY_DN10001_c0_g2_i1
>TRINITY_DN10002_c0_g2_i1
## Found in Trinity.fasta.transdecorder.pep, seq same between files, so for now, **assume** mergedT_UP2col.fasta references & seqs faithfully found in Trinity.fasta.transdecorder.pep.
*****************************************************
find . -name 'Trinity.fasta.transdecorder.pep' -print
find . -name 'mergedT_UP2col.fasta' -print
## looks like don't have Trinity.fasta.transdecorder.pep file on macbook (but do in pfam dir ???????????????)

## to **compare** size blastp input file merged769hits2col.fasta with output file blastpuniprotKB.outfmt6
grep -c "^>" merged769hits2col.fasta  ## 769
wc -l merged769hits2col.fasta  ## 1538
grep -c "^TRI" blastpuniprotKB.outfmt6  ## 771
wc -l blastpuniprotKB.outfmt6  ## 771
## *****Q*****: 2 extra lines in blastpuniprotKB.outfmt6 ?????????????????
## Perhaps try find ****explanation**** for the difference ?????????????????

03/19-20/17:

## then **ready** for blastp vs uniprotKB
## see prev slurm blastp vs uniprotKB in dir for reference.
/Users/bterry/macbook2016/keenanres16/Bdac/pfam/uniprot

## created slurm_blastp_uniprotKB_T_UP.sh in 'uniprot' dir
## to do, scp to crane, scripts dir
## scp mergedT_UP2col.fasta to crane 'pfam' dir.
## created slurm_blastp_uniprotKB_C_UP.sh in 'uniprot' dir
## to do, scp to crane, scripts dir
## scp mergedC_UP2col.fasta to crane 'pfam' dir.

## Reference 02/09/17: above for running these 'slurm' files on crane.
cd /Users/bterry/macbook2016/keenanres16/Bdac/pfam/uniprot
scp slurm_blastp_uniprotKB_T_UP.sh pterry@crane.unl.edu:/home/amundsen/pterry/scripts/
cd /Users/bterry/macbook2016/keenanres16/Bdac/pfam
pwd
scp mergedT_UP2col.fasta pterry@crane.unl.edu:/work/amundsen/pterry/hmm_pfam/

ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry/hmm_pfam/
ls -lh  ## ck if blastpuniprotKB dir exists?
cd /home/amundsen/pterry/scripts
ls -lh
sbatch slurm_blastp_uniprotKB_T_UP.sh 7101537 10:03am => ??:??am, 
squeue -u pterry  ## a PD
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           7101537     batch TJob_bla   pterry  R      36:27      1 c1209
36.27 at 1:32pm, so started approx 1:00pm ?????????????????????

cd /work/amundsen/pterry/hmm_pfam/blastpuniprotKB
ls -lh
less job.7101537.err  ## just JJ's contact info if problem.

sacct -j  7101537 -o start,end
              Start                 End 
------------------- ------------------- 
2017-03-20T12:53:21 2017-03-20T13:29:58 
2017-03-20T12:53:21 2017-03-20T13:29:58 
## 1:30 - 12:53 = 37 min run

## for T_IP, how best try gather annotation for hits vs uniprotKB ????????
## **To do**, compare number records blastp input, output.

cd /Users/bterry/macbook2016/keenanres16/Bdac/pfam/uniprot
scp pterry@crane.unl.edu:/work/amundsen/pterry/hmm_pfam/blastpuniprotKB/blastpT_UPuniprotKB.outfmt6 .
wc -l ../mergedT_UP2col.fasta
    8336 ../mergedT_UP2col.fasta
wc -l blastpT_UPuniprotKB.outfmt6
    4432 blastpT_UPuniprotKB.outfmt6
## Q: why more than half of mergedT_UP2col.fasta ???????????????
grep -c "^>" ../mergedT_UP2col.fasta  ## 4168, half 'wc -l', ok
grep -c "^TRI" blastpT_UPuniprotKB.outfmt6  ## 4432, same as 'wc -l', ok
## Q: relation input, output file, should not output file have same grep output as grep input ?????????????????????????????
## now what, would like to relate DE'd T_UP tx names with annotation of their uniprotKB hits. **How** best to accomplish for 4432 tx names in blastpT_UPuniprotKB.outfmt6 ??????????????????????????????????
## GO, B2GO, etc.? Manually, some automated fashion? Perhaps email query to uniprotKB site ???????????????????????
## Q: blastp with duplicate tx names ??????????????
## UGA person & info on disease resistence in plants ????????????

03/23/17:
Talked to Keenan,
Try to 'ID' defense related proteins in blastpT_UPuniprotKB.outfmt6. 

## Following response from uniprotKB contact email, try use uniprotKB 'batch retrieval tool' to retrieve annotations for uniprotKB identifiers in blastpT_UPuniprotKB.outfmt6.
## 1st, cut colm2 from linux command line to blastpT_UPuniprotKBcol2IDs.txt 


Then inside BBedit, grep part between the '|' characters. ...
cp blastpT_UPuniprotKB.outfmt6 to blastpT_UPuniprotKBcol2IDs.txt

cut -f 2 blastpT_UPuniprotKB.outfmt6 > blastpT_UPuniprotKBcol2IDs.txt
head -n 3 blastpT_UPuniprotKBcol2IDs.txt  
wc -l blastpT_UPuniprotKBcol2IDs.txt  
    4432 blastpT_UPuniprotKBcol2IDs.txt

Of course 'grep' & 'case sensitive' checked, in 'find' box, 'sp\|(\w+)\|\w+', and in replace box, '\1'. 4432 rows replaced as expect.

wc -l blastpT_UPuniprotKBcol2IDs.txt  ## 4432 as expect.

sort blastpT_UPuniprotKBcol2IDs.txt | uniq > blastpT_UPuniprotKBcol2IDs.uniq.txt
head -n 3 blastpT_UPuniprotKBcol2IDs.uniq.txt
wc -l blastpT_UPuniprotKBcol2IDs.uniq.txt  ##      3971 T_UPcol1.uniq.txt
    3259 blastpT_UPuniprotKBcol2IDs.uniq.txt
## so several duplicate uniprotKB ID's in blastpT_UPuniprotKB.outfmt6

03/24/17:
## perhaps blastpT_UPuniprotKBcol2IDs.uniq.txt file the one to submit to 'batch retrieval tool' on uniprotKB werbsite.

03/29/17:
## Then, need to become familiar with the options for filtering of the results.
## response from 2nd email Q to help@uniprot.org.
## 'Leucine-rich repeat (44)' has **two** links, one a description of the domain, the 2nd to the 44 uniprotKB ID's.
## so attempt try organize a bit these 44 ID's.
## at least 32 of 44 IDs are from plant.

03/30/17:

04/05/17:

STOPPED

## I note the amount of work done with plants and fungal pathogens in S. Childs preprint: 'A soybean resistance allele from PI 423972 at the Rpp4 locus'.

## to group the 44 LRR proteins into categories, then look bit more at description IDs in each category, see if can conclude qqch about the categories ???????????

LRR receptors (may be able to subset further ???)
O22938, Q9FRS6, Q9LIG2, Q9C9H7(?), Q1MX30, Q2R2D5, COLGH2, COLGK4, COLGP4, Q9LT96, Q9LJF3, Q42371

## colms to populate
ID(entry)
protein names
gene names
organism
length
function
subellular location
a.a. modifications (???)
domains
all kinds of references to other db's

## see /Users/bterry/macbook2016/keenanres16/Bdac/pfam/uniprot/from_uniprotKB
/uniprot-yourlist%3AM2017040583C3DD8CE55183C76102DC5D3A26728BC9218FD.tab

Test: O22938
ID: O22938
protein names: Leucine-rich repeat receptor-like tyrosine-protein kinase PXC3 (EC 2.7.10.1) (Protein PXY/TDR-CORRELATED 3)
gene names: PXC3 At2g41820 T11A7.8
organism: Arabidopsis thaliana (Mouse-ear cress)
length: 890
function: ATP + a [protein]-L-tyrosine = ADP + a [protein]-L-tyrosine phosphate
GO Molr fcn: transmembrane receptor protein tyrosine kinase activity
subellular location: Cell membrane
GO cellular component: 
integral component of membrane (tair, plasma membrane)
a.a. modifications: N-linked GlcNac (14 residues, glycoprotein)
domains: 
LRR(18), protein kinase(1)

Test: Q9FRS6
ID: Q9FRS6
protein names: Leucine-rich repeat receptor-like protein kinase PXL1 (EC 2.7.11.1) (Protein PHLOEM INTERCALATED WITH XYLEM-LIKE 1)
gene names: PXL1 At1g08590 F22O13.7
organism: Arabidopsis thaliana (Mouse-ear cress)
length: 1029
function: ATP + a protein = ADP + a phosphoprotein.
## Note: Involved in the regulation of procambium maintenance and polarity during vascular-tissue development (PubMed:17570668). Phosphorylates HIRD11 and LHCA1 in vitro (PubMed:25602612).
Go Molr fcn: protein serine/threonine kinase activity
subellular location: cell membrane
GO cellular component: integral component of membrane, plasma membrane
a.a. modifications: N-linked GlcNac (14 residues, glycoprotein), phosphoserine/threonine/tyrosine (7 residues)
## Q: if a protein kinase, why 7 residues ??????????????????????????
domains: 
LRR(22), protein kinase(1)

Test: Q9LIG2
ID: Q9LIG2
protein names: Receptor-like protein kinase At3g21340 (EC 2.7.10.1) (EC 2.7.11.1) (Leucine-rich repeat receptor-like protein kinase At3g21340)
## 2 names ?????
gene names: At3g21340 MHC9.2
## Q: ???????????
organism: Arabidopsis thaliana (Mouse-ear cress)
length: 899
function: ATP + a protein = ADP + a phosphoprotein.
## Probable receptor with a dual specificity kinase activity acting on both serine/threonine- and tyrosine-containing substrates.
Go Molr fcn: transmembrane receptor protein tyrosine kinase activity
subellular location: cell membrane, Single-pass type I membrane protein
GO cellular component: integral component of membrane
a.a. modifications: a.a. modifications: N-linked GlcNac (10 residues, glycoprotein), phosphoserine (1), phosphothreonine (1)
## Q: ## Q: if a protein kinase, why phosphoserine (1), phosphothreonine (1) & 1 residue apart ?????????????????????????
domains: 
LRR(3), protein kinase(1)

...




'R' protein
Q7XA39, Q9STES, Q7XBQ9, ...

04/10/17:
## see /Users/bterry/macbook2016/keenanres16/Bdac/pfam/uniprot/from_uniprotKB
/uniprot-yourlist%3AM2017041083C3DD8CE55183C76102DC5D3A26728BCB8BE7T.tab

Test: Q7XA39
ID: Q7XA39
protein names: Putative disease resistance protein RGA4
gene names: RGA4 (RGA4-blb)	RGA4 177O13.34 CB3A14.8
organism: Solanum bulbocastanum (Wild potato)
length: 988
function: Disease resistance protein. Resistance proteins guard the plant against pathogens that contain an appropriate avirulence protein via a direct or indirect interaction with this avirulence protein. That triggers a defense system which restricts the pathogen growth.
Go Molr fcn: ATP binding, ADP binding
GO Biol'l process: defense response
subellular location: ?????????????????????????????????
a.a. modifications: ???????????????????????????
domains: NB-ARC(1), LRR(14)

Test: Q9STE5
ID: Q9STE5
protein names: Putative disease resistance RPP13-like protein 2
## Q: split before 'gene names' ?????
gene names: RPP13L2 At3g46710 T6H20.260
organism: Arabidopsis thaliana (Mouse-ear cress)
length: 847
function: Potential disease resistance protein. ??????????????????????
Go Molr fcn: ATP binding
GO Biol'l process: plant-type hypersensitive response, signal transduction
subellular location: 
GO cellular component: plasma membrane
a.a. modifications: ????????????????????????????????
domains: NB-ARC(1), LRR(5)

04/12/17:
## so updated BdactyloidesthruGSEA081615.txt to github, planets repo.

Test: Q7XBQ9
ID: Q7XBQ9
protein names: Disease resistance protein RGA2 (Blight resistance protein RPI) (RGA2-blb)
## Q: split before 'gene names' ?????
gene names: RGA2 177O13.40 CB3A14.5 RB RPI-BLB1
organism: Solanum bulbocastanum (Wild potato)
length: 970
function: Disease resistance protein. Resistance proteins guard the plant against pathogens that contain an appropriate avirulence protein via a direct or indirect interaction with this avirulence protein. That triggers a defense system which restricts the pathogen growth. Confers a broad resistance to all known races of P.infestans.
Go Molr fcn: ATP binding
GO Biol'l process: defense response
subellular location: ??????????????????
Expression:
Induction: Constitutively expressed. ?????????????????????????????
a.a. modifications: ????????????????????????????????
domains: NB-ARC(1), LRR(14)
Sequence similarities: belongs to the disease resistance NB-LRR family

04/13/17:
Test: Q7XA42
ID: Q7XA42
protein names: Putative disease resistance protein RGA1 (RGA3-blb)
gene names: RGA1 177O13.37 CB3A14.4
organism: Solanum bulbocastanum (Wild potato)
length: 979
function: Disease resistance protein. Resistance proteins guard the plant against pathogens that contain an appropriate avirulence protein via a direct or indirect interaction with this avirulence protein. That triggers a defense system which restricts the pathogen growth.
Miscellaneous
Belongs to a four-gene family located at the same locus. Although the four genes are expressed in the resistant haplotype, only RGA2 confers the resistance to P.infestans. In the susceptible haplotype, RGA1 and RGA3 are likely to be pseudogenes created by deletions and mutations, while RGA2 contains also several modifications.
Go Molr fcn: ATP binding
GO Biol'l process: defense response
subellular location: ?????????????????????????????????????
Expression:
Induction: Constitutively expressed. ?????????????????????????????
a.a. modifications: ?????????????????????????????????????????
domains: NB-ARC(1), LRR(12)
Sequence similarities: belongs to the disease resistance NB-LRR family

Test: Q9FI14
ID: Q9FI14
...




LRR-repeat (without receptor in name ?????)
## ***NOTE***: don't see much help wi the following documentation ??????????????
Q9FJV1, ...

## see /Users/bterry/macbook2016/keenanres16/Bdac/pfam/uniprot/from_uniprotKB
/uniprot-yourlist%3AM20170413F725F458AC8690F874DD868E4ED79B88AFC94CV.tab

Test: Q1PE04
ID: Q1PE04
protein names: F-box/LRR-repeat protein 25
gene names: FBL25 At5g02920 F9G14.230
organism: Arabidopsis thaliana (Mouse-ear cress)
length: 258   ## Q: what to think ??????????????????
function: ???????????????????????????????????
subellular location: ????????????????????????????
domains: F-box(1), LRR(4)

Test: Q9M0E1
ID: Q9M0E1
protein names: F-box/LRR-repeat protein At4g29420
gene names: At4g29420 F17A13.240
organism: Arabidopsis thaliana (Mouse-ear cress)
length: 446
function: ?????????????????????????????????
GO Biol'l process: cytokinin activated signaling pathway, hormone transport
subellular location: plasmodesma
domains: F-box(1), LRR(8)

Test: Q5VMP0
ID: Q5VMP0
protein names: F-box/LRR-repeat MAX2 homolog (F-box and leucine-rich repeat MAX2 homolog) (Protein DWARF 3)
gene names: D3 Os06g0154200 LOC_Os06g06050 OSJNBa0085L11.6-1
organism: Oryza sativa subsp. japonica (Rice)
length: 720
function: ***lot of explanation, not related to disease*** ??????????
...

Test: Q9FJV1
ID: Q9FJV1
protein names: F-box/FBD/LRR-repeat protein At5g56570
gene names: At5g56570 MIK19.1
organism: Arabidopsis thaliana (Mouse-ear cress)
length: 439
function: ??????????????????????????????????????
domains: F-box(1), LRR(2), FBD(1)

## so, have ? + ? + 6 of the 44.
## try isolate, see of any have useful doc. ??

## Looks like mainly 2 categories of proteins in this list of 44. Each group appears to be well documented.

04/24/17:
## Q: what now? Repeat blastp for 95C_UP (the subset of DE'd tx's).
04/25/17:
## to check, for '.outfmt6' files in /work/amundsen/pterry/hmm_pfam/blastpuniprotKB

ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry/hmm_pfam/blastpuniprotKB
ls -lh  ## have blastpT_UPuniprotKB.outfmt6
## but none for C_UP
cd /work/amundsen/pterry/hmm_pfam
ls -lh  ## have mergedT_UP2col.fasta
## but no mergedC_UP2col.fasta on crane.
## so need find this on macbook, or how to create it ???????
## line 9565 above,
## scp mergedC_UP2col.fasta to crane 'pfam' dir.

04/27/17:
## Apparently never did ??????????????????????????
## try do some checking 1st
## check before line 9520, which is
writeLines(mergedC_UP2colfasta, "mergedC_UP2col.fasta")  ## looks ok.
## check precursor to mergedC_UP2col.fasta, looks like may be in pfam dir, perhaps created in pfam project in RStudio ???????
## yes, following line is line 121 in C_UPT_UPforblastp.R
## ready for blastp vs uniprotKB
## refer to lines 9572 => 9642, this file
## 
cd /Users/bterry/macbook2016/keenanres16/Bdac/pfam/uniprot
scp slurm_blastp_uniprotKB_C_UP.sh pterry@crane.unl.edu:/home/amundsen/pterry/scripts/
cd /Users/bterry/macbook2016/keenanres16/Bdac/pfam
pwd
scp mergedC_UP2col.fasta pterry@crane.unl.edu:/work/amundsen/pterry/hmm_pfam/

ssh -Y pterry@crane.unl.edu
# Rrq096mN 
cd /work/amundsen/pterry/hmm_pfam/
ls -lh  ## ck if blastpuniprotKB dir exists?
cd /home/amundsen/pterry/scripts
ls -lh
sbatch slurm_blastp_uniprotKB_C_UP.sh 7329536  13:10pm => ??:??am, 
squeue -u pterry  ## a PD
             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           7101537     batch TJob_bla   pterry  R      36:27      1 c1209
36.27 at 1:32pm, so started approx 1:00pm ?????????????????????

cd /work/amundsen/pterry/hmm_pfam/blastpuniprotKB
ls -lh
less job.job.7329536.err  ## just JJ's contact info if problem.

sacct -j  7329536 -o start,end
              Start                 End 
------------------- ------------------- 
2017-04-27T16:44:36 2017-04-27T16:55:36 
2017-04-27T16:44:36 2017-04-27T16:55:36 
## 55:36 - 44:36 = 11 min run
## 1:30 - 12:53 = 37 min run

## for C_IP, how best try gather annotation for hits vs uniprotKB ????????
## **To do**, compare number records blastp input, output.

cd /work/amundsen/pterry/hmm_pfam/blastpuniprotKB
ls -lh
less blastpC_UPuniprotKB.outfmt6

cd /Users/bterry/macbook2016/keenanres16/Bdac/pfam/uniprot
scp pterry@crane.unl.edu:/work/amundsen/pterry/hmm_pfam/blastpuniprotKB/blastpC_UPuniprotKB.outfmt6 .
wc -l ../mergedC_UP2col.fasta
    3396 ../mergedC_UP2col.fasta
wc -l blastpC_UPuniprotKB.outfmt6
    1785 blastpC_UPuniprotKB.outfmt6
## Q: why more than half of mergedC_UP2col.fasta ???????????????
## perhaps dups in blastpC_UPuniprotKB.outfmt6 ???????
grep -c "^>" ../mergedC_UP2col.fasta  ## 1698, half 'wc -l', ok
grep -c "^TRI" blastpC_UPuniprotKB.outfmt6  ## 1785, same as 'wc -l', ok
## Q: relation input, output file, should not output file have same grep output as grep input ?????????????????????????????
## now what, would like to relate DE'd C_UP tx names with annotation of their uniprotKB hits. **How** best to accomplish for 1785 tx names in blastpC_UPuniprotKB.outfmt6 ??????????????????????????????????
## GO, B2GO, etc.? Manually, some automated fashion? Perhaps email query to uniprotKB site ???????????????????????
## Q: blastp with duplicate tx names ??????????????
## UGA person & info on disease resistence in plants ????????????

04/28/17:
## Following response from uniprotKB contact email, try use uniprotKB 'batch retrieval tool' to retrieve annotations for uniprotKB identifiers in blastpT_UPuniprotKB.outfmt6.
## 1st, cut colm2 from linux command line to blastpC_UPuniprotKBcol2IDs.txt 

Then inside BBedit, grep part between the '|' characters. ...
cp blastpC_UPuniprotKB.outfmt6 to blastpC_UPuniprotKBcol2IDs.txt

cut -f 2 blastpC_UPuniprotKB.outfmt6 > blastpC_UPuniprotKBcol2IDs.txt
head -n 3 blastpC_UPuniprotKBcol2IDs.txt  
sp|Q9XED7|R51A2_MAIZE
sp|Q9HE10|DSC3_SCHPO
sp|Q54VU4|Y8013_DICDI
wc -l blastpC_UPuniprotKBcol2IDs.txt  
    1785 blastpC_UPuniprotKBcol2IDs.txt

Of course 'grep' & 'case sensitive' checked, in 'find' box, 'sp\|(\w+)\|\w+', and in replace box, '\1'. 1785 rows replaced as expect.

wc -l blastpC_UPuniprotKBcol2IDs.txt  ## 1785 as expect.
    1785 blastpC_UPuniprotKBcol2IDs.txt

sort blastpC_UPuniprotKBcol2IDs.txt | uniq > blastpC_UPuniprotKBcol2IDs.uniq.txt
head -n 3 blastpC_UPuniprotKBcol2IDs.uniq.txt
A0A096SRM5
A0QAU8
A0SPJ3
wc -l blastpC_UPuniprotKBcol2IDs.uniq.txt  
    1190 blastpC_UPuniprotKBcol2IDs.uniq.txt
## 1785 down to 1190 when reduce to unique. So 1785 - 1190 = 595 dup's
## so several duplicate uniprotKB ID's in blastpC_UPuniprotKB.outfmt6

## perhaps blastpC_UPuniprotKBcol2IDs.uniq.txt file the one to submit to 'batch retrieval tool' on uniprotKB werbsite.

## 'LLR domain' has 31 hits of the 1190 blastp unique hits uploaded with 'batch retrieval tool' to uniprotKB.

## use 'comm' with T_UP & C_UP files submitted to uniprotKB with 'batch retrieval tool'. Are any of them in common?
comm -12 blastpC_UPuniprotKBcol2IDs.uniq.txt blastpT_UPuniprotKBcol2IDs.uniq.txt > common.txt
wc -l common.txt
     132 common.txt
wc -l blastpC_UPuniprotKBcol2IDs.uniq.txt
    1190 blastpC_UPuniprotKBcol2IDs.uniq.txt
wc -l blastpT_UPuniprotKBcol2IDs.uniq.txt
    3259 blastpT_UPuniprotKBcol2IDs.uniq.txt
## perhaps check LLR domain ID's in common for C_UP, T_UP ????
cd ..
ls -lh *.tab  ## none currently in 'pfam' or 'uniprot' dir.
## So, put in 'basket' from uniprotKB 1st the 31 C_UP hits, dnload. Rename to C_UP_LRR_uniprotKBhits.tab  (done)
## **To do**:  get a basket of the 44 for T_UP. 
## resubmit blastpC_UPuniprotKBcol2IDs.uniq.txt with 'batch retrieval tool' uniprotKB to get list of 44 LRR hits for T_UP.
## rename to T_UP_LRR_uniprotKBhits.tab
## for C_UP_LRR_uniprotKBhits.tab & T_UP_LRR_uniprotKBhits.tab,
## remove header
C_UP_LRR_uniprotKBhitsnohead.tab & T_UP_LRR_uniprotKBhitsnohead.tab
Since 1st colm has uniprotKB ID's (after remove header line) cut 1st colm each, 

cut -f 1 C_UP_LRR_uniprotKBhitsnohead.tab > C_UP_LRR_uniprotKBhitsnoheadcol1.tab
head -n 3 C_UP_LRR_uniprotKBhitsnoheadcol1.tab  
Q9LY03
Q9Y4C4
Q8LPB4
wc -l C_UP_LRR_uniprotKBhitsnoheadcol1.tab  
      31 C_UP_LRR_uniprotKBhitsnoheadcol1.tab

cut -f 1 T_UP_LRR_uniprotKBhitsnohead.tab > T_UP_LRR_uniprotKBhitsnoheadcol1.tab
head -n 3 T_UP_LRR_uniprotKBhitsnoheadcol1.tab  
Q8MVR1
Q6P1G2
Q0GKD5
wc -l T_UP_LRR_uniprotKBhitsnoheadcol1.tab  
      44 T_UP_LRR_uniprotKBhitsnoheadcol1.tab

## Now ready sort, uniq, C_UP, T_UP, then comm

sort C_UP_LRR_uniprotKBhitsnoheadcol1.tab | uniq > C_UP_LRR_uniprotKBhitsnoheadcol1.uniq.tab
head -n 3 C_UP_LRR_uniprotKBhitsnoheadcol1.uniq.tab
C0LGF5
C0LGH8
C0LGI2
wc -l C_UP_LRR_uniprotKBhitsnoheadcol1.uniq.tab  
      31 C_UP_LRR_uniprotKBhitsnoheadcol1.uniq.tab

sort T_UP_LRR_uniprotKBhitsnoheadcol1.tab | uniq > T_UP_LRR_uniprotKBhitsnoheadcol1.uniq.tab
head -n 3 T_UP_LRR_uniprotKBhitsnoheadcol1.uniq.tab
C0LGH2
C0LGK4
C0LGP4
wc -l T_UP_LRR_uniprotKBhitsnoheadcol1.uniq.tab  
      44 T_UP_LRR_uniprotKBhitsnoheadcol1.uniq.tab

comm -12 C_UP_LRR_uniprotKBhitsnoheadcol1.uniq.tab T_UP_LRR_uniprotKBhitsnoheadcol1.uniq.tab
C0LGP4
Q2R2D5
Q39214
Q42371
Q7XA39
Q7XBQ9
Q9FI14
Q9LIG2
Q9SKB2
Q9SX38
## so 10 ID's in common. Perhaps check fcn these proteins ????
## 5 receptor
## 5 disease
## looks like for LRR proteins, not significant distinction disease, receptor ratio between T_UP, C_UP. WHAT TO THINK ???????????

STOPPED
## **if** use this data, recheck that the uniprotKB ID's match with tx's from DE'd C_UP & T_UP tx's.
## Q: is there other possible info from uniprotKB of use ?????????

05/02/17:
talked to Keenan, mentioned uniprotKB result for 95_UP DE'd tx's. Mentioned 95-55 is resistant organism. Also tested **'prestige'**, a plant not resistent to the disease. So, may run trt & ctl for prestige thru trinity analysis, compare with result for 95-55.

05/17/17:
Updated to github.

07/01/17:
Updated to github.



Q: duplication??, how merge ???????????, perhaps append ???????



## initially, perhaps scp it to macbook, examine what have. Think need create a fasta file of top hits (how decide, perhaps 'crit5) ???????????
## from /work/amundsen/pterry/hmm_pfam/hmmsrchshortpeprefined2ndtry.out file.

## p-1722, blastx, 
#module load blast/2.2.29  ## is this up to date ?????????????????
#blastx -query Trinity.fasta -db $TRINOTATE_SP -num_threads 8 -max_target_seqs 1 -outfmt 6 > blastx.outfmt6

# note: new query for blastp will be the hits from '2nd' hmmsearch output (hmmsrchshortpeprefined2ndtry.out), for example, sec3, i_Evalue < ***.0001*** ?????????????????
## Q: p-773, Cell Reports, new trinotate pub, **what** protein db('s) to use ???????????


## Then try read into R, see if can subset by column (sequence) the dataframe (refSeqID_seq, by its column, refSeqID, thus get names of the 908 hit seqs? Finally do %in% to subset Trinity.fasta.transdecoder.pep for these 908 hit seqs (or whatever to subset the df ??????????????????




vecFullSeq <- vector(mode="character", length=148984)  ## 6 elts longer than expected number of of seq strings
vecFullSeq
for(i in 1:12) {
  if((i %% 2) == 0) {
    vecFullSeq[i/2] <- dseq[i,1]
  }
}
class(vecFullSeq)
vecFullSeq







## then, try build two vectors from this in R, preparing to put in df, then subset 908 seqs (merge wi hmmsrchshortpep.out file df to get domain location info.




## if working, try coerce to vector, then cp every 2nd elt of 10 elt vector to new 5 elt vector ??????
unlist(d)

12/29/16:
BBedit 





## need locate DE file for 95T tx's, (think ~ 2600).


R
getwd()
# Bl2GO_95C_xls <- read.delim("blast2go_fisher_20160620_0009.txt", stringsAsFactors=FALSE)
Bl2GO_95C_xls_chtstat_lev2 <- read.delim("Bl2GO_95C_xls_OVER_05_3col_lev2.txt", stringsAsFactors=FALSE)
Bl2GO_95T_xls_chtstat_lev2 <- read.delim("Bl2GO_95T_xls_OVER_05_3col_lev2.txt", stringsAsFactors=FALSE)





dim(Bl2GO_95C_xls)  ## [1] 230  12, agrees wi 'wc'
class(Bl2GO_95C_xls)
colnames(Bl2GO_95C_xls)  ## counting rownames as a colm ????????
 [1] "GO.ID"          "Term"           "Category"       "FDR"           
 [5] "P.Value"        "X.Test"         "X.Ref"          "X.notAnnotTest"
 [9] "X.notAnnotRef"  "Over.Under"     "TestSeqs"       "RefSeqs"
save.image(file="dir95C_frompro_june21_16.RData")
ls()






## save txt, 
## refer line 6785, 6806, 
## 1504 is 2x of wc of blast2go_fisher_20160602_2212.txt (753) Q: why diff ?????
## perhaps blank lines betw each real line (Q: why wc would not count these ???)
## now (looks like done prevly, redo, since also doing 95C), filter for 'Over/Under' (colm 9) => did, line 6851,
...



## now ready to 1st convert 








06/04/16:
## read bit of 2 references.
## blast2go ref: 0407034v2.pdf
understand bit more about how fisher exact test employed.
## GOstatsHyperG.pdf (Falcon & Gentleman)
## Upshot: to check with Vikas, see what can make out of blast2gO run on 06/01/16 above ????????????????????




ssh -Y pterry@crane.unl.edu 
# Rrq096mN 
cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo/95TUPsubset
ls -al



cd /work/amundsen/pterry/Trin21test/95C1-3T1-3/vbufalo/threecolmvikas_xls
